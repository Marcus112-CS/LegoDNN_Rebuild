2023-06-27 20:57:11,932 - log.py[38] - DEBUG: entry file content: ---------------------------------
2023-06-27 20:57:11,932 - log.py[39] - DEBUG: 
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

from legodnn.utils.dl.common.env import set_random_seed
set_random_seed(0)

import sys
sys.setrecursionlimit(100000) # 最大随机深度（与资源占用有关）
import torch

from legodnn import BlockExtractor, BlockTrainer, ServerBlockProfiler, EdgeBlockProfiler, OptimalRuntime
from legodnn.gen_series_legodnn_models import gen_series_legodnn_models
from legodnn.block_detection.model_topology_extraction import topology_extraction  # 构建模型拓扑结构
from legodnn.presets.auto_block_manager import AutoBlockManager
from legodnn.presets.common_detection_manager_1204_new import CommonDetectionManager
from legodnn.model_manager.common_model_manager import CommonModelManager  # AbstractModelManager的实现
from legodnn.utils.common.file import experiments_model_file_path
from legodnn.utils.dl.common.model import get_module, set_module, get_model_size

from cv_task.datasets.image_classification.cifar_dataloader import CIFAR10Dataloader, CIFAR100Dataloader
from cv_task.image_classification.cifar.models import resnet18
from cv_task.image_classification.cifar.legodnn_configs import get_cifar100_train_config_200e
dataset_root_dir = '/home/marcus/newspace/datasets'

if __name__ == '__main__':
    cv_task = 'image_classification'
    dataset_name = 'cifar100'
    model_name = 'resnet18'
    method = 'legodnn'
    device = 'cuda'
    compress_layer_max_ratio = 0.125  # 最大压缩比？？？
    model_input_size = (1, 3, 32, 32)
    
    block_sparsity = [0.0, 0.2, 0.4, 0.6, 0.8]
    root_path = os.path.join('results/legodnn', cv_task, model_name+'_'+dataset_name + '_' + str(compress_layer_max_ratio).replace('.', '-'))

    compressed_blocks_dir_path = root_path + '/compressed'  # 压缩后的block
    trained_blocks_dir_path = root_path + '/trained'  # 训练过的block
    descendant_models_dir_path = root_path + '/descendant'  # 后代block
    block_training_max_epoch = 65
    test_sample_num = 100
    
    checkpoint = None
    teacher_model = resnet18(num_classes=100).to(device)
    # teacher_model.load_state_dict(torch.load(checkpoint)['net'])  # 权重导入（初次训练没有）

    print('\033[1;36m-------------------------------->    BUILD LEGODNN GRAPH\033[0m')  # 构建拓扑结构
    model_graph = topology_extraction(teacher_model, model_input_size, device=device, mode='unpack')  # pack/unpack
    model_graph.print_ordered_node()  # 按顺序打印节点
    
    print('\033[1;36m-------------------------------->    START BLOCK DETECTION\033[0m')  # 根据拓扑结构探测block
    detection_manager = CommonDetectionManager(model_graph, max_ratio=compress_layer_max_ratio)
    detection_manager.detection_all_blocks()
    detection_manager.print_all_blocks()

    # modelmanager和blockmanager
    model_manager = CommonModelManager()
    block_manager = AutoBlockManager(block_sparsity, detection_manager, model_manager)
    
    print('\033[1;36m-------------------------------->    START BLOCK EXTRACTION\033[0m')  # block导出
    block_extractor = BlockExtractor(teacher_model, block_manager, compressed_blocks_dir_path, model_input_size, device)
    block_extractor.extract_all_blocks()  # 按稀疏度导出blocks

    print('\033[1;36m-------------------------------->    START BLOCK TRAIN\033[0m')
    train_loader, test_loader = CIFAR100Dataloader(root_dir=dataset_root_dir, num_workers=0, train_batch_size=128, test_batch_size=128)
    print("\033[32mDataloader done\033[0m")
    block_trainer = BlockTrainer(teacher_model, block_manager, model_manager, compressed_blocks_dir_path,
                                 trained_blocks_dir_path, block_training_max_epoch, train_loader, device=device)
    print("\033[32mDatatrainer initialized\033[0m")
    block_trainer.train_all_blocks()
    print("\033[32mBlock trained\033[0m")

    server_block_profiler = ServerBlockProfiler(teacher_model, block_manager, model_manager,
                                                trained_blocks_dir_path, test_loader, model_input_size, device)
    server_block_profiler.profile_all_blocks()

    edge_block_profiler = EdgeBlockProfiler(block_manager, model_manager, trained_blocks_dir_path, 
                                            test_sample_num, model_input_size, device)
    edge_block_profiler.profile_all_blocks()

    optimal_runtime = OptimalRuntime(trained_blocks_dir_path, model_input_size,
                                     block_manager, model_manager, device)
    model_size_min = get_model_size(torch.load(os.path.join(compressed_blocks_dir_path, 'model_frame.pt')))/1024**2
    model_size_max = get_model_size(teacher_model)/1024**2 + 1
    gen_series_legodnn_models(deadline=100, model_size_search_range=[model_size_min, model_size_max], target_model_num=100, optimal_runtime=optimal_runtime, descendant_models_save_path=descendant_models_dir_path, device=device)
2023-06-27 20:57:11,932 - log.py[40] - DEBUG: entry file content: ---------------------------------
2023-06-27 20:57:17,923 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-0.pt
2023-06-27 20:57:17,923 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:18,199 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-2.pt
2023-06-27 20:57:18,199 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:18,465 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-4.pt
2023-06-27 20:57:18,465 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:18,738 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-6.pt
2023-06-27 20:57:18,738 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:19,004 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-8.pt
2023-06-27 20:57:19,004 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:19,037 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-0.pt
2023-06-27 20:57:19,037 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:19,298 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-2.pt
2023-06-27 20:57:19,298 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:19,571 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-4.pt
2023-06-27 20:57:19,571 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:19,836 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-6.pt
2023-06-27 20:57:19,836 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:20,103 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-8.pt
2023-06-27 20:57:20,103 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:20,132 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-0.pt
2023-06-27 20:57:20,133 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:20,345 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-2.pt
2023-06-27 20:57:20,346 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:20,554 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-4.pt
2023-06-27 20:57:20,554 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 77, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:20,769 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-6.pt
2023-06-27 20:57:20,769 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:21,039 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-8.pt
2023-06-27 20:57:21,039 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:21,071 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-0.pt
2023-06-27 20:57:21,071 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:21,332 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-2.pt
2023-06-27 20:57:21,332 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:21,597 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-4.pt
2023-06-27 20:57:21,597 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:21,867 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-6.pt
2023-06-27 20:57:21,867 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:22,133 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-8.pt
2023-06-27 20:57:22,133 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:22,166 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-0.pt
2023-06-27 20:57:22,166 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:22,383 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-2.pt
2023-06-27 20:57:22,383 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:22,603 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-4.pt
2023-06-27 20:57:22,603 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 154, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(154, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:22,834 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-6.pt
2023-06-27 20:57:22,834 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:23,054 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-8.pt
2023-06-27 20:57:23,055 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:23,100 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-0.pt
2023-06-27 20:57:23,100 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:23,385 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-2.pt
2023-06-27 20:57:23,385 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:23,668 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-4.pt
2023-06-27 20:57:23,668 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 154, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(154, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:23,963 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-6.pt
2023-06-27 20:57:23,963 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:24,240 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-8.pt
2023-06-27 20:57:24,240 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:24,289 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-0.pt
2023-06-27 20:57:24,289 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:24,570 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-2.pt
2023-06-27 20:57:24,570 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 410, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(410, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(410, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:24,845 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-4.pt
2023-06-27 20:57:24,845 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 308, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(308, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(308, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:25,131 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-6.pt
2023-06-27 20:57:25,132 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:25,387 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-8.pt
2023-06-27 20:57:25,387 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-27 20:57:25,439 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-0.pt
2023-06-27 20:57:25,439 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:25,810 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-2.pt
2023-06-27 20:57:25,810 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(410, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(410, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:26,172 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-4.pt
2023-06-27 20:57:26,172 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 308, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(308, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(308, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:26,506 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-6.pt
2023-06-27 20:57:26,507 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:26,838 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-8.pt
2023-06-27 20:57:26,838 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-27 20:57:28,337 - block_trainer.py[183] - INFO: start block training...
2023-06-27 21:04:16,708 - block_trainer.py[357] - INFO: epoch 0 (408.370652s, 40 blocks still need training), blocks loss: 
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-0 | 0.44865295 | 0.45221681 | 0.45899490 | 0.47105719 | 0.49270953 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-1 | 0.77841776 | 0.77971523 | 0.78159156 | 0.78455448 | 0.79121273 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-2 | 0.00290354 | 0.00271508 | 0.00237661 | 0.00208632 | 0.00195592 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-3 | 0.83514710 | 0.83578800 | 0.83671879 | 0.83784849 | 0.83979016 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-4 | 0.00322009 | 0.00257049 | 0.00203979 | 0.00150614 | 0.00094015 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-5 | 0.86806572 | 0.86807367 | 0.86667885 | 0.84862814 | 0.56229053 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-6 | 0.00226637 | 0.00169372 | 0.00123862 | 0.00082253 | 0.00042903 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-7 | 0.88079648 | 0.88097149 | 0.88108264 | 0.88049020 | 0.86028166 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+

2023-06-27 21:11:06,696 - block_trainer.py[357] - INFO: epoch 1 (409.987944s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.22279773   |   0.22424673   |   0.22654369   |   0.23032375   |   0.23851302   |
|         | (↓ 0.22585523) | (↓ 0.22797008) | (↓ 0.23245121) | (↓ 0.24073344) | (↓ 0.25419651) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.59325308   |   0.59396157   |   0.59501407   |   0.59649143   |   0.56638577   |
|         | (↓ 0.18516468) | (↓ 0.18575367) | (↓ 0.18657749) | (↓ 0.18806305) | (↓ 0.22482697) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00050280   |   0.00053255   |   0.00055361   |   0.00060842   |   0.00069698   |
|         | (↓ 0.00240074) | (↓ 0.00218253) | (↓ 0.00182300) | (↓ 0.00147790) | (↓ 0.00125894) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.64439307   |   0.64476688   |   0.64527203   |   0.64580015   |   0.59602198   |
|         | (↓ 0.19075403) | (↓ 0.19102112) | (↓ 0.19144676) | (↓ 0.19204835) | (↓ 0.24376819) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00033573   |   0.00030759   |   0.00026538   |   0.00025297   |   0.00022714   |
|         | (↓ 0.00288435) | (↓ 0.00226290) | (↓ 0.00177441) | (↓ 0.00125317) | (↓ 0.00071301) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.67392520   |   0.67045032   |   0.66174347   |   0.51275230   |   0.03303265   |
|         | (↓ 0.19414052) | (↓ 0.19762335) | (↓ 0.20493539) | (↓ 0.33587584) | (↓ 0.52925788) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00017334   |   0.00013458   |   0.00010365   |   0.00010514   |   0.00005611   |
|         | (↓ 0.00209303) | (↓ 0.00155914) | (↓ 0.00113497) | (↓ 0.00071740) | (↓ 0.00037292) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.68531860   |   0.68541339   |   0.68555595   |   0.68575296   |   0.67993279   |
|         | (↓ 0.19547788) | (↓ 0.19555811) | (↓ 0.19552670) | (↓ 0.19473724) | (↓ 0.18034887) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 21:17:56,415 - block_trainer.py[357] - INFO: epoch 2 (409.718267s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.10617729   |   0.10729419   |   0.10900482   |   0.11166419   |   0.11848003   |
|         | (↓ 0.11662043) | (↓ 0.11695254) | (↓ 0.11753886) | (↓ 0.11865956) | (↓ 0.12003300) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.44395176   |   0.44454554   |   0.44539959   |   0.44658832   |   0.22809206   |
|         | (↓ 0.14930133) | (↓ 0.14941602) | (↓ 0.14961448) | (↓ 0.14990312) | (↓ 0.33829371) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00041140   |   0.00043712   |   0.00045238   |   0.00050217   |   0.00057422   |
|         | (↓ 0.00009140) | (↓ 0.00009543) | (↓ 0.00010123) | (↓ 0.00010625) | (↓ 0.00012276) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.48781930   |   0.48813013   |   0.48852986   |   0.48788383   |   0.27663246   |
|         | (↓ 0.15657377) | (↓ 0.15663675) | (↓ 0.15674217) | (↓ 0.15791631) | (↓ 0.31938952) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00022448   |   0.00021860   |   0.00019307   |   0.00019386   |   0.00017876   |
|         | (↓ 0.00011126) | (↓ 0.00008899) | (↓ 0.00007231) | (↓ 0.00005911) | (↓ 0.00004838) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.49133212   |   0.48825818   |   0.44956730   |   0.23923267   |   0.01624258   |
|         | (↓ 0.18259308) | (↓ 0.18219214) | (↓ 0.21217617) | (↓ 0.27351963) | (↓ 0.01679008) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00013924   |   0.00010869   |   0.00008234   |   0.00006296   |   0.00004726   |
|         | (↓ 0.00003410) | (↓ 0.00002589) | (↓ 0.00002131) | (↓ 0.00004217) | (↓ 0.00000885) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.52310455   |   0.52316487   |   0.52324642   |   0.52331966   |   0.51927008   |
|         | (↓ 0.16221405) | (↓ 0.16224851) | (↓ 0.16230953) | (↓ 0.16243330) | (↓ 0.16066271) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 21:24:47,828 - block_trainer.py[357] - INFO: epoch 3 (411.413082s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.04639480   |   0.04731025   |   0.04873792   |   0.05102349   |   0.05705146   |
|         | (↓ 0.05978249) | (↓ 0.05998394) | (↓ 0.06026690) | (↓ 0.06064070) | (↓ 0.06142857) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.32389341   |   0.32439448   |   0.32510274   |   0.32613920   |   0.07858760   |
|         | (↓ 0.12005835) | (↓ 0.12015106) | (↓ 0.12029685) | (↓ 0.12044912) | (↓ 0.14950446) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00037057   |   0.00038715   |   0.00039680   |   0.00044744   |   0.00051162   |
|         | (↓ 0.00004083) | (↓ 0.00004997) | (↓ 0.00005559) | (↓ 0.00005473) | (↓ 0.00006259) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.36059229   |   0.36084774   |   0.36126261   |   0.26717667   |   0.13569057   |
|         | (↓ 0.12722701) | (↓ 0.12728239) | (↓ 0.12726724) | (↓ 0.22070716) | (↓ 0.14094189) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00018602   |   0.00018500   |   0.00016512   |   0.00016482   |   0.00015472   |
|         | (↓ 0.00003845) | (↓ 0.00003360) | (↓ 0.00002794) | (↓ 0.00002903) | (↓ 0.00002404) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.09173882   |   0.19222322   |   0.16050817   |   0.14432573   |   0.01215905   |
|         | (↓ 0.39959330) | (↓ 0.29603496) | (↓ 0.28905913) | (↓ 0.09490694) | (↓ 0.00408352) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00014415   |    0.00010920   |   0.00007875   |   0.00005693   |   0.00004374   |
|         | (↓ -0.00000491) | (↓ -0.00000051) | (↓ 0.00000359) | (↓ 0.00000604) | (↓ 0.00000352) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.39029254   |   0.39027243   |   0.39033382   |   0.39045927   |   0.38722896   |
|         | (↓ 0.13281202) | (↓ 0.13289244) | (↓ 0.13291260) | (↓ 0.13286039) | (↓ 0.13204113) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 21:31:38,208 - block_trainer.py[357] - INFO: epoch 4 (410.379226s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.01953238   |   0.02031001   |   0.02154747   |   0.02366685   |   0.02913074   |
|         | (↓ 0.02686242) | (↓ 0.02700024) | (↓ 0.02719045) | (↓ 0.02735664) | (↓ 0.02792072) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.22899639   |   0.22941174   |   0.22999524   |   0.23090557   |   0.04186867   |
|         | (↓ 0.09489702) | (↓ 0.09498274) | (↓ 0.09510750) | (↓ 0.09523363) | (↓ 0.03671892) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00033780   |   0.00035705   |   0.00036609   |   0.00041295   |   0.00047478   |
|         | (↓ 0.00003277) | (↓ 0.00003010) | (↓ 0.00003070) | (↓ 0.00003449) | (↓ 0.00003684) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.25887695   |   0.25910164   |   0.24335160   |   0.08614296   |   0.07115562   |
|         | (↓ 0.10171534) | (↓ 0.10174610) | (↓ 0.11791101) | (↓ 0.18103371) | (↓ 0.06453495) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00016129   |   0.00016124   |   0.00014444   |   0.00014486   |   0.00013936   |
|         | (↓ 0.00002473) | (↓ 0.00002376) | (↓ 0.00002069) | (↓ 0.00001996) | (↓ 0.00001536) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00427550   |   0.02135100   |   0.02708622   |   0.08706015   |   0.00971684   |
|         | (↓ 0.08746332) | (↓ 0.17087222) | (↓ 0.13342195) | (↓ 0.05726557) | (↓ 0.00244221) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00013556   |   0.00010383   |   0.00007514   |   0.00005413   |   0.00004142   |
|         | (↓ 0.00000859) | (↓ 0.00000538) | (↓ 0.00000361) | (↓ 0.00000280) | (↓ 0.00000232) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.17847811   |   0.18445799   |   0.25470069   |   0.28342296   |   0.28004989   |
|         | (↓ 0.21181442) | (↓ 0.20581444) | (↓ 0.13563313) | (↓ 0.10703631) | (↓ 0.10717906) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 21:38:28,671 - block_trainer.py[357] - INFO: epoch 5 (410.463566s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00925279   |   0.00993154   |   0.01103644   |   0.01304886   |   0.01806329   |
|         | (↓ 0.01027959) | (↓ 0.01037847) | (↓ 0.01051103) | (↓ 0.01061800) | (↓ 0.01106744) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.15571603   |   0.15605353   |   0.15652636   |   0.15745929   |   0.01717152   |
|         | (↓ 0.07328036) | (↓ 0.07335821) | (↓ 0.07346889) | (↓ 0.07344628) | (↓ 0.02469715) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00030662   |   0.00032215   |   0.00033194   |   0.00037966   |   0.00044677   |
|         | (↓ 0.00003118) | (↓ 0.00003490) | (↓ 0.00003415) | (↓ 0.00003329) | (↓ 0.00002801) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.17930854   |   0.17948253   |   0.02000906   |   0.02556872   |   0.03920520   |
|         | (↓ 0.07956841) | (↓ 0.07961910) | (↓ 0.22334254) | (↓ 0.06057424) | (↓ 0.03195043) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00014381   |   0.00014276   |   0.00013165   |   0.00013256   |   0.00012849   |
|         | (↓ 0.00001748) | (↓ 0.00001848) | (↓ 0.00001278) | (↓ 0.00001231) | (↓ 0.00001087) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00259015   |   0.00359882   |   0.00573737   |   0.05197512   |   0.00886495   |
|         | (↓ 0.00168535) | (↓ 0.01775218) | (↓ 0.02134885) | (↓ 0.03508503) | (↓ 0.00085190) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00012151   |   0.00009410   |   0.00006989   |   0.00005086   |   0.00003847   |
|         | (↓ 0.00001405) | (↓ 0.00000973) | (↓ 0.00000525) | (↓ 0.00000327) | (↓ 0.00000295) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00023282   |   0.00030005   |   0.00067461   |   0.19878388   |   0.19545597   |
|         | (↓ 0.17824529) | (↓ 0.18415794) | (↓ 0.25402608) | (↓ 0.08463908) | (↓ 0.08459392) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 21:45:18,650 - block_trainer.py[357] - INFO: epoch 6 (409.978821s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00584575   |   0.00646187   |   0.00747343   |   0.00937820   |   0.01398298   |
|         | (↓ 0.00340704) | (↓ 0.00346967) | (↓ 0.00356302) | (↓ 0.00367065) | (↓ 0.00408032) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.10090391   |   0.10116999   |   0.10154329   |   0.09686962   |   0.00921935   |
|         | (↓ 0.05481213) | (↓ 0.05488355) | (↓ 0.05498307) | (↓ 0.06058967) | (↓ 0.00795217) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00029886   |   0.00031065   |   0.00031730   |   0.00035919   |   0.00042524   |
|         | (↓ 0.00000776) | (↓ 0.00001151) | (↓ 0.00001464) | (↓ 0.00002047) | (↓ 0.00002153) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.11882640   |   0.11899491   |   0.00178229   |   0.00595987   |   0.01655745   |
|         | (↓ 0.06048214) | (↓ 0.06048763) | (↓ 0.01822677) | (↓ 0.01960885) | (↓ 0.02264775) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00014051   |   0.00013760   |   0.00012463   |   0.00012370   |   0.00012106   |
|         | (↓ 0.00000330) | (↓ 0.00000516) | (↓ 0.00000702) | (↓ 0.00000886) | (↓ 0.00000743) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00139368   |   0.00218611   |   0.00317977   |   0.03114345   |   0.00779669   |
|         | (↓ 0.00119647) | (↓ 0.00141271) | (↓ 0.00255760) | (↓ 0.02083166) | (↓ 0.00106825) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00011140   |   0.00008700   |   0.00006586   |   0.00004691   |   0.00003517   |
|         | (↓ 0.00001011) | (↓ 0.00000710) | (↓ 0.00000403) | (↓ 0.00000395) | (↓ 0.00000329) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00010057   |   0.00012015   |   0.00016709   |   0.13339905   |   0.13021913   |
|         | (↓ 0.00013225) | (↓ 0.00017990) | (↓ 0.00050752) | (↓ 0.06538482) | (↓ 0.06523684) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 21:52:08,605 - block_trainer.py[357] - INFO: epoch 7 (409.955067s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00476481   |   0.00534000   |   0.00627242   |   0.00805383   |   0.01239682   |
|         | (↓ 0.00108093) | (↓ 0.00112187) | (↓ 0.00120101) | (↓ 0.00132437) | (↓ 0.00158615) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.06160208   |   0.06180462   |   0.06208971   |   0.02601271   |   0.00544747   |
|         | (↓ 0.03930183) | (↓ 0.03936537) | (↓ 0.03945358) | (↓ 0.07085690) | (↓ 0.00377189) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00029109   |   0.00030240   |   0.00030966   |   0.00035327   |   0.00041233   |
|         | (↓ 0.00000778) | (↓ 0.00000824) | (↓ 0.00000764) | (↓ 0.00000592) | (↓ 0.00001291) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.07453955   |   0.07472010   |   0.00134506   |   0.00249442   |   0.00761506   |
|         | (↓ 0.04428685) | (↓ 0.04427481) | (↓ 0.00043723) | (↓ 0.00346545) | (↓ 0.00894239) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00012449   |   0.00012260   |   0.00011617   |   0.00011765   |   0.00011617   |
|         | (↓ 0.00001602) | (↓ 0.00001500) | (↓ 0.00000846) | (↓ 0.00000605) | (↓ 0.00000489) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00133383   |   0.00162738   |   0.00270535   |   0.01715046   |   0.00712905   |
|         | (↓ 0.00005986) | (↓ 0.00055874) | (↓ 0.00047442) | (↓ 0.01399299) | (↓ 0.00066764) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00010058   |   0.00007947   |   0.00006031   |   0.00004294   |   0.00003211   |
|         | (↓ 0.00001082) | (↓ 0.00000753) | (↓ 0.00000555) | (↓ 0.00000398) | (↓ 0.00000307) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00006418   |   0.00007410   |   0.00009274   |   0.03543700   |   0.08092268   |
|         | (↓ 0.00003639) | (↓ 0.00004605) | (↓ 0.00007435) | (↓ 0.09796205) | (↓ 0.04929645) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 21:58:58,431 - block_trainer.py[357] - INFO: epoch 8 (409.825058s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00433961   |   0.00488926   |   0.00575037   |   0.00743270   |   0.01153643   |
|         | (↓ 0.00042520) | (↓ 0.00045073) | (↓ 0.00052204) | (↓ 0.00062113) | (↓ 0.00086040) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.03487161   |   0.03502232   |   0.03523346   |   0.00504299   |   0.00469542   |
|         | (↓ 0.02673047) | (↓ 0.02678230) | (↓ 0.02685625) | (↓ 0.02096973) | (↓ 0.00075205) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00028797   |   0.00029720   |   0.00029876   |   0.00033697   |   0.00040084   |
|         | (↓ 0.00000312) | (↓ 0.00000520) | (↓ 0.00001090) | (↓ 0.00001630) | (↓ 0.00001149) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.04365585   |   0.04386917   |   0.00108273   |   0.00220568   |   0.00442477   |
|         | (↓ 0.03088370) | (↓ 0.03085093) | (↓ 0.00026233) | (↓ 0.00028875) | (↓ 0.00319029) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00012291   |   0.00011845   |   0.00011072   |   0.00011086   |   0.00011078   |
|         | (↓ 0.00000158) | (↓ 0.00000415) | (↓ 0.00000545) | (↓ 0.00000679) | (↓ 0.00000539) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-5 |    0.00150599   |   0.00140717   |   0.00230030   |   0.01086517   |   0.00643465   |
|         | (↓ -0.00017216) | (↓ 0.00022021) | (↓ 0.00040506) | (↓ 0.00628529) | (↓ 0.00069440) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00009446   |   0.00007504   |   0.00005586   |   0.00004060   |   0.00003016   |
|         | (↓ 0.00000613) | (↓ 0.00000443) | (↓ 0.00000445) | (↓ 0.00000233) | (↓ 0.00000195) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00005024   |   0.00005628   |   0.00006431   |   0.00021807   |   0.04577983   |
|         | (↓ 0.00001393) | (↓ 0.00001782) | (↓ 0.00002843) | (↓ 0.03521893) | (↓ 0.03514286) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 22:05:48,191 - block_trainer.py[357] - INFO: epoch 9 (409.760315s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00399089   |   0.00451349   |   0.00530769   |   0.00691361   |   0.01076755   |
|         | (↓ 0.00034872) | (↓ 0.00037578) | (↓ 0.00044268) | (↓ 0.00051909) | (↓ 0.00076888) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.01797397   |   0.01808296   |   0.01823591   |   0.00166715   |   0.00428354   |
|         | (↓ 0.01689764) | (↓ 0.01693936) | (↓ 0.01699755) | (↓ 0.00337584) | (↓ 0.00041188) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00026698   |   0.00027736   |   0.00028679   |   0.00032654   |   0.00039194   |
|         | (↓ 0.00002098) | (↓ 0.00001985) | (↓ 0.00001198) | (↓ 0.00001043) | (↓ 0.00000890) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.02345370   |   0.01557170   |   0.00088497   |   0.00171182   |   0.00292731   |
|         | (↓ 0.02020216) | (↓ 0.02829746) | (↓ 0.00019776) | (↓ 0.00049386) | (↓ 0.00149746) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00011577   |   0.00011208   |   0.00010610   |   0.00010776   |   0.00010654   |
|         | (↓ 0.00000714) | (↓ 0.00000638) | (↓ 0.00000463) | (↓ 0.00000310) | (↓ 0.00000424) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00066543   |   0.00114187   |   0.00178266   |   0.00638853   |   0.00608673   |
|         | (↓ 0.00084056) | (↓ 0.00026530) | (↓ 0.00051764) | (↓ 0.00447664) | (↓ 0.00034792) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00009129   |   0.00007351   |   0.00005471   |   0.00003871   |   0.00002841   |
|         | (↓ 0.00000316) | (↓ 0.00000153) | (↓ 0.00000115) | (↓ 0.00000189) | (↓ 0.00000175) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00004183   |   0.00004553   |   0.00004846   |   0.00010503   |   0.02261831   |
|         | (↓ 0.00000841) | (↓ 0.00001075) | (↓ 0.00001585) | (↓ 0.00011303) | (↓ 0.02316152) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 22:12:38,012 - block_trainer.py[357] - INFO: epoch 10 (409.820115s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00371670   |   0.00420997   |   0.00494287   |   0.00647501   |   0.01005524   |
|         | (↓ 0.00027419) | (↓ 0.00030351) | (↓ 0.00036483) | (↓ 0.00043860) | (↓ 0.00071230) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00821598   |   0.00829494   |   0.00840510   |   0.00108505   |   0.00392496   |
|         | (↓ 0.00975799) | (↓ 0.00978802) | (↓ 0.00983081) | (↓ 0.00058210) | (↓ 0.00035858) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-2 |    0.00026747   |   0.00027511   |   0.00027962   |   0.00031792   |   0.00038475   |
|         | (↓ -0.00000048) | (↓ 0.00000224) | (↓ 0.00000716) | (↓ 0.00000862) | (↓ 0.00000719) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+-----------------+-----------------+----------------+
| block-3 |   0.01128861   |   0.00032425   |    0.00103312   |    0.00191907   |   0.00276831   |
|         | (↓ 0.01216509) | (↓ 0.01524745) | (↓ -0.00014815) | (↓ -0.00020726) | (↓ 0.00015900) |
+---------+----------------+----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00011055   |   0.00010573   |   0.00010021   |   0.00010245   |   0.00010324   |
|         | (↓ 0.00000521) | (↓ 0.00000635) | (↓ 0.00000589) | (↓ 0.00000530) | (↓ 0.00000331) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00159778   |    0.00115579   |    0.00228053   |   0.00523937   |   0.00519607   |
|         | (↓ -0.00093235) | (↓ -0.00001392) | (↓ -0.00049788) | (↓ 0.00114916) | (↓ 0.00089065) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00008128   |   0.00006605   |   0.00005122   |   0.00003604   |   0.00002703   |
|         | (↓ 0.00001001) | (↓ 0.00000745) | (↓ 0.00000348) | (↓ 0.00000267) | (↓ 0.00000138) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00003746   |   0.00004354   |   0.00004238   |   0.00007350   |   0.00978526   |
|         | (↓ 0.00000438) | (↓ 0.00000199) | (↓ 0.00000608) | (↓ 0.00003154) | (↓ 0.01283305) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 22:19:29,227 - block_trainer.py[357] - INFO: epoch 11 (411.215425s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00347436   |   0.00394425   |   0.00462632   |   0.00608644   |   0.00939197   |
|         | (↓ 0.00024235) | (↓ 0.00026572) | (↓ 0.00031655) | (↓ 0.00038857) | (↓ 0.00066327) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00324756   |   0.00330703   |   0.00338984   |   0.00092995   |   0.00372211   |
|         | (↓ 0.00496842) | (↓ 0.00498791) | (↓ 0.00501526) | (↓ 0.00015510) | (↓ 0.00020285) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00026389   |   0.00026879   |   0.00027294   |   0.00030902   |   0.00037770   |
|         | (↓ 0.00000358) | (↓ 0.00000632) | (↓ 0.00000668) | (↓ 0.00000890) | (↓ 0.00000705) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00474550   |   0.00016923   |   0.00098274   |   0.00162973   |   0.00246647   |
|         | (↓ 0.00654311) | (↓ 0.00015503) | (↓ 0.00005037) | (↓ 0.00028935) | (↓ 0.00030184) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00011017   |   0.00010388   |   0.00009715   |   0.00009916   |   0.00010048   |
|         | (↓ 0.00000038) | (↓ 0.00000185) | (↓ 0.00000305) | (↓ 0.00000330) | (↓ 0.00000275) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+----------------+-----------------+-----------------+
| block-5 |   0.00088734   |    0.00120277   |   0.00201759   |    0.00554961   |    0.00536814   |
|         | (↓ 0.00071044) | (↓ -0.00004699) | (↓ 0.00026294) | (↓ -0.00031024) | (↓ -0.00017207) |
+---------+----------------+-----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00007603   |   0.00006133   |   0.00004769   |   0.00003447   |   0.00002629   |
|         | (↓ 0.00000525) | (↓ 0.00000472) | (↓ 0.00000353) | (↓ 0.00000157) | (↓ 0.00000074) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00003408   |   0.00003675   |   0.00003883   |   0.00005881   |   0.00379845   |
|         | (↓ 0.00000337) | (↓ 0.00000679) | (↓ 0.00000355) | (↓ 0.00001469) | (↓ 0.00598681) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 22:26:18,746 - block_trainer.py[357] - INFO: epoch 12 (409.518605s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00326493   |   0.00372686   |   0.00437461   |   0.00576161   |   0.00880470   |
|         | (↓ 0.00020943) | (↓ 0.00021739) | (↓ 0.00025171) | (↓ 0.00032482) | (↓ 0.00058728) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-1 |   0.00107601   |   0.00112480   |   0.00119231   |    0.00093634   |   0.00361418   |
|         | (↓ 0.00217155) | (↓ 0.00218223) | (↓ 0.00219753) | (↓ -0.00000639) | (↓ 0.00010793) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-2 |   0.00025742   |   0.00026519   |   0.00027079   |   0.00030879   |    0.00037816   |
|         | (↓ 0.00000647) | (↓ 0.00000360) | (↓ 0.00000215) | (↓ 0.00000023) | (↓ -0.00000045) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-3 |   0.00167939   |   0.00014570   |   0.00082533   |    0.00176828   |   0.00245166   |
|         | (↓ 0.00306611) | (↓ 0.00002352) | (↓ 0.00015741) | (↓ -0.00013855) | (↓ 0.00001481) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010500   |   0.00009995   |   0.00009492   |   0.00009718   |   0.00009749   |
|         | (↓ 0.00000517) | (↓ 0.00000393) | (↓ 0.00000223) | (↓ 0.00000198) | (↓ 0.00000300) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00055152   |   0.00102158   |   0.00133062   |   0.00380626   |   0.00421122   |
|         | (↓ 0.00033582) | (↓ 0.00018120) | (↓ 0.00068697) | (↓ 0.00174335) | (↓ 0.00115692) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00007118   |   0.00005799   |   0.00004579   |   0.00003247   |   0.00002503   |
|         | (↓ 0.00000485) | (↓ 0.00000334) | (↓ 0.00000191) | (↓ 0.00000200) | (↓ 0.00000126) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.00004380   |    0.00003743   |    0.00003972   |   0.00005135   |   0.00152541   |
|         | (↓ -0.00000971) | (↓ -0.00000068) | (↓ -0.00000089) | (↓ 0.00000745) | (↓ 0.00227304) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2023-06-27 22:33:08,564 - block_trainer.py[357] - INFO: epoch 13 (409.817672s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00303709   |   0.00346698   |   0.00409095   |   0.00540279   |   0.00819264   |
|         | (↓ 0.00022784) | (↓ 0.00025988) | (↓ 0.00028365) | (↓ 0.00035883) | (↓ 0.00061206) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00029623   |   0.00034028   |   0.00040077   |   0.00080786   |   0.00336646   |
|         | (↓ 0.00077978) | (↓ 0.00078452) | (↓ 0.00079154) | (↓ 0.00012848) | (↓ 0.00024772) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00024544   |   0.00025239   |   0.00025856   |   0.00029869   |   0.00037407   |
|         | (↓ 0.00001198) | (↓ 0.00001279) | (↓ 0.00001223) | (↓ 0.00001010) | (↓ 0.00000409) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00048397   |   0.00013092   |   0.00069398   |   0.00142040   |   0.00240194   |
|         | (↓ 0.00119542) | (↓ 0.00001479) | (↓ 0.00013136) | (↓ 0.00034788) | (↓ 0.00004972) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009933   |   0.00009438   |   0.00008949   |   0.00009234   |   0.00009439   |
|         | (↓ 0.00000567) | (↓ 0.00000556) | (↓ 0.00000543) | (↓ 0.00000484) | (↓ 0.00000309) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+----------------+----------------+
| block-5 |    0.00100855   |   0.00092754   |    0.00158001   |   0.00367879   |   0.00417718   |
|         | (↓ -0.00045703) | (↓ 0.00009404) | (↓ -0.00024939) | (↓ 0.00012746) | (↓ 0.00003403) |
+---------+-----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00006612   |   0.00005377   |   0.00004163   |   0.00003062   |   0.00002416   |
|         | (↓ 0.00000506) | (↓ 0.00000422) | (↓ 0.00000416) | (↓ 0.00000185) | (↓ 0.00000087) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-7 |   0.00003231   |   0.00003572   |    0.00004243   |   0.00004248   |   0.00069199   |
|         | (↓ 0.00001149) | (↓ 0.00000171) | (↓ -0.00000271) | (↓ 0.00000887) | (↓ 0.00083342) |
+---------+----------------+----------------+-----------------+----------------+----------------+

2023-06-27 22:39:59,287 - block_trainer.py[357] - INFO: epoch 14 (410.722677s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00291568   |   0.00331228   |   0.00391191   |   0.00513849   |   0.00767727   |
|         | (↓ 0.00012141) | (↓ 0.00015470) | (↓ 0.00017904) | (↓ 0.00026429) | (↓ 0.00051537) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-1 |   0.00007927   |   0.00012118   |   0.00017927   |    0.00085104   |    0.00357733   |
|         | (↓ 0.00021696) | (↓ 0.00021910) | (↓ 0.00022150) | (↓ -0.00004318) | (↓ -0.00021086) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00024081   |   0.00024717   |   0.00025556   |   0.00029222   |   0.00036829   |
|         | (↓ 0.00000463) | (↓ 0.00000522) | (↓ 0.00000300) | (↓ 0.00000647) | (↓ 0.00000579) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+-----------------+-----------------+----------------+
| block-3 |   0.00011229   |   0.00012971   |    0.00114363   |    0.00235990   |   0.00216672   |
|         | (↓ 0.00037168) | (↓ 0.00000121) | (↓ -0.00044965) | (↓ -0.00093950) | (↓ 0.00023522) |
+---------+----------------+----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-4 |   0.00009625   |   0.00009266   |   0.00008941   |    0.00009237   |   0.00009230   |
|         | (↓ 0.00000308) | (↓ 0.00000172) | (↓ 0.00000008) | (↓ -0.00000003) | (↓ 0.00000209) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-5 |   0.00087885   |   0.00085839   |    0.00164136   |   0.00364466   |   0.00368515   |
|         | (↓ 0.00012970) | (↓ 0.00006915) | (↓ -0.00006135) | (↓ 0.00003413) | (↓ 0.00049204) |
+---------+----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00006173   |   0.00005224   |   0.00004143   |   0.00003001   |   0.00002323   |
|         | (↓ 0.00000439) | (↓ 0.00000153) | (↓ 0.00000020) | (↓ 0.00000061) | (↓ 0.00000093) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00003164   |   0.00003233   |   0.00003002   |   0.00004000   |   0.00041446   |
|         | (↓ 0.00000067) | (↓ 0.00000339) | (↓ 0.00001240) | (↓ 0.00000249) | (↓ 0.00027753) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 22:46:49,473 - block_trainer.py[357] - INFO: epoch 15 (410.185936s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00268237   |   0.00303897   |   0.00362302   |   0.00474806   |   0.00702925   |
|         | (↓ 0.00023331) | (↓ 0.00027331) | (↓ 0.00028889) | (↓ 0.00039043) | (↓ 0.00064802) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003179   |   0.00007271   |   0.00013021   |   0.00076110   |   0.00308519   |
|         | (↓ 0.00004748) | (↓ 0.00004847) | (↓ 0.00004906) | (↓ 0.00008994) | (↓ 0.00049214) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00023336   |   0.00024041   |   0.00024749   |   0.00028421   |   0.00036251   |
|         | (↓ 0.00000745) | (↓ 0.00000676) | (↓ 0.00000807) | (↓ 0.00000801) | (↓ 0.00000577) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00002440   |   0.00010700   |   0.00050742   |   0.00109059   |   0.00186326   |
|         | (↓ 0.00008789) | (↓ 0.00002271) | (↓ 0.00063621) | (↓ 0.00126931) | (↓ 0.00030346) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009284   |   0.00008800   |   0.00008486   |   0.00008750   |   0.00008917   |
|         | (↓ 0.00000342) | (↓ 0.00000466) | (↓ 0.00000455) | (↓ 0.00000487) | (↓ 0.00000313) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00034445   |   0.00054127   |   0.00076432   |   0.00267605   |   0.00302464   |
|         | (↓ 0.00053441) | (↓ 0.00031712) | (↓ 0.00087704) | (↓ 0.00096861) | (↓ 0.00066051) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00005486   |   0.00004620   |   0.00003731   |   0.00002822   |   0.00002247   |
|         | (↓ 0.00000687) | (↓ 0.00000604) | (↓ 0.00000413) | (↓ 0.00000180) | (↓ 0.00000077) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.00003565   |    0.00003242   |    0.00003153   |   0.00003471   |   0.00030828   |
|         | (↓ -0.00000401) | (↓ -0.00000010) | (↓ -0.00000150) | (↓ 0.00000529) | (↓ 0.00010618) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2023-06-27 22:53:39,280 - block_trainer.py[357] - INFO: epoch 16 (409.807521s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00252954   |   0.00285027   |   0.00341173   |   0.00443461   |   0.00648098   |
|         | (↓ 0.00015283) | (↓ 0.00018870) | (↓ 0.00021129) | (↓ 0.00031345) | (↓ 0.00054826) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00002482   |   0.00006526   |   0.00012279   |   0.00072179   |   0.00300466   |
|         | (↓ 0.00000697) | (↓ 0.00000745) | (↓ 0.00000742) | (↓ 0.00003931) | (↓ 0.00008053) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00022719   |   0.00023374   |   0.00024186   |   0.00027707   |   0.00035981   |
|         | (↓ 0.00000617) | (↓ 0.00000667) | (↓ 0.00000563) | (↓ 0.00000714) | (↓ 0.00000271) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |   0.00000935   |    0.00010918   |    0.00061940   |    0.00124215   |    0.00202879   |
|         | (↓ 0.00001505) | (↓ -0.00000218) | (↓ -0.00011198) | (↓ -0.00015157) | (↓ -0.00016553) |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009049   |   0.00008514   |   0.00008206   |   0.00008600   |   0.00008770   |
|         | (↓ 0.00000234) | (↓ 0.00000286) | (↓ 0.00000280) | (↓ 0.00000149) | (↓ 0.00000147) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00077323   |    0.00066952   |    0.00111613   |    0.00268067   |   0.00278818   |
|         | (↓ -0.00042878) | (↓ -0.00012825) | (↓ -0.00035181) | (↓ -0.00000462) | (↓ 0.00023646) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004953   |   0.00004243   |   0.00003440   |   0.00002679   |   0.00002194   |
|         | (↓ 0.00000533) | (↓ 0.00000376) | (↓ 0.00000291) | (↓ 0.00000143) | (↓ 0.00000053) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+-----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+-----------------+----------------+-----------------+----------------+
| block-7 |   0.00003043   |    0.00003462   |   0.00002772   |    0.00003716   |   0.00025848   |
|         | (↓ 0.00000522) | (↓ -0.00000220) | (↓ 0.00000380) | (↓ -0.00000245) | (↓ 0.00004980) |
+---------+----------------+-----------------+----------------+-----------------+----------------+

2023-06-27 23:00:29,463 - block_trainer.py[357] - INFO: epoch 17 (410.182304s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00245199   |   0.00274752   |   0.00328036   |   0.00423195   |   0.00601387   |
|         | (↓ 0.00007755) | (↓ 0.00010275) | (↓ 0.00013137) | (↓ 0.00020266) | (↓ 0.00046711) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-1 |   0.00002398   |   0.00006394   |   0.00012181   |    0.00073146   |    0.00307875   |
|         | (↓ 0.00000083) | (↓ 0.00000132) | (↓ 0.00000098) | (↓ -0.00000967) | (↓ -0.00007410) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+-----------------+-----------------+
|         |       0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+-----------------+----------------+----------------+-----------------+-----------------+
| block-2 |    0.00022836   |   0.00023356   |   0.00024163   |    0.00027855   |    0.00036235   |
|         | (↓ -0.00000117) | (↓ 0.00000017) | (↓ 0.00000023) | (↓ -0.00000148) | (↓ -0.00000254) |
+---------+-----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+-----------------+-----------------+-----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |   0.00000738   |    0.00011873   |    0.00095272   |    0.00161002   |   0.00198005   |
|         | (↓ 0.00000197) | (↓ -0.00000955) | (↓ -0.00033331) | (↓ -0.00036787) | (↓ 0.00004873) |
+---------+----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008997   |   0.00008475   |   0.00008075   |   0.00008387   |   0.00008680   |
|         | (↓ 0.00000052) | (↓ 0.00000038) | (↓ 0.00000131) | (↓ 0.00000213) | (↓ 0.00000090) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-5 |   0.00048973   |    0.00067653   |   0.00104379   |   0.00243289   |   0.00244675   |
|         | (↓ 0.00028350) | (↓ -0.00000701) | (↓ 0.00007234) | (↓ 0.00024778) | (↓ 0.00034143) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004890   |   0.00004114   |   0.00003372   |   0.00002609   |   0.00002137   |
|         | (↓ 0.00000063) | (↓ 0.00000129) | (↓ 0.00000067) | (↓ 0.00000070) | (↓ 0.00000057) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00002305   |   0.00003341   |   0.00002614   |   0.00003159   |   0.00021949   |
|         | (↓ 0.00000738) | (↓ 0.00000121) | (↓ 0.00000158) | (↓ 0.00000556) | (↓ 0.00003899) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 23:07:19,349 - block_trainer.py[357] - INFO: epoch 18 (409.885758s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00230495   |   0.00257463   |   0.00308285   |   0.00396435   |   0.00548124   |
|         | (↓ 0.00014704) | (↓ 0.00017289) | (↓ 0.00019750) | (↓ 0.00026760) | (↓ 0.00053263) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00002277   |   0.00006161   |   0.00011998   |   0.00072103   |   0.00292582   |
|         | (↓ 0.00000121) | (↓ 0.00000233) | (↓ 0.00000183) | (↓ 0.00001043) | (↓ 0.00015294) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00021754   |   0.00022681   |   0.00023457   |   0.00026890   |   0.00035578   |
|         | (↓ 0.00001082) | (↓ 0.00000675) | (↓ 0.00000706) | (↓ 0.00000965) | (↓ 0.00000657) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000666   |   0.00010563   |   0.00067427   |   0.00113076   |   0.00166977   |
|         | (↓ 0.00000072) | (↓ 0.00001309) | (↓ 0.00027844) | (↓ 0.00047926) | (↓ 0.00031028) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008524   |   0.00007991   |   0.00007668   |   0.00008074   |   0.00008405   |
|         | (↓ 0.00000474) | (↓ 0.00000485) | (↓ 0.00000407) | (↓ 0.00000313) | (↓ 0.00000275) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00072252   |    0.00097557   |    0.00133021   |   0.00186411   |   0.00209002   |
|         | (↓ -0.00023279) | (↓ -0.00029904) | (↓ -0.00028642) | (↓ 0.00056878) | (↓ 0.00035672) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004331   |   0.00003741   |   0.00003026   |   0.00002414   |   0.00002084   |
|         | (↓ 0.00000558) | (↓ 0.00000373) | (↓ 0.00000346) | (↓ 0.00000195) | (↓ 0.00000052) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.00002555   |   0.00003050   |   0.00002423   |   0.00003099   |   0.00019222   |
|         | (↓ -0.00000250) | (↓ 0.00000291) | (↓ 0.00000191) | (↓ 0.00000060) | (↓ 0.00002727) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-27 23:14:09,238 - block_trainer.py[357] - INFO: epoch 19 (409.889085s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00214618   |   0.00239871   |   0.00287163   |   0.00369021   |   0.00495501   |
|         | (↓ 0.00015877) | (↓ 0.00017592) | (↓ 0.00021122) | (↓ 0.00027414) | (↓ 0.00052623) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00002177   |   0.00005957   |   0.00011820   |   0.00069074   |   0.00257708   |
|         | (↓ 0.00000101) | (↓ 0.00000204) | (↓ 0.00000178) | (↓ 0.00003030) | (↓ 0.00034874) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00020816   |   0.00021602   |   0.00022567   |   0.00026203   |   0.00035023   |
|         | (↓ 0.00000938) | (↓ 0.00001079) | (↓ 0.00000890) | (↓ 0.00000688) | (↓ 0.00000555) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000625   |   0.00009612   |   0.00056823   |   0.00105680   |   0.00163325   |
|         | (↓ 0.00000041) | (↓ 0.00000951) | (↓ 0.00010604) | (↓ 0.00007397) | (↓ 0.00003652) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008430   |   0.00007847   |   0.00007450   |   0.00007846   |   0.00008283   |
|         | (↓ 0.00000093) | (↓ 0.00000143) | (↓ 0.00000218) | (↓ 0.00000228) | (↓ 0.00000122) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00035603   |   0.00032038   |   0.00042571   |   0.00171360   |   0.00169746   |
|         | (↓ 0.00036649) | (↓ 0.00065519) | (↓ 0.00090450) | (↓ 0.00015051) | (↓ 0.00039256) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-6 |   0.00004281   |   0.00003565   |   0.00002968   |    0.00002428   |   0.00002034   |
|         | (↓ 0.00000051) | (↓ 0.00000176) | (↓ 0.00000058) | (↓ -0.00000013) | (↓ 0.00000051) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-7 |   0.00002474   |    0.00003511   |    0.00002750   |   0.00002779   |   0.00016435   |
|         | (↓ 0.00000081) | (↓ -0.00000461) | (↓ -0.00000327) | (↓ 0.00000320) | (↓ 0.00002787) |
+---------+----------------+-----------------+-----------------+----------------+----------------+

2023-06-27 23:20:59,259 - block_trainer.py[357] - INFO: epoch 20 (410.020489s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00204553   |   0.00228806   |   0.00272640   |   0.00349533   |   0.00452803   |
|         | (↓ 0.00010065) | (↓ 0.00011065) | (↓ 0.00014523) | (↓ 0.00019488) | (↓ 0.00042698) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00002148   |   0.00005818   |   0.00011690   |   0.00063124   |   0.00256177   |
|         | (↓ 0.00000029) | (↓ 0.00000139) | (↓ 0.00000131) | (↓ 0.00005950) | (↓ 0.00001530) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00020445   |   0.00021106   |   0.00022063   |   0.00025823   |   0.00034810   |
|         | (↓ 0.00000371) | (↓ 0.00000495) | (↓ 0.00000504) | (↓ 0.00000380) | (↓ 0.00000213) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |   0.00000604   |    0.00012245   |    0.00088116   |    0.00124492   |   0.00139214   |
|         | (↓ 0.00000021) | (↓ -0.00002632) | (↓ -0.00031293) | (↓ -0.00018812) | (↓ 0.00024110) |
+---------+----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008388   |   0.00007824   |   0.00007360   |   0.00007681   |   0.00008178   |
|         | (↓ 0.00000042) | (↓ 0.00000024) | (↓ 0.00000090) | (↓ 0.00000165) | (↓ 0.00000105) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00037655   |    0.00056736   |    0.00093954   |   0.00129429   |   0.00141587   |
|         | (↓ -0.00002052) | (↓ -0.00024699) | (↓ -0.00051382) | (↓ 0.00041930) | (↓ 0.00028159) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004134   |   0.00003530   |   0.00002863   |   0.00002349   |   0.00001975   |
|         | (↓ 0.00000146) | (↓ 0.00000034) | (↓ 0.00000105) | (↓ 0.00000079) | (↓ 0.00000059) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00002155   |   0.00002547   |   0.00001908   |   0.00002723   |   0.00014153   |
|         | (↓ 0.00000319) | (↓ 0.00000964) | (↓ 0.00000842) | (↓ 0.00000056) | (↓ 0.00002282) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 23:27:49,014 - block_trainer.py[357] - INFO: epoch 21 (409.754977s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00195459   |   0.00218477   |   0.00258666   |   0.00330074   |   0.00413170   |
|         | (↓ 0.00009094) | (↓ 0.00010329) | (↓ 0.00013974) | (↓ 0.00019459) | (↓ 0.00039633) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-1 |   0.00002137   |   0.00005725   |   0.00011589   |    0.00063309   |   0.00220956   |
|         | (↓ 0.00000011) | (↓ 0.00000093) | (↓ 0.00000101) | (↓ -0.00000185) | (↓ 0.00035222) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00020627   |    0.00021404   |    0.00022393   |    0.00025862   |    0.00035096   |
|         | (↓ -0.00000182) | (↓ -0.00000298) | (↓ -0.00000330) | (↓ -0.00000039) | (↓ -0.00000286) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-3 |   0.00000583   |   0.00007953   |   0.00038769   |   0.00098639   |    0.00149563   |
|         | (↓ 0.00000022) | (↓ 0.00004292) | (↓ 0.00049347) | (↓ 0.00025853) | (↓ -0.00010349) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00007773   |   0.00007416   |   0.00007279   |   0.00007632   |   0.00008084   |
|         | (↓ 0.00000615) | (↓ 0.00000407) | (↓ 0.00000081) | (↓ 0.00000049) | (↓ 0.00000095) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-5 |    0.00046443   |   0.00033399   |   0.00042838   |   0.00127449   |   0.00135315   |
|         | (↓ -0.00008788) | (↓ 0.00023338) | (↓ 0.00051116) | (↓ 0.00001980) | (↓ 0.00006272) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003499   |   0.00003087   |   0.00002607   |   0.00002174   |   0.00001935   |
|         | (↓ 0.00000635) | (↓ 0.00000443) | (↓ 0.00000256) | (↓ 0.00000175) | (↓ 0.00000040) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+----------------+----------------+
| block-7 |    0.00002367   |   0.00001582   |    0.00002003   |   0.00002320   |   0.00011616   |
|         | (↓ -0.00000212) | (↓ 0.00000965) | (↓ -0.00000095) | (↓ 0.00000403) | (↓ 0.00002537) |
+---------+-----------------+----------------+-----------------+----------------+----------------+

2023-06-27 23:34:40,015 - block_trainer.py[357] - INFO: epoch 22 (411.000646s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00189271   |   0.00211411   |   0.00248873   |   0.00314844   |   0.00379349   |
|         | (↓ 0.00006188) | (↓ 0.00007066) | (↓ 0.00009794) | (↓ 0.00015229) | (↓ 0.00033821) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-1 |   0.00002110   |   0.00005650   |   0.00011495   |   0.00060491   |    0.00229217   |
|         | (↓ 0.00000027) | (↓ 0.00000075) | (↓ 0.00000094) | (↓ 0.00002818) | (↓ -0.00008262) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00020358   |   0.00021280   |   0.00022272   |   0.00025775   |   0.00034975   |
|         | (↓ 0.00000269) | (↓ 0.00000124) | (↓ 0.00000121) | (↓ 0.00000087) | (↓ 0.00000121) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-3 |   0.00000578   |    0.00009854   |    0.00062407   |   0.00082126   |   0.00111001   |
|         | (↓ 0.00000005) | (↓ -0.00001901) | (↓ -0.00023637) | (↓ 0.00016513) | (↓ 0.00038562) |
+---------+----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00007740   |   0.00007304   |   0.00007013   |   0.00007368   |   0.00007943   |
|         | (↓ 0.00000032) | (↓ 0.00000112) | (↓ 0.00000266) | (↓ 0.00000263) | (↓ 0.00000141) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00047576   |    0.00048518   |    0.00073091   |   0.00096064   |   0.00098804   |
|         | (↓ -0.00001133) | (↓ -0.00015119) | (↓ -0.00030253) | (↓ 0.00031385) | (↓ 0.00036510) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-6 |    0.00003575   |    0.00003142   |    0.00002615   |   0.00002159   |   0.00001872   |
|         | (↓ -0.00000075) | (↓ -0.00000055) | (↓ -0.00000008) | (↓ 0.00000015) | (↓ 0.00000062) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+-----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+-----------------+----------------+-----------------+----------------+
| block-7 |   0.00002140   |    0.00001725   |   0.00001779   |    0.00002345   |   0.00009552   |
|         | (↓ 0.00000228) | (↓ -0.00000143) | (↓ 0.00000224) | (↓ -0.00000025) | (↓ 0.00002064) |
+---------+----------------+-----------------+----------------+-----------------+----------------+

2023-06-27 23:41:30,207 - block_trainer.py[357] - INFO: epoch 23 (410.191848s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00174688   |   0.00196325   |   0.00231966   |   0.00292801   |   0.00341457   |
|         | (↓ 0.00014583) | (↓ 0.00015086) | (↓ 0.00016907) | (↓ 0.00022044) | (↓ 0.00037893) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001967   |   0.00005409   |   0.00011190   |   0.00057324   |   0.00199852   |
|         | (↓ 0.00000144) | (↓ 0.00000241) | (↓ 0.00000305) | (↓ 0.00003167) | (↓ 0.00029366) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00018906   |   0.00019724   |   0.00020952   |   0.00024692   |   0.00034480   |
|         | (↓ 0.00001453) | (↓ 0.00001556) | (↓ 0.00001319) | (↓ 0.00001083) | (↓ 0.00000494) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-3 |   0.00000528   |   0.00008136   |   0.00043801   |    0.00091762   |   0.00108885   |
|         | (↓ 0.00000049) | (↓ 0.00001718) | (↓ 0.00018605) | (↓ -0.00009637) | (↓ 0.00002116) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00007358   |   0.00007055   |   0.00006845   |   0.00007245   |   0.00007828   |
|         | (↓ 0.00000382) | (↓ 0.00000249) | (↓ 0.00000168) | (↓ 0.00000124) | (↓ 0.00000115) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-5 |   0.00037218   |   0.00026898   |   0.00064604   |    0.00096763   |   0.00086952   |
|         | (↓ 0.00010357) | (↓ 0.00021620) | (↓ 0.00008487) | (↓ -0.00000698) | (↓ 0.00011853) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003335   |   0.00002944   |   0.00002424   |   0.00002044   |   0.00001845   |
|         | (↓ 0.00000239) | (↓ 0.00000199) | (↓ 0.00000191) | (↓ 0.00000114) | (↓ 0.00000027) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-7 |   0.00001626   |    0.00002009   |    0.00001780   |   0.00002020   |   0.00008120   |
|         | (↓ 0.00000513) | (↓ -0.00000283) | (↓ -0.00000001) | (↓ 0.00000325) | (↓ 0.00001432) |
+---------+----------------+-----------------+-----------------+----------------+----------------+

2023-06-27 23:48:20,320 - block_trainer.py[357] - INFO: epoch 24 (410.112881s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00164776   |   0.00185651   |   0.00220123   |   0.00274771   |   0.00309379   |
|         | (↓ 0.00009912) | (↓ 0.00010674) | (↓ 0.00011842) | (↓ 0.00018029) | (↓ 0.00032077) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001905   |   0.00005319   |   0.00011062   |   0.00054514   |   0.00186028   |
|         | (↓ 0.00000062) | (↓ 0.00000090) | (↓ 0.00000128) | (↓ 0.00002810) | (↓ 0.00013824) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00019002   |    0.00019820   |    0.00021022   |   0.00024554   |   0.00034148   |
|         | (↓ -0.00000096) | (↓ -0.00000096) | (↓ -0.00000070) | (↓ 0.00000139) | (↓ 0.00000333) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000506   |   0.00007869   |   0.00043261   |   0.00076220   |   0.00095880   |
|         | (↓ 0.00000022) | (↓ 0.00000267) | (↓ 0.00000540) | (↓ 0.00015543) | (↓ 0.00013005) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00007752   |    0.00007321   |    0.00006900   |   0.00007091   |   0.00007779   |
|         | (↓ -0.00000393) | (↓ -0.00000266) | (↓ -0.00000056) | (↓ 0.00000153) | (↓ 0.00000049) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-5 |   0.00020002   |    0.00027802   |   0.00027489   |   0.00068100   |   0.00070006   |
|         | (↓ 0.00017216) | (↓ -0.00000904) | (↓ 0.00037115) | (↓ 0.00028663) | (↓ 0.00016946) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-6 |   0.00003185   |   0.00002805   |   0.00002389   |    0.00002060   |   0.00001807   |
|         | (↓ 0.00000150) | (↓ 0.00000138) | (↓ 0.00000035) | (↓ -0.00000016) | (↓ 0.00000039) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00001443   |   0.00001562   |   0.00001643   |   0.00001851   |   0.00006445   |
|         | (↓ 0.00000183) | (↓ 0.00000447) | (↓ 0.00000137) | (↓ 0.00000169) | (↓ 0.00001676) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-27 23:55:10,966 - block_trainer.py[357] - INFO: epoch 25 (410.645909s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-0 |    0.00165895   |    0.00186504   |   0.00219354   |   0.00268708   |   0.00291968   |
|         | (↓ -0.00001119) | (↓ -0.00000852) | (↓ 0.00000769) | (↓ 0.00006063) | (↓ 0.00017412) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00002004   |    0.00005376   |    0.00011070   |    0.00055978   |   0.00174644   |
|         | (↓ -0.00000099) | (↓ -0.00000057) | (↓ -0.00000008) | (↓ -0.00001464) | (↓ 0.00011384) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |   0.00018974   |    0.00019868   |    0.00021106   |    0.00024778   |    0.00034679   |
|         | (↓ 0.00000028) | (↓ -0.00000048) | (↓ -0.00000083) | (↓ -0.00000224) | (↓ -0.00000531) |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-3 |    0.00000529   |    0.00008632   |    0.00047540   |   0.00075632   |   0.00091990   |
|         | (↓ -0.00000022) | (↓ -0.00000763) | (↓ -0.00004279) | (↓ 0.00000587) | (↓ 0.00003890) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00007335   |   0.00007031   |   0.00006786   |   0.00007076   |   0.00007709   |
|         | (↓ 0.00000417) | (↓ 0.00000289) | (↓ 0.00000114) | (↓ 0.00000015) | (↓ 0.00000069) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+----------------+----------------+
| block-5 |    0.00023996   |   0.00027659   |    0.00043928   |   0.00065781   |   0.00058856   |
|         | (↓ -0.00003994) | (↓ 0.00000143) | (↓ -0.00016440) | (↓ 0.00002319) | (↓ 0.00011150) |
+---------+-----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-6 |   0.00003144   |    0.00002856   |   0.00002345   |   0.00001973   |   0.00001774   |
|         | (↓ 0.00000041) | (↓ -0.00000051) | (↓ 0.00000044) | (↓ 0.00000088) | (↓ 0.00000032) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-7 |   0.00001427   |    0.00001666   |   0.00001262   |   0.00001709   |   0.00005462   |
|         | (↓ 0.00000016) | (↓ -0.00000104) | (↓ 0.00000381) | (↓ 0.00000142) | (↓ 0.00000982) |
+---------+----------------+-----------------+----------------+----------------+----------------+

2023-06-28 00:02:01,130 - block_trainer.py[357] - INFO: epoch 26 (410.163482s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00156849   |   0.00176978   |   0.00208887   |   0.00252935   |   0.00266950   |
|         | (↓ 0.00009046) | (↓ 0.00009526) | (↓ 0.00010467) | (↓ 0.00015774) | (↓ 0.00025018) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001862   |   0.00005172   |   0.00010809   |   0.00052138   |   0.00153739   |
|         | (↓ 0.00000142) | (↓ 0.00000203) | (↓ 0.00000261) | (↓ 0.00003840) | (↓ 0.00020905) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00018692   |   0.00019267   |   0.00020604   |   0.00024314   |   0.00034193   |
|         | (↓ 0.00000282) | (↓ 0.00000600) | (↓ 0.00000502) | (↓ 0.00000464) | (↓ 0.00000486) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000480   |   0.00007484   |   0.00041399   |   0.00061862   |   0.00078782   |
|         | (↓ 0.00000048) | (↓ 0.00001148) | (↓ 0.00006141) | (↓ 0.00013770) | (↓ 0.00013209) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00006797   |   0.00006513   |   0.00006326   |   0.00006705   |   0.00007597   |
|         | (↓ 0.00000537) | (↓ 0.00000518) | (↓ 0.00000460) | (↓ 0.00000371) | (↓ 0.00000112) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00043964   |    0.00033719   |   0.00040813   |   0.00053305   |   0.00045570   |
|         | (↓ -0.00019968) | (↓ -0.00006060) | (↓ 0.00003115) | (↓ 0.00012476) | (↓ 0.00013286) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00002913   |   0.00002634   |   0.00002200   |   0.00001843   |   0.00001690   |
|         | (↓ 0.00000231) | (↓ 0.00000222) | (↓ 0.00000144) | (↓ 0.00000130) | (↓ 0.00000084) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-7 |   0.00001091   |   0.00001128   |   0.00000981   |    0.00002558   |   0.00004165   |
|         | (↓ 0.00000336) | (↓ 0.00000538) | (↓ 0.00000281) | (↓ -0.00000848) | (↓ 0.00001297) |
+---------+----------------+----------------+----------------+-----------------+----------------+

2023-06-28 00:08:50,680 - block_trainer.py[357] - INFO: epoch 27 (409.550055s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00147209   |   0.00167884   |   0.00198708   |   0.00237110   |   0.00243905   |
|         | (↓ 0.00009640) | (↓ 0.00009095) | (↓ 0.00010179) | (↓ 0.00015825) | (↓ 0.00023044) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001829   |   0.00005088   |   0.00010696   |   0.00049389   |   0.00142806   |
|         | (↓ 0.00000034) | (↓ 0.00000085) | (↓ 0.00000113) | (↓ 0.00002749) | (↓ 0.00010933) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00017747   |   0.00018586   |   0.00020222   |   0.00023969   |   0.00033994   |
|         | (↓ 0.00000944) | (↓ 0.00000681) | (↓ 0.00000383) | (↓ 0.00000345) | (↓ 0.00000199) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-3 |   0.00000464   |   0.00007390   |   0.00034896   |    0.00063099   |   0.00071690   |
|         | (↓ 0.00000017) | (↓ 0.00000094) | (↓ 0.00006503) | (↓ -0.00001237) | (↓ 0.00007091) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-4 |    0.00006918   |    0.00006640   |    0.00006416   |    0.00006724   |   0.00007473   |
|         | (↓ -0.00000121) | (↓ -0.00000128) | (↓ -0.00000090) | (↓ -0.00000019) | (↓ 0.00000124) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-5 |   0.00019327   |   0.00026859   |    0.00054637   |   0.00039418   |   0.00033692   |
|         | (↓ 0.00024637) | (↓ 0.00006860) | (↓ -0.00013824) | (↓ 0.00013887) | (↓ 0.00011878) |
+---------+----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-6 |   0.00002878   |   0.00002568   |   0.00002158   |    0.00001853   |    0.00001709   |
|         | (↓ 0.00000035) | (↓ 0.00000066) | (↓ 0.00000043) | (↓ -0.00000010) | (↓ -0.00000019) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.00001102   |    0.00001131   |    0.00001115   |   0.00001385   |   0.00003540   |
|         | (↓ -0.00000010) | (↓ -0.00000003) | (↓ -0.00000134) | (↓ 0.00001173) | (↓ 0.00000625) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2023-06-28 00:15:44,229 - block_trainer.py[357] - INFO: epoch 28 (413.549371s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00141914   |   0.00162807   |   0.00192821   |   0.00226406   |   0.00227645   |
|         | (↓ 0.00005294) | (↓ 0.00005076) | (↓ 0.00005887) | (↓ 0.00010703) | (↓ 0.00016261) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001771   |   0.00004983   |   0.00010569   |   0.00047547   |   0.00129156   |
|         | (↓ 0.00000058) | (↓ 0.00000105) | (↓ 0.00000128) | (↓ 0.00001842) | (↓ 0.00013650) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00017378   |   0.00018264   |   0.00019901   |   0.00023642   |   0.00033912   |
|         | (↓ 0.00000369) | (↓ 0.00000323) | (↓ 0.00000321) | (↓ 0.00000327) | (↓ 0.00000082) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-3 |   0.00000450   |   0.00007054   |    0.00036040   |   0.00052422   |   0.00065440   |
|         | (↓ 0.00000014) | (↓ 0.00000336) | (↓ -0.00001144) | (↓ 0.00010676) | (↓ 0.00006250) |
+---------+----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00006571   |   0.00006283   |   0.00006131   |   0.00006506   |   0.00007412   |
|         | (↓ 0.00000347) | (↓ 0.00000357) | (↓ 0.00000285) | (↓ 0.00000218) | (↓ 0.00000061) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-5 |    0.00027175   |   0.00019030   |   0.00010868   |   0.00036643   |   0.00028521   |
|         | (↓ -0.00007848) | (↓ 0.00007828) | (↓ 0.00043769) | (↓ 0.00002775) | (↓ 0.00005171) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00002590   |   0.00002384   |   0.00002025   |   0.00001763   |   0.00001629   |
|         | (↓ 0.00000288) | (↓ 0.00000184) | (↓ 0.00000133) | (↓ 0.00000090) | (↓ 0.00000080) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+-----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+-----------------+----------------+
| block-7 |    0.00001264   |   0.00001069   |    0.00001221   |    0.00001420   |   0.00002815   |
|         | (↓ -0.00000162) | (↓ 0.00000061) | (↓ -0.00000105) | (↓ -0.00000035) | (↓ 0.00000725) |
+---------+-----------------+----------------+-----------------+-----------------+----------------+

2023-06-28 00:22:34,090 - block_trainer.py[357] - INFO: epoch 29 (409.860597s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00139232   |   0.00159988   |   0.00188692   |   0.00217589   |   0.00214968   |
|         | (↓ 0.00002682) | (↓ 0.00002819) | (↓ 0.00004129) | (↓ 0.00008818) | (↓ 0.00012677) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-1 |    0.00001792   |   0.00004933   |   0.00010477   |   0.00046345   |   0.00123564   |
|         | (↓ -0.00000021) | (↓ 0.00000050) | (↓ 0.00000092) | (↓ 0.00001202) | (↓ 0.00005592) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00017210   |   0.00017827   |   0.00019546   |   0.00023528   |   0.00033826   |
|         | (↓ 0.00000168) | (↓ 0.00000437) | (↓ 0.00000355) | (↓ 0.00000115) | (↓ 0.00000086) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000453   |   0.00006871   |   0.00032679   |   0.00047478   |   0.00051170   |
|         | (↓ -0.00000003) | (↓ 0.00000183) | (↓ 0.00003361) | (↓ 0.00004944) | (↓ 0.00014270) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00006985   |    0.00006646   |    0.00006283   |   0.00006442   |   0.00007365   |
|         | (↓ -0.00000414) | (↓ -0.00000362) | (↓ -0.00000152) | (↓ 0.00000064) | (↓ 0.00000047) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-5 |   0.00018004   |    0.00025590   |    0.00028779   |   0.00029095   |   0.00023092   |
|         | (↓ 0.00009171) | (↓ -0.00006559) | (↓ -0.00017911) | (↓ 0.00007549) | (↓ 0.00005429) |
+---------+----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00002594   |    0.00002467   |    0.00002089   |    0.00001784   |    0.00001641   |
|         | (↓ -0.00000003) | (↓ -0.00000083) | (↓ -0.00000065) | (↓ -0.00000021) | (↓ -0.00000012) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+----------------+-----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+-----------------+----------------+-----------------+----------------+
| block-7 |   0.00001046   |    0.00001108   |   0.00001127   |    0.00001514   |   0.00002269   |
|         | (↓ 0.00000218) | (↓ -0.00000038) | (↓ 0.00000094) | (↓ -0.00000095) | (↓ 0.00000545) |
+---------+----------------+-----------------+----------------+-----------------+----------------+

2023-06-28 00:29:23,771 - block_trainer.py[357] - INFO: epoch 30 (409.680834s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00137016   |   0.00157655   |   0.00185568   |   0.00209926   |   0.00204593   |
|         | (↓ 0.00002216) | (↓ 0.00002333) | (↓ 0.00003124) | (↓ 0.00007663) | (↓ 0.00010376) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-1 |    0.00001807   |   0.00004876   |   0.00010389   |   0.00043846   |   0.00108040   |
|         | (↓ -0.00000015) | (↓ 0.00000056) | (↓ 0.00000088) | (↓ 0.00002499) | (↓ 0.00015524) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-2 |    0.00017375   |    0.00017954   |    0.00019680   |   0.00023438   |    0.00033949   |
|         | (↓ -0.00000165) | (↓ -0.00000128) | (↓ -0.00000134) | (↓ 0.00000090) | (↓ -0.00000123) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-3 |   0.00000452   |    0.00007184   |   0.00030624   |   0.00039982   |   0.00050644   |
|         | (↓ 0.00000001) | (↓ -0.00000313) | (↓ 0.00002055) | (↓ 0.00007496) | (↓ 0.00000526) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-4 |   0.00006487   |   0.00006215   |   0.00006049   |   0.00006437   |    0.00007398   |
|         | (↓ 0.00000498) | (↓ 0.00000431) | (↓ 0.00000233) | (↓ 0.00000005) | (↓ -0.00000033) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-5 |    0.00021792   |   0.00017519   |   0.00021773   |   0.00026665   |   0.00018667   |
|         | (↓ -0.00003788) | (↓ 0.00008070) | (↓ 0.00007006) | (↓ 0.00002430) | (↓ 0.00004424) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00002521   |   0.00002342   |   0.00001994   |   0.00001715   |   0.00001596   |
|         | (↓ 0.00000073) | (↓ 0.00000125) | (↓ 0.00000095) | (↓ 0.00000069) | (↓ 0.00000045) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+----------------+----------------+
| block-7 |    0.00001144   |   0.00000989   |    0.00001129   |   0.00001256   |   0.00001839   |
|         | (↓ -0.00000098) | (↓ 0.00000119) | (↓ -0.00000002) | (↓ 0.00000258) | (↓ 0.00000431) |
+---------+-----------------+----------------+-----------------+----------------+----------------+

2023-06-28 00:36:13,428 - block_trainer.py[357] - INFO: epoch 31 (409.656493s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00132680   |   0.00152527   |   0.00179825   |   0.00200208   |   0.00192507   |
|         | (↓ 0.00004336) | (↓ 0.00005128) | (↓ 0.00005743) | (↓ 0.00009717) | (↓ 0.00012085) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001798   |   0.00004798   |   0.00010290   |   0.00042060   |   0.00100748   |
|         | (↓ 0.00000009) | (↓ 0.00000078) | (↓ 0.00000099) | (↓ 0.00001787) | (↓ 0.00007292) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00017293   |   0.00017898   |   0.00019566   |   0.00023417   |   0.00033808   |
|         | (↓ 0.00000082) | (↓ 0.00000057) | (↓ 0.00000113) | (↓ 0.00000021) | (↓ 0.00000140) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000442   |   0.00006547   |   0.00030099   |   0.00037108   |   0.00040716   |
|         | (↓ 0.00000010) | (↓ 0.00000637) | (↓ 0.00000525) | (↓ 0.00002874) | (↓ 0.00009927) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00006336   |   0.00006203   |   0.00006027   |   0.00006325   |   0.00007358   |
|         | (↓ 0.00000151) | (↓ 0.00000012) | (↓ 0.00000022) | (↓ 0.00000112) | (↓ 0.00000040) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-5 |   0.00013591   |   0.00015190   |    0.00030011   |   0.00017323   |   0.00016320   |
|         | (↓ 0.00008201) | (↓ 0.00002329) | (↓ -0.00008238) | (↓ 0.00009341) | (↓ 0.00002347) |
+---------+----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00002347   |   0.00002169   |   0.00001889   |   0.00001671   |   0.00001591   |
|         | (↓ 0.00000174) | (↓ 0.00000173) | (↓ 0.00000105) | (↓ 0.00000043) | (↓ 0.00000006) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-7 |    0.00001237   |    0.00001057   |   0.00000946   |   0.00001200   |   0.00001505   |
|         | (↓ -0.00000093) | (↓ -0.00000068) | (↓ 0.00000183) | (↓ 0.00000056) | (↓ 0.00000333) |
+---------+-----------------+-----------------+----------------+----------------+----------------+

2023-06-28 00:43:03,086 - block_trainer.py[357] - INFO: epoch 32 (409.657855s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00125426   |   0.00144984   |   0.00171289   |   0.00187862   |   0.00179176   |
|         | (↓ 0.00007253) | (↓ 0.00007543) | (↓ 0.00008537) | (↓ 0.00012347) | (↓ 0.00013331) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001667   |   0.00004557   |   0.00010022   |   0.00039724   |   0.00095511   |
|         | (↓ 0.00000131) | (↓ 0.00000241) | (↓ 0.00000268) | (↓ 0.00002335) | (↓ 0.00005237) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00016466   |   0.00017222   |   0.00019149   |   0.00023027   |   0.00033462   |
|         | (↓ 0.00000827) | (↓ 0.00000676) | (↓ 0.00000418) | (↓ 0.00000389) | (↓ 0.00000346) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000411   |   0.00006160   |   0.00023738   |   0.00031491   |   0.00034699   |
|         | (↓ 0.00000031) | (↓ 0.00000387) | (↓ 0.00006361) | (↓ 0.00005617) | (↓ 0.00006017) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00006236   |   0.00006025   |   0.00005814   |   0.00006122   |   0.00007218   |
|         | (↓ 0.00000100) | (↓ 0.00000179) | (↓ 0.00000213) | (↓ 0.00000203) | (↓ 0.00000140) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00012230   |   0.00012796   |   0.00013033   |   0.00013009   |   0.00009180   |
|         | (↓ 0.00001360) | (↓ 0.00002394) | (↓ 0.00016978) | (↓ 0.00004314) | (↓ 0.00007140) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00002207   |   0.00002070   |   0.00001800   |   0.00001595   |   0.00001531   |
|         | (↓ 0.00000140) | (↓ 0.00000099) | (↓ 0.00000089) | (↓ 0.00000076) | (↓ 0.00000060) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |   0.00001208   |    0.00001405   |    0.00000986   |    0.00001322   |   0.00001259   |
|         | (↓ 0.00000029) | (↓ -0.00000348) | (↓ -0.00000040) | (↓ -0.00000122) | (↓ 0.00000246) |
+---------+----------------+-----------------+-----------------+-----------------+----------------+

2023-06-28 00:49:53,778 - block_trainer.py[357] - INFO: epoch 33 (410.691468s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-0 |    0.00127293   |    0.00146110   |    0.00171749   |   0.00184663   |   0.00175013   |
|         | (↓ -0.00001866) | (↓ -0.00001126) | (↓ -0.00000460) | (↓ 0.00003199) | (↓ 0.00004163) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-1 |    0.00001718   |   0.00004518   |   0.00009968   |   0.00038560   |   0.00090033   |
|         | (↓ -0.00000051) | (↓ 0.00000039) | (↓ 0.00000054) | (↓ 0.00001164) | (↓ 0.00005478) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00016748   |    0.00017288   |    0.00019296   |    0.00023200   |    0.00033684   |
|         | (↓ -0.00000283) | (↓ -0.00000066) | (↓ -0.00000148) | (↓ -0.00000173) | (↓ -0.00000221) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-3 |    0.00000419   |    0.00006171   |    0.00025416   |   0.00029895   |   0.00033335   |
|         | (↓ -0.00000008) | (↓ -0.00000011) | (↓ -0.00001677) | (↓ 0.00001595) | (↓ 0.00001364) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00006283   |    0.00006083   |    0.00005881   |    0.00006204   |    0.00007280   |
|         | (↓ -0.00000047) | (↓ -0.00000058) | (↓ -0.00000068) | (↓ -0.00000082) | (↓ -0.00000062) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+-----------------+-----------------+-----------------+
|         |       0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00017085   |   0.00010508   |    0.00015508   |    0.00015709   |    0.00009871   |
|         | (↓ -0.00004855) | (↓ 0.00002288) | (↓ -0.00002475) | (↓ -0.00002700) | (↓ -0.00000692) |
+---------+-----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-6 |   0.00002152   |   0.00002033   |   0.00001771   |   0.00001589   |    0.00001536   |
|         | (↓ 0.00000055) | (↓ 0.00000036) | (↓ 0.00000029) | (↓ 0.00000006) | (↓ -0.00000005) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-7 |   0.00000955   |   0.00001036   |    0.00001040   |   0.00001245   |   0.00001049   |
|         | (↓ 0.00000253) | (↓ 0.00000369) | (↓ -0.00000054) | (↓ 0.00000078) | (↓ 0.00000210) |
+---------+----------------+----------------+-----------------+----------------+----------------+

2023-06-28 00:56:44,273 - block_trainer.py[357] - INFO: epoch 34 (410.494917s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00117938   |   0.00136519   |   0.00161345   |   0.00171429   |   0.00161992   |
|         | (↓ 0.00009354) | (↓ 0.00009591) | (↓ 0.00010405) | (↓ 0.00013233) | (↓ 0.00013021) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001642   |   0.00004342   |   0.00009748   |   0.00036655   |   0.00082253   |
|         | (↓ 0.00000076) | (↓ 0.00000176) | (↓ 0.00000221) | (↓ 0.00001905) | (↓ 0.00007780) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00015864   |   0.00016656   |   0.00018800   |   0.00022647   |   0.00033040   |
|         | (↓ 0.00000884) | (↓ 0.00000632) | (↓ 0.00000496) | (↓ 0.00000553) | (↓ 0.00000644) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000396   |   0.00005940   |   0.00019362   |   0.00025112   |   0.00029895   |
|         | (↓ 0.00000024) | (↓ 0.00000231) | (↓ 0.00006054) | (↓ 0.00004783) | (↓ 0.00003440) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00006109   |   0.00005817   |   0.00005697   |   0.00006029   |   0.00007151   |
|         | (↓ 0.00000175) | (↓ 0.00000266) | (↓ 0.00000184) | (↓ 0.00000175) | (↓ 0.00000128) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-5 |   0.00013563   |    0.00011685   |    0.00015707   |   0.00013117   |   0.00008205   |
|         | (↓ 0.00003522) | (↓ -0.00001177) | (↓ -0.00000199) | (↓ 0.00002592) | (↓ 0.00001666) |
+---------+----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001966   |   0.00001987   |   0.00001756   |   0.00001559   |   0.00001485   |
|         | (↓ 0.00000185) | (↓ 0.00000047) | (↓ 0.00000015) | (↓ 0.00000031) | (↓ 0.00000050) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.00001265   |   0.00000900   |   0.00000934   |   0.00001211   |   0.00000901   |
|         | (↓ -0.00000310) | (↓ 0.00000136) | (↓ 0.00000106) | (↓ 0.00000033) | (↓ 0.00000148) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-28 01:03:33,786 - block_trainer.py[357] - INFO: epoch 35 (409.513183s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-0 |    0.00118611   |    0.00136769   |   0.00160594   |   0.00167875   |   0.00158304   |
|         | (↓ -0.00000673) | (↓ -0.00000250) | (↓ 0.00000751) | (↓ 0.00003555) | (↓ 0.00003688) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-1 |    0.00001673   |   0.00004289   |   0.00009621   |   0.00035263   |   0.00078978   |
|         | (↓ -0.00000030) | (↓ 0.00000053) | (↓ 0.00000126) | (↓ 0.00001392) | (↓ 0.00003275) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-2 |   0.00015572   |   0.00016331   |   0.00018557   |   0.00022601   |    0.00033218   |
|         | (↓ 0.00000293) | (↓ 0.00000326) | (↓ 0.00000243) | (↓ 0.00000046) | (↓ -0.00000178) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-3 |    0.00000408   |    0.00006016   |   0.00017629   |   0.00020027   |   0.00026600   |
|         | (↓ -0.00000013) | (↓ -0.00000076) | (↓ 0.00001733) | (↓ 0.00005085) | (↓ 0.00003296) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00005975   |   0.00005767   |   0.00005593   |   0.00005911   |   0.00007112   |
|         | (↓ 0.00000133) | (↓ 0.00000050) | (↓ 0.00000104) | (↓ 0.00000118) | (↓ 0.00000040) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00014734   |    0.00015100   |   0.00013990   |   0.00006417   |   0.00006127   |
|         | (↓ -0.00001171) | (↓ -0.00003415) | (↓ 0.00001717) | (↓ 0.00006701) | (↓ 0.00002079) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00002018   |   0.00001882   |   0.00001686   |   0.00001506   |   0.00001476   |
|         | (↓ -0.00000052) | (↓ 0.00000104) | (↓ 0.00000070) | (↓ 0.00000053) | (↓ 0.00000009) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.00001341   |    0.00000954   |    0.00001194   |    0.00001294   |   0.00000800   |
|         | (↓ -0.00000075) | (↓ -0.00000054) | (↓ -0.00000260) | (↓ -0.00000082) | (↓ 0.00000101) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2023-06-28 01:10:23,310 - block_trainer.py[357] - INFO: epoch 36 (409.523490s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00112810   |   0.00130415   |   0.00152952   |   0.00158145   |   0.00148759   |
|         | (↓ 0.00005802) | (↓ 0.00006353) | (↓ 0.00007642) | (↓ 0.00009730) | (↓ 0.00009545) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001610   |   0.00004169   |   0.00009386   |   0.00034099   |   0.00074799   |
|         | (↓ 0.00000063) | (↓ 0.00000120) | (↓ 0.00000235) | (↓ 0.00001164) | (↓ 0.00004180) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+-----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+-----------------+----------------+
| block-2 |    0.00015625   |   0.00016270   |    0.00018623   |    0.00022621   |   0.00033079   |
|         | (↓ -0.00000053) | (↓ 0.00000061) | (↓ -0.00000066) | (↓ -0.00000020) | (↓ 0.00000139) |
+---------+-----------------+----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000385   |   0.00005672   |   0.00016818   |   0.00018998   |   0.00023712   |
|         | (↓ 0.00000024) | (↓ 0.00000344) | (↓ 0.00000810) | (↓ 0.00001029) | (↓ 0.00002888) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00005990   |   0.00005725   |   0.00005517   |   0.00005886   |   0.00007106   |
|         | (↓ -0.00000014) | (↓ 0.00000042) | (↓ 0.00000076) | (↓ 0.00000025) | (↓ 0.00000006) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+-----------------+-----------------+----------------+
| block-5 |   0.00013273   |   0.00007852   |    0.00016895   |    0.00006739   |   0.00005706   |
|         | (↓ 0.00001461) | (↓ 0.00007247) | (↓ -0.00002906) | (↓ -0.00000322) | (↓ 0.00000421) |
+---------+----------------+----------------+-----------------+-----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00002025   |   0.00001822   |   0.00001626   |   0.00001477   |   0.00001451   |
|         | (↓ -0.00000007) | (↓ 0.00000060) | (↓ 0.00000060) | (↓ 0.00000029) | (↓ 0.00000026) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00001120   |   0.00000852   |   0.00000890   |   0.00001082   |   0.00000711   |
|         | (↓ 0.00000221) | (↓ 0.00000103) | (↓ 0.00000303) | (↓ 0.00000212) | (↓ 0.00000089) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-28 01:17:12,742 - block_trainer.py[357] - INFO: epoch 37 (409.432620s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-0 |    0.00114666   |    0.00131834   |    0.00153669   |   0.00156212   |   0.00147111   |
|         | (↓ -0.00001856) | (↓ -0.00001418) | (↓ -0.00000717) | (↓ 0.00001933) | (↓ 0.00001648) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-1 |    0.00001612   |   0.00004136   |   0.00009258   |   0.00032952   |   0.00071756   |
|         | (↓ -0.00000002) | (↓ 0.00000033) | (↓ 0.00000128) | (↓ 0.00001146) | (↓ 0.00003043) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |   0.00015573   |    0.00016418   |    0.00018751   |    0.00022875   |    0.00033361   |
|         | (↓ 0.00000051) | (↓ -0.00000148) | (↓ -0.00000128) | (↓ -0.00000253) | (↓ -0.00000282) |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000397   |   0.00005398   |   0.00015206   |   0.00018164   |   0.00022120   |
|         | (↓ -0.00000013) | (↓ 0.00000274) | (↓ 0.00001613) | (↓ 0.00000834) | (↓ 0.00001592) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00005691   |   0.00005556   |   0.00005420   |   0.00005817   |   0.00007103   |
|         | (↓ 0.00000299) | (↓ 0.00000169) | (↓ 0.00000097) | (↓ 0.00000068) | (↓ 0.00000003) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-5 |   0.00011311   |    0.00008829   |   0.00010702   |   0.00006653   |   0.00004909   |
|         | (↓ 0.00001962) | (↓ -0.00000976) | (↓ 0.00006194) | (↓ 0.00000086) | (↓ 0.00000798) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001766   |   0.00001757   |   0.00001558   |   0.00001429   |   0.00001422   |
|         | (↓ 0.00000259) | (↓ 0.00000065) | (↓ 0.00000068) | (↓ 0.00000048) | (↓ 0.00000028) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.00001125   |    0.00000926   |    0.00000911   |   0.00000980   |   0.00000656   |
|         | (↓ -0.00000005) | (↓ -0.00000074) | (↓ -0.00000021) | (↓ 0.00000101) | (↓ 0.00000055) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2023-06-28 01:24:02,226 - block_trainer.py[357] - INFO: epoch 38 (409.483401s, 40 blocks still need training), blocks loss: 
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-0 |    0.00114748   |   0.00131565   |   0.00152584   |   0.00153129   |   0.00144843   |
|         | (↓ -0.00000082) | (↓ 0.00000269) | (↓ 0.00001086) | (↓ 0.00003083) | (↓ 0.00002269) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00001657   |    0.00004153   |   0.00009153   |   0.00032183   |   0.00068986   |
|         | (↓ -0.00000045) | (↓ -0.00000017) | (↓ 0.00000105) | (↓ 0.00000769) | (↓ 0.00002770) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00015166   |   0.00015973   |   0.00018532   |   0.00022545   |   0.00033193   |
|         | (↓ 0.00000407) | (↓ 0.00000445) | (↓ 0.00000219) | (↓ 0.00000329) | (↓ 0.00000168) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-3 |   0.00000396   |    0.00005446   |   0.00014484   |   0.00015924   |   0.00020390   |
|         | (↓ 0.00000001) | (↓ -0.00000048) | (↓ 0.00000722) | (↓ 0.00002240) | (↓ 0.00001730) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00005754   |    0.00005601   |    0.00005479   |   0.00005793   |   0.00007064   |
|         | (↓ -0.00000063) | (↓ -0.00000046) | (↓ -0.00000059) | (↓ 0.00000024) | (↓ 0.00000039) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00014142   |    0.00010042   |   0.00008531   |   0.00005160   |   0.00004444   |
|         | (↓ -0.00002831) | (↓ -0.00001213) | (↓ 0.00002171) | (↓ 0.00001494) | (↓ 0.00000465) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-6 |   0.00001666   |   0.00001667   |   0.00001545   |    0.00001429   |   0.00001417   |
|         | (↓ 0.00000100) | (↓ 0.00000091) | (↓ 0.00000014) | (↓ -0.00000001) | (↓ 0.00000005) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.00001133   |   0.00000895   |   0.00000866   |   0.00000876   |   0.00000595   |
|         | (↓ -0.00000008) | (↓ 0.00000030) | (↓ 0.00000046) | (↓ 0.00000104) | (↓ 0.00000061) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-28 01:30:51,983 - block_trainer.py[357] - INFO: epoch 39 (409.756958s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00112219   |   0.00128497   |   0.00148546   |   0.00147541   |   0.00139690   |
|         | (↓ 0.00002528) | (↓ 0.00003067) | (↓ 0.00004037) | (↓ 0.00005588) | (↓ 0.00005152) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001595   |   0.00004093   |   0.00008990   |   0.00031159   |   0.00066202   |
|         | (↓ 0.00000063) | (↓ 0.00000060) | (↓ 0.00000162) | (↓ 0.00001024) | (↓ 0.00002784) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00015122   |   0.00015845   |   0.00018280   |   0.00022332   |   0.00032965   |
|         | (↓ 0.00000045) | (↓ 0.00000127) | (↓ 0.00000252) | (↓ 0.00000214) | (↓ 0.00000228) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000394   |   0.00005330   |   0.00012630   |   0.00014637   |   0.00018595   |
|         | (↓ 0.00000003) | (↓ 0.00000116) | (↓ 0.00001854) | (↓ 0.00001287) | (↓ 0.00001795) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-4 |   0.00005691   |   0.00005515   |   0.00005359   |   0.00005749   |    0.00007089   |
|         | (↓ 0.00000063) | (↓ 0.00000087) | (↓ 0.00000120) | (↓ 0.00000044) | (↓ -0.00000026) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-5 |   0.00009636   |   0.00005128   |    0.00009545   |   0.00004254   |   0.00004008   |
|         | (↓ 0.00004506) | (↓ 0.00004914) | (↓ -0.00001014) | (↓ 0.00000905) | (↓ 0.00000436) |
+---------+----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001666   |   0.00001637   |   0.00001498   |   0.00001380   |   0.00001406   |
|         | (↓ 0.00000000) | (↓ 0.00000029) | (↓ 0.00000047) | (↓ 0.00000049) | (↓ 0.00000012) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00000997   |   0.00000820   |   0.00000786   |   0.00000840   |   0.00000558   |
|         | (↓ 0.00000137) | (↓ 0.00000075) | (↓ 0.00000079) | (↓ 0.00000037) | (↓ 0.00000036) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-28 01:37:42,157 - block_trainer.py[357] - INFO: epoch 40 (410.173552s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00107071   |   0.00122999   |   0.00142352   |   0.00139804   |   0.00132984   |
|         | (↓ 0.00005149) | (↓ 0.00005499) | (↓ 0.00006194) | (↓ 0.00007738) | (↓ 0.00006706) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001517   |   0.00004012   |   0.00008823   |   0.00030257   |   0.00063685   |
|         | (↓ 0.00000078) | (↓ 0.00000081) | (↓ 0.00000167) | (↓ 0.00000903) | (↓ 0.00002517) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00014422   |   0.00015219   |   0.00017713   |   0.00021952   |   0.00032664   |
|         | (↓ 0.00000700) | (↓ 0.00000626) | (↓ 0.00000567) | (↓ 0.00000380) | (↓ 0.00000301) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000381   |   0.00005081   |   0.00010925   |   0.00013218   |   0.00017462   |
|         | (↓ 0.00000012) | (↓ 0.00000249) | (↓ 0.00001706) | (↓ 0.00001419) | (↓ 0.00001133) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00005486   |   0.00005282   |   0.00005217   |   0.00005642   |   0.00006978   |
|         | (↓ 0.00000205) | (↓ 0.00000233) | (↓ 0.00000142) | (↓ 0.00000107) | (↓ 0.00000111) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00011718   |    0.00006908   |   0.00007682   |   0.00004036   |   0.00003735   |
|         | (↓ -0.00002081) | (↓ -0.00001780) | (↓ 0.00001863) | (↓ 0.00000219) | (↓ 0.00000273) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001515   |   0.00001494   |   0.00001393   |   0.00001315   |   0.00001376   |
|         | (↓ 0.00000151) | (↓ 0.00000143) | (↓ 0.00000105) | (↓ 0.00000065) | (↓ 0.00000029) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-7 |   0.00000975   |    0.00000830   |    0.00000838   |   0.00000792   |   0.00000526   |
|         | (↓ 0.00000022) | (↓ -0.00000010) | (↓ -0.00000052) | (↓ 0.00000048) | (↓ 0.00000033) |
+---------+----------------+-----------------+-----------------+----------------+----------------+

2023-06-28 01:44:32,246 - block_trainer.py[357] - INFO: epoch 41 (410.088767s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00111232   |    0.00127039   |    0.00145186   |    0.00141133   |    0.00135265   |
|         | (↓ -0.00004162) | (↓ -0.00004040) | (↓ -0.00002834) | (↓ -0.00001330) | (↓ -0.00002281) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00001558   |    0.00004076   |   0.00008811   |   0.00029811   |   0.00061968   |
|         | (↓ -0.00000041) | (↓ -0.00000064) | (↓ 0.00000012) | (↓ 0.00000446) | (↓ 0.00001716) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-2 |   0.00014145   |   0.00015074   |    0.00017770   |    0.00022095   |    0.00032990   |
|         | (↓ 0.00000277) | (↓ 0.00000145) | (↓ -0.00000057) | (↓ -0.00000143) | (↓ -0.00000326) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-3 |    0.00000396   |    0.00005121   |    0.00011321   |   0.00012716   |   0.00016573   |
|         | (↓ -0.00000015) | (↓ -0.00000041) | (↓ -0.00000397) | (↓ 0.00000501) | (↓ 0.00000889) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+-----------------+----------------+-----------------+
| block-4 |   0.00005481   |   0.00005257   |    0.00005233   |   0.00005639   |    0.00006996   |
|         | (↓ 0.00000005) | (↓ 0.00000025) | (↓ -0.00000016) | (↓ 0.00000003) | (↓ -0.00000018) |
+---------+----------------+----------------+-----------------+----------------+-----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-5 |   0.00009413   |    0.00009338   |    0.00009092   |   0.00003823   |   0.00003517   |
|         | (↓ 0.00002304) | (↓ -0.00002430) | (↓ -0.00001410) | (↓ 0.00000213) | (↓ 0.00000218) |
+---------+----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00001612   |    0.00001593   |    0.00001428   |    0.00001321   |    0.00001377   |
|         | (↓ -0.00000097) | (↓ -0.00000099) | (↓ -0.00000035) | (↓ -0.00000006) | (↓ -0.00000001) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.00001068   |    0.00000911   |    0.00000971   |    0.00000805   |   0.00000498   |
|         | (↓ -0.00000093) | (↓ -0.00000081) | (↓ -0.00000133) | (↓ -0.00000014) | (↓ 0.00000028) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2023-06-28 01:51:22,239 - block_trainer.py[357] - INFO: epoch 42 (409.992591s, 40 blocks still need training), blocks loss: 
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-0 |    0.00111641   |   0.00127021   |   0.00144146   |   0.00138900   |   0.00133654   |
|         | (↓ -0.00000408) | (↓ 0.00000017) | (↓ 0.00001040) | (↓ 0.00002233) | (↓ 0.00001611) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00001613   |    0.00004133   |   0.00008803   |   0.00029219   |   0.00060272   |
|         | (↓ -0.00000056) | (↓ -0.00000058) | (↓ 0.00000008) | (↓ 0.00000592) | (↓ 0.00001697) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00014874   |    0.00015738   |    0.00018454   |    0.00022698   |    0.00033242   |
|         | (↓ -0.00000729) | (↓ -0.00000664) | (↓ -0.00000684) | (↓ -0.00000603) | (↓ -0.00000252) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000419   |   0.00004843   |   0.00009741   |   0.00011570   |   0.00015805   |
|         | (↓ -0.00000023) | (↓ 0.00000278) | (↓ 0.00001580) | (↓ 0.00001147) | (↓ 0.00000767) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-4 |   0.00005355   |   0.00005155   |   0.00005156   |    0.00005644   |    0.00007068   |
|         | (↓ 0.00000127) | (↓ 0.00000102) | (↓ 0.00000077) | (↓ -0.00000005) | (↓ -0.00000072) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007610   |   0.00006385   |   0.00006151   |   0.00003293   |   0.00003287   |
|         | (↓ 0.00001803) | (↓ 0.00002953) | (↓ 0.00002941) | (↓ 0.00000530) | (↓ 0.00000230) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001476   |   0.00001510   |   0.00001377   |   0.00001287   |   0.00001373   |
|         | (↓ 0.00000136) | (↓ 0.00000083) | (↓ 0.00000051) | (↓ 0.00000034) | (↓ 0.00000004) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00000933   |   0.00000850   |   0.00000834   |   0.00000752   |   0.00000473   |
|         | (↓ 0.00000136) | (↓ 0.00000062) | (↓ 0.00000136) | (↓ 0.00000054) | (↓ 0.00000025) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-28 01:58:12,112 - block_trainer.py[357] - INFO: epoch 43 (409.872854s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00104438   |   0.00119255   |   0.00136079   |   0.00130247   |   0.00125803   |
|         | (↓ 0.00007202) | (↓ 0.00007766) | (↓ 0.00008068) | (↓ 0.00008654) | (↓ 0.00007852) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001500   |   0.00004028   |   0.00008635   |   0.00028421   |   0.00058246   |
|         | (↓ 0.00000113) | (↓ 0.00000105) | (↓ 0.00000168) | (↓ 0.00000798) | (↓ 0.00002026) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00013382   |   0.00014464   |   0.00017294   |   0.00021795   |   0.00032613   |
|         | (↓ 0.00001492) | (↓ 0.00001274) | (↓ 0.00001160) | (↓ 0.00000903) | (↓ 0.00000629) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000383   |   0.00004733   |   0.00008873   |   0.00010837   |   0.00015072   |
|         | (↓ 0.00000036) | (↓ 0.00000109) | (↓ 0.00000869) | (↓ 0.00000732) | (↓ 0.00000734) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00005170   |   0.00005139   |   0.00005074   |   0.00005471   |   0.00006884   |
|         | (↓ 0.00000184) | (↓ 0.00000016) | (↓ 0.00000083) | (↓ 0.00000173) | (↓ 0.00000184) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00006472   |   0.00005284   |   0.00005702   |   0.00002990   |   0.00003116   |
|         | (↓ 0.00001138) | (↓ 0.00001101) | (↓ 0.00000449) | (↓ 0.00000303) | (↓ 0.00000171) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001350   |   0.00001370   |   0.00001306   |   0.00001267   |   0.00001344   |
|         | (↓ 0.00000126) | (↓ 0.00000140) | (↓ 0.00000071) | (↓ 0.00000020) | (↓ 0.00000029) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.00001010   |    0.00000860   |    0.00000858   |   0.00000650   |   0.00000451   |
|         | (↓ -0.00000077) | (↓ -0.00000011) | (↓ -0.00000024) | (↓ 0.00000101) | (↓ 0.00000022) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2023-06-28 02:05:01,468 - block_trainer.py[357] - INFO: epoch 44 (409.355996s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00104071   |   0.00118596   |   0.00133963   |   0.00127094   |   0.00123356   |
|         | (↓ 0.00000367) | (↓ 0.00000659) | (↓ 0.00002116) | (↓ 0.00003152) | (↓ 0.00002447) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00001504   |    0.00004037   |   0.00008584   |   0.00028020   |   0.00057010   |
|         | (↓ -0.00000003) | (↓ -0.00000009) | (↓ 0.00000052) | (↓ 0.00000401) | (↓ 0.00001236) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00014038   |    0.00015050   |    0.00017906   |    0.00022285   |    0.00032883   |
|         | (↓ -0.00000656) | (↓ -0.00000586) | (↓ -0.00000612) | (↓ -0.00000490) | (↓ -0.00000271) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000393   |   0.00004634   |   0.00008621   |   0.00010496   |   0.00014651   |
|         | (↓ -0.00000010) | (↓ 0.00000100) | (↓ 0.00000252) | (↓ 0.00000341) | (↓ 0.00000421) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-4 |   0.00005147   |   0.00005099   |    0.00005115   |    0.00005522   |    0.00006986   |
|         | (↓ 0.00000023) | (↓ 0.00000040) | (↓ -0.00000042) | (↓ -0.00000051) | (↓ -0.00000101) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-5 |   0.00006407   |   0.00005247   |    0.00005860   |   0.00002776   |   0.00002976   |
|         | (↓ 0.00000065) | (↓ 0.00000037) | (↓ -0.00000158) | (↓ 0.00000214) | (↓ 0.00000140) |
+---------+----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-6 |   0.00001301   |   0.00001365   |   0.00001301   |   0.00001247   |    0.00001345   |
|         | (↓ 0.00000049) | (↓ 0.00000005) | (↓ 0.00000006) | (↓ 0.00000019) | (↓ -0.00000000) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-7 |   0.00000944   |    0.00000936   |   0.00000824   |   0.00000618   |   0.00000430   |
|         | (↓ 0.00000066) | (↓ -0.00000075) | (↓ 0.00000034) | (↓ 0.00000032) | (↓ 0.00000021) |
+---------+----------------+-----------------+----------------+----------------+----------------+

2023-06-28 02:11:51,419 - block_trainer.py[357] - INFO: epoch 45 (409.950800s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00100942   |   0.00115194   |   0.00130154   |   0.00122762   |   0.00119974   |
|         | (↓ 0.00003129) | (↓ 0.00003402) | (↓ 0.00003809) | (↓ 0.00004332) | (↓ 0.00003382) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001449   |   0.00003977   |   0.00008486   |   0.00027399   |   0.00055486   |
|         | (↓ 0.00000055) | (↓ 0.00000060) | (↓ 0.00000098) | (↓ 0.00000621) | (↓ 0.00001523) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00013200   |   0.00014291   |   0.00017202   |   0.00021635   |   0.00032356   |
|         | (↓ 0.00000838) | (↓ 0.00000759) | (↓ 0.00000704) | (↓ 0.00000650) | (↓ 0.00000527) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000375   |   0.00004526   |   0.00008038   |   0.00009981   |   0.00014192   |
|         | (↓ 0.00000018) | (↓ 0.00000108) | (↓ 0.00000583) | (↓ 0.00000515) | (↓ 0.00000458) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00005074   |   0.00004891   |   0.00004897   |   0.00005374   |   0.00006867   |
|         | (↓ 0.00000073) | (↓ 0.00000208) | (↓ 0.00000218) | (↓ 0.00000148) | (↓ 0.00000119) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00006221   |   0.00004870   |   0.00005056   |   0.00002561   |   0.00002855   |
|         | (↓ 0.00000185) | (↓ 0.00000377) | (↓ 0.00000805) | (↓ 0.00000215) | (↓ 0.00000121) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00001338   |   0.00001331   |   0.00001248   |   0.00001201   |   0.00001314   |
|         | (↓ -0.00000037) | (↓ 0.00000034) | (↓ 0.00000053) | (↓ 0.00000047) | (↓ 0.00000031) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+-----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+----------------+----------------+-----------------+----------------+
| block-7 |    0.00000984   |   0.00000835   |   0.00000796   |    0.00000626   |   0.00000407   |
|         | (↓ -0.00000041) | (↓ 0.00000100) | (↓ 0.00000028) | (↓ -0.00000008) | (↓ 0.00000023) |
+---------+-----------------+----------------+----------------+-----------------+----------------+

2023-06-28 02:18:40,982 - block_trainer.py[357] - INFO: epoch 46 (409.562980s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00098550   |   0.00112328   |   0.00126320   |   0.00118719   |   0.00116589   |
|         | (↓ 0.00002392) | (↓ 0.00002866) | (↓ 0.00003834) | (↓ 0.00004043) | (↓ 0.00003385) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001381   |   0.00003903   |   0.00008380   |   0.00026790   |   0.00054240   |
|         | (↓ 0.00000068) | (↓ 0.00000074) | (↓ 0.00000105) | (↓ 0.00000609) | (↓ 0.00001246) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00012951   |   0.00014109   |   0.00017057   |   0.00021469   |   0.00032236   |
|         | (↓ 0.00000249) | (↓ 0.00000181) | (↓ 0.00000145) | (↓ 0.00000166) | (↓ 0.00000120) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000365   |   0.00004443   |   0.00007619   |   0.00009630   |   0.00013833   |
|         | (↓ 0.00000010) | (↓ 0.00000083) | (↓ 0.00000419) | (↓ 0.00000351) | (↓ 0.00000360) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00004859   |   0.00004837   |   0.00004870   |   0.00005321   |   0.00006842   |
|         | (↓ 0.00000215) | (↓ 0.00000054) | (↓ 0.00000027) | (↓ 0.00000053) | (↓ 0.00000025) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-5 |   0.00006006   |    0.00005030   |   0.00004990   |   0.00002391   |   0.00002763   |
|         | (↓ 0.00000216) | (↓ -0.00000160) | (↓ 0.00000066) | (↓ 0.00000170) | (↓ 0.00000092) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001179   |   0.00001259   |   0.00001226   |   0.00001188   |   0.00001306   |
|         | (↓ 0.00000159) | (↓ 0.00000072) | (↓ 0.00000022) | (↓ 0.00000013) | (↓ 0.00000008) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-7 |   0.00000944   |    0.00000851   |    0.00000805   |   0.00000580   |   0.00000385   |
|         | (↓ 0.00000041) | (↓ -0.00000015) | (↓ -0.00000009) | (↓ 0.00000046) | (↓ 0.00000022) |
+---------+----------------+-----------------+-----------------+----------------+----------------+

2023-06-28 02:25:30,093 - block_trainer.py[357] - INFO: epoch 47 (409.110719s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00100493   |    0.00113871   |    0.00126989   |    0.00118826   |    0.00117208   |
|         | (↓ -0.00001943) | (↓ -0.00001543) | (↓ -0.00000669) | (↓ -0.00000107) | (↓ -0.00000619) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00001436   |    0.00003968   |    0.00008430   |   0.00026493   |   0.00053298   |
|         | (↓ -0.00000055) | (↓ -0.00000064) | (↓ -0.00000049) | (↓ 0.00000297) | (↓ 0.00000942) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00013179   |    0.00014318   |    0.00017298   |    0.00021769   |    0.00032491   |
|         | (↓ -0.00000228) | (↓ -0.00000208) | (↓ -0.00000240) | (↓ -0.00000299) | (↓ -0.00000255) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000380   |   0.00004414   |   0.00007301   |   0.00009399   |   0.00013573   |
|         | (↓ -0.00000015) | (↓ 0.00000029) | (↓ 0.00000318) | (↓ 0.00000231) | (↓ 0.00000260) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00004953   |    0.00004841   |    0.00004910   |    0.00005412   |    0.00006924   |
|         | (↓ -0.00000094) | (↓ -0.00000004) | (↓ -0.00000039) | (↓ -0.00000091) | (↓ -0.00000082) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00005838   |   0.00004979   |   0.00004604   |   0.00002249   |   0.00002694   |
|         | (↓ 0.00000167) | (↓ 0.00000051) | (↓ 0.00000386) | (↓ 0.00000142) | (↓ 0.00000069) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00001226   |    0.00001303   |    0.00001235   |    0.00001192   |    0.00001320   |
|         | (↓ -0.00000046) | (↓ -0.00000044) | (↓ -0.00000009) | (↓ -0.00000005) | (↓ -0.00000014) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+-----------------+-----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |   0.00000914   |    0.00000866   |    0.00000815   |    0.00000590   |   0.00000364   |
|         | (↓ 0.00000030) | (↓ -0.00000015) | (↓ -0.00000009) | (↓ -0.00000010) | (↓ 0.00000021) |
+---------+----------------+-----------------+-----------------+-----------------+----------------+

2023-06-28 02:32:19,327 - block_trainer.py[357] - INFO: epoch 48 (409.234238s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00096789   |   0.00110026   |   0.00122508   |   0.00114083   |   0.00113082   |
|         | (↓ 0.00003704) | (↓ 0.00003845) | (↓ 0.00004480) | (↓ 0.00004743) | (↓ 0.00004125) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001342   |   0.00003862   |   0.00008303   |   0.00025918   |   0.00052029   |
|         | (↓ 0.00000093) | (↓ 0.00000106) | (↓ 0.00000127) | (↓ 0.00000575) | (↓ 0.00001269) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00012607   |   0.00013834   |   0.00016887   |   0.00021377   |   0.00032093   |
|         | (↓ 0.00000572) | (↓ 0.00000484) | (↓ 0.00000411) | (↓ 0.00000391) | (↓ 0.00000398) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000361   |   0.00004306   |   0.00006969   |   0.00009096   |   0.00013261   |
|         | (↓ 0.00000020) | (↓ 0.00000108) | (↓ 0.00000332) | (↓ 0.00000303) | (↓ 0.00000312) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00004812   |   0.00004711   |   0.00004735   |   0.00005244   |   0.00006847   |
|         | (↓ 0.00000141) | (↓ 0.00000131) | (↓ 0.00000175) | (↓ 0.00000167) | (↓ 0.00000077) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00005320   |   0.00004319   |   0.00004226   |   0.00002124   |   0.00002624   |
|         | (↓ 0.00000518) | (↓ 0.00000660) | (↓ 0.00000378) | (↓ 0.00000125) | (↓ 0.00000070) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001139   |   0.00001194   |   0.00001165   |   0.00001150   |   0.00001292   |
|         | (↓ 0.00000086) | (↓ 0.00000109) | (↓ 0.00000070) | (↓ 0.00000042) | (↓ 0.00000028) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+----------------+----------------+
| block-7 |    0.00001056   |   0.00000848   |    0.00000825   |   0.00000582   |   0.00000344   |
|         | (↓ -0.00000143) | (↓ 0.00000018) | (↓ -0.00000011) | (↓ 0.00000008) | (↓ 0.00000019) |
+---------+-----------------+----------------+-----------------+----------------+----------------+

2023-06-28 02:39:08,554 - block_trainer.py[357] - INFO: epoch 49 (409.226125s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00103538   |    0.00116534   |    0.00127532   |    0.00118496   |    0.00117621   |
|         | (↓ -0.00006748) | (↓ -0.00006507) | (↓ -0.00005024) | (↓ -0.00004412) | (↓ -0.00004538) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00001514   |    0.00004039   |    0.00008461   |   0.00025855   |   0.00051433   |
|         | (↓ -0.00000171) | (↓ -0.00000178) | (↓ -0.00000158) | (↓ 0.00000062) | (↓ 0.00000596) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00013263   |    0.00014607   |    0.00017808   |    0.00022293   |    0.00032960   |
|         | (↓ -0.00000656) | (↓ -0.00000774) | (↓ -0.00000921) | (↓ -0.00000916) | (↓ -0.00000868) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000403   |   0.00004275   |   0.00006779   |   0.00008928   |   0.00013082   |
|         | (↓ -0.00000042) | (↓ 0.00000031) | (↓ 0.00000189) | (↓ 0.00000168) | (↓ 0.00000180) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |   0.00004773   |    0.00004824   |    0.00004919   |    0.00005381   |    0.00006863   |
|         | (↓ 0.00000039) | (↓ -0.00000114) | (↓ -0.00000184) | (↓ -0.00000137) | (↓ -0.00000016) |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-5 |   0.00005106   |    0.00004466   |   0.00003937   |   0.00002023   |   0.00002565   |
|         | (↓ 0.00000214) | (↓ -0.00000147) | (↓ 0.00000289) | (↓ 0.00000101) | (↓ 0.00000060) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00001186   |    0.00001313   |    0.00001264   |    0.00001207   |    0.00001327   |
|         | (↓ -0.00000046) | (↓ -0.00000119) | (↓ -0.00000099) | (↓ -0.00000057) | (↓ -0.00000035) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-7 |   0.00000896   |    0.00000880   |   0.00000813   |   0.00000564   |   0.00000328   |
|         | (↓ 0.00000160) | (↓ -0.00000032) | (↓ 0.00000012) | (↓ 0.00000018) | (↓ 0.00000017) |
+---------+----------------+-----------------+----------------+----------------+----------------+

2023-06-28 02:45:58,024 - block_trainer.py[357] - INFO: epoch 50 (409.470542s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00096779   |   0.00109462   |   0.00120355   |   0.00111593   |   0.00111428   |
|         | (↓ 0.00006759) | (↓ 0.00007072) | (↓ 0.00007178) | (↓ 0.00006903) | (↓ 0.00006193) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001405   |   0.00003922   |   0.00008340   |   0.00025293   |   0.00050134   |
|         | (↓ 0.00000109) | (↓ 0.00000117) | (↓ 0.00000121) | (↓ 0.00000562) | (↓ 0.00001299) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00012341   |   0.00013756   |   0.00016988   |   0.00021520   |   0.00032151   |
|         | (↓ 0.00000922) | (↓ 0.00000851) | (↓ 0.00000820) | (↓ 0.00000773) | (↓ 0.00000809) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000379   |   0.00004177   |   0.00006519   |   0.00008647   |   0.00012794   |
|         | (↓ 0.00000024) | (↓ 0.00000097) | (↓ 0.00000261) | (↓ 0.00000281) | (↓ 0.00000287) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00004729   |   0.00004718   |   0.00004803   |   0.00005289   |   0.00006782   |
|         | (↓ 0.00000044) | (↓ 0.00000106) | (↓ 0.00000116) | (↓ 0.00000091) | (↓ 0.00000081) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00004899   |   0.00004057   |   0.00003562   |   0.00001931   |   0.00002499   |
|         | (↓ 0.00000207) | (↓ 0.00000409) | (↓ 0.00000375) | (↓ 0.00000092) | (↓ 0.00000066) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00001264   |   0.00001255   |   0.00001198   |   0.00001174   |   0.00001304   |
|         | (↓ -0.00000078) | (↓ 0.00000058) | (↓ 0.00000066) | (↓ 0.00000034) | (↓ 0.00000023) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+-----------------+-----------------+----------------+
| block-7 |   0.00000894   |   0.00000843   |    0.00000831   |    0.00000564   |   0.00000314   |
|         | (↓ 0.00000001) | (↓ 0.00000037) | (↓ -0.00000018) | (↓ -0.00000000) | (↓ 0.00000014) |
+---------+----------------+----------------+-----------------+-----------------+----------------+

2023-06-28 02:52:48,269 - block_trainer.py[357] - INFO: epoch 51 (410.244803s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00094733   |   0.00107205   |   0.00116837   |   0.00108094   |   0.00108142   |
|         | (↓ 0.00002046) | (↓ 0.00002257) | (↓ 0.00003518) | (↓ 0.00003499) | (↓ 0.00003286) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001386   |   0.00003911   |   0.00008317   |   0.00025029   |   0.00049019   |
|         | (↓ 0.00000019) | (↓ 0.00000011) | (↓ 0.00000023) | (↓ 0.00000264) | (↓ 0.00001115) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00012217   |   0.00013691   |   0.00016892   |   0.00021378   |   0.00032017   |
|         | (↓ 0.00000124) | (↓ 0.00000065) | (↓ 0.00000096) | (↓ 0.00000142) | (↓ 0.00000135) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000372   |   0.00004113   |   0.00006334   |   0.00008431   |   0.00012550   |
|         | (↓ 0.00000007) | (↓ 0.00000064) | (↓ 0.00000185) | (↓ 0.00000217) | (↓ 0.00000245) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+-----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+-----------------+----------------+----------------+----------------+-----------------+
| block-4 |    0.00004746   |   0.00004675   |   0.00004749   |   0.00005263   |    0.00006787   |
|         | (↓ -0.00000017) | (↓ 0.00000043) | (↓ 0.00000054) | (↓ 0.00000027) | (↓ -0.00000005) |
+---------+-----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00004703   |   0.00003848   |   0.00003163   |   0.00001853   |   0.00002439   |
|         | (↓ 0.00000196) | (↓ 0.00000209) | (↓ 0.00000399) | (↓ 0.00000077) | (↓ 0.00000060) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001081   |   0.00001170   |   0.00001161   |   0.00001148   |   0.00001298   |
|         | (↓ 0.00000182) | (↓ 0.00000085) | (↓ 0.00000037) | (↓ 0.00000026) | (↓ 0.00000006) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.00000917   |   0.00000823   |   0.00000788   |   0.00000554   |   0.00000301   |
|         | (↓ -0.00000023) | (↓ 0.00000020) | (↓ 0.00000043) | (↓ 0.00000010) | (↓ 0.00000012) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-28 02:59:37,634 - block_trainer.py[357] - INFO: epoch 52 (409.364813s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00096390   |    0.00108651   |    0.00117580   |    0.00108708   |    0.00108939   |
|         | (↓ -0.00001657) | (↓ -0.00001446) | (↓ -0.00000743) | (↓ -0.00000614) | (↓ -0.00000798) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00001388   |    0.00003919   |    0.00008328   |   0.00024746   |   0.00048138   |
|         | (↓ -0.00000002) | (↓ -0.00000008) | (↓ -0.00000011) | (↓ 0.00000283) | (↓ 0.00000881) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-2 |   0.00011978   |   0.00013451   |   0.00016773   |   0.00021377   |    0.00032037   |
|         | (↓ 0.00000239) | (↓ 0.00000240) | (↓ 0.00000120) | (↓ 0.00000001) | (↓ -0.00000020) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000378   |   0.00004059   |   0.00006165   |   0.00008207   |   0.00012317   |
|         | (↓ -0.00000006) | (↓ 0.00000054) | (↓ 0.00000169) | (↓ 0.00000224) | (↓ 0.00000232) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00004552   |   0.00004509   |   0.00004641   |   0.00005174   |   0.00006779   |
|         | (↓ 0.00000194) | (↓ 0.00000166) | (↓ 0.00000108) | (↓ 0.00000089) | (↓ 0.00000008) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00004506   |   0.00003713   |   0.00002731   |   0.00001779   |   0.00002381   |
|         | (↓ 0.00000197) | (↓ 0.00000135) | (↓ 0.00000432) | (↓ 0.00000074) | (↓ 0.00000059) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00001041   |   0.00001115   |   0.00001114   |   0.00001117   |   0.00001284   |
|         | (↓ 0.00000040) | (↓ 0.00000056) | (↓ 0.00000048) | (↓ 0.00000030) | (↓ 0.00000014) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.00001014   |    0.00000917   |    0.00000792   |   0.00000536   |   0.00000291   |
|         | (↓ -0.00000097) | (↓ -0.00000094) | (↓ -0.00000004) | (↓ 0.00000018) | (↓ 0.00000011) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2023-06-28 03:06:26,743 - block_trainer.py[357] - INFO: epoch 53 (409.108378s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00100150   |    0.00112014   |    0.00120172   |    0.00111448   |    0.00111751   |
|         | (↓ -0.00003761) | (↓ -0.00003363) | (↓ -0.00002592) | (↓ -0.00002740) | (↓ -0.00002812) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00001468   |    0.00004003   |    0.00008395   |   0.00024570   |   0.00047283   |
|         | (↓ -0.00000080) | (↓ -0.00000084) | (↓ -0.00000067) | (↓ 0.00000176) | (↓ 0.00000855) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00012399   |    0.00013946   |    0.00017150   |    0.00021535   |    0.00032132   |
|         | (↓ -0.00000421) | (↓ -0.00000495) | (↓ -0.00000377) | (↓ -0.00000158) | (↓ -0.00000095) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000404   |   0.00004017   |   0.00006044   |   0.00008012   |   0.00012053   |
|         | (↓ -0.00000026) | (↓ 0.00000042) | (↓ 0.00000121) | (↓ 0.00000195) | (↓ 0.00000265) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00004625   |    0.00004622   |    0.00004728   |    0.00005319   |    0.00006855   |
|         | (↓ -0.00000073) | (↓ -0.00000113) | (↓ -0.00000087) | (↓ -0.00000145) | (↓ -0.00000076) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00004270   |   0.00003533   |   0.00002389   |   0.00001716   |   0.00002322   |
|         | (↓ 0.00000235) | (↓ 0.00000179) | (↓ 0.00000341) | (↓ 0.00000063) | (↓ 0.00000058) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00001057   |    0.00001131   |    0.00001128   |    0.00001128   |    0.00001301   |
|         | (↓ -0.00000016) | (↓ -0.00000016) | (↓ -0.00000015) | (↓ -0.00000010) | (↓ -0.00000017) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+----------------+-----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+-----------------+----------------+-----------------+----------------+
| block-7 |   0.00000937   |    0.00000962   |   0.00000786   |    0.00000541   |   0.00000282   |
|         | (↓ 0.00000077) | (↓ -0.00000045) | (↓ 0.00000006) | (↓ -0.00000005) | (↓ 0.00000009) |
+---------+----------------+-----------------+----------------+-----------------+----------------+

2023-06-28 03:13:15,895 - block_trainer.py[357] - INFO: epoch 54 (409.151796s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00098010   |   0.00109867   |   0.00117140   |   0.00108368   |   0.00108887   |
|         | (↓ 0.00002140) | (↓ 0.00002147) | (↓ 0.00003031) | (↓ 0.00003081) | (↓ 0.00002864) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001425   |   0.00003961   |   0.00008348   |   0.00024296   |   0.00046368   |
|         | (↓ 0.00000043) | (↓ 0.00000041) | (↓ 0.00000047) | (↓ 0.00000274) | (↓ 0.00000916) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-2 |   0.00012080   |   0.00013745   |   0.00017063   |    0.00021650   |    0.00032305   |
|         | (↓ 0.00000319) | (↓ 0.00000201) | (↓ 0.00000086) | (↓ -0.00000115) | (↓ -0.00000173) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000397   |   0.00003961   |   0.00005896   |   0.00007802   |   0.00011782   |
|         | (↓ 0.00000007) | (↓ 0.00000056) | (↓ 0.00000148) | (↓ 0.00000210) | (↓ 0.00000271) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00004496   |   0.00004482   |   0.00004590   |   0.00005144   |   0.00006760   |
|         | (↓ 0.00000129) | (↓ 0.00000140) | (↓ 0.00000138) | (↓ 0.00000175) | (↓ 0.00000095) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00004084   |   0.00003331   |   0.00002151   |   0.00001651   |   0.00002252   |
|         | (↓ 0.00000186) | (↓ 0.00000203) | (↓ 0.00000238) | (↓ 0.00000065) | (↓ 0.00000070) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-6 |   0.00001005   |    0.00001133   |    0.00001137   |   0.00001126   |   0.00001289   |
|         | (↓ 0.00000053) | (↓ -0.00000002) | (↓ -0.00000009) | (↓ 0.00000002) | (↓ 0.00000012) |
+---------+----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-7 |   0.00000889   |   0.00000856   |    0.00000804   |   0.00000539   |   0.00000273   |
|         | (↓ 0.00000048) | (↓ 0.00000105) | (↓ -0.00000018) | (↓ 0.00000001) | (↓ 0.00000008) |
+---------+----------------+----------------+-----------------+----------------+----------------+

2023-06-28 03:20:05,094 - block_trainer.py[357] - INFO: epoch 55 (409.199528s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00095273   |   0.00106711   |   0.00113124   |   0.00104631   |   0.00105455   |
|         | (↓ 0.00002737) | (↓ 0.00003156) | (↓ 0.00004016) | (↓ 0.00003737) | (↓ 0.00003432) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001420   |   0.00003956   |   0.00008336   |   0.00024059   |   0.00045501   |
|         | (↓ 0.00000005) | (↓ 0.00000005) | (↓ 0.00000012) | (↓ 0.00000237) | (↓ 0.00000866) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-2 |   0.00011989   |   0.00013745   |    0.00017237   |    0.00021838   |    0.00032418   |
|         | (↓ 0.00000091) | (↓ 0.00000000) | (↓ -0.00000174) | (↓ -0.00000188) | (↓ -0.00000114) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000383   |   0.00003877   |   0.00005737   |   0.00007594   |   0.00011514   |
|         | (↓ 0.00000014) | (↓ 0.00000084) | (↓ 0.00000159) | (↓ 0.00000208) | (↓ 0.00000268) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00004352   |   0.00004376   |   0.00004523   |   0.00005099   |   0.00006687   |
|         | (↓ 0.00000144) | (↓ 0.00000106) | (↓ 0.00000067) | (↓ 0.00000045) | (↓ 0.00000073) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00003831   |   0.00003049   |   0.00001974   |   0.00001588   |   0.00002185   |
|         | (↓ 0.00000253) | (↓ 0.00000281) | (↓ 0.00000177) | (↓ 0.00000063) | (↓ 0.00000068) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00000964   |   0.00001070   |   0.00001086   |   0.00001093   |   0.00001272   |
|         | (↓ 0.00000040) | (↓ 0.00000063) | (↓ 0.00000051) | (↓ 0.00000032) | (↓ 0.00000018) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |   0.00000879   |    0.00000881   |    0.00000805   |    0.00000558   |   0.00000264   |
|         | (↓ 0.00000010) | (↓ -0.00000025) | (↓ -0.00000001) | (↓ -0.00000019) | (↓ 0.00000009) |
+---------+----------------+-----------------+-----------------+-----------------+----------------+

2023-06-28 03:26:54,701 - block_trainer.py[357] - INFO: epoch 56 (409.605978s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00091677   |   0.00102770   |   0.00108444   |   0.00100197   |   0.00101478   |
|         | (↓ 0.00003596) | (↓ 0.00003941) | (↓ 0.00004681) | (↓ 0.00004433) | (↓ 0.00003977) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001331   |   0.00003857   |   0.00008244   |   0.00023737   |   0.00044493   |
|         | (↓ 0.00000089) | (↓ 0.00000099) | (↓ 0.00000092) | (↓ 0.00000322) | (↓ 0.00001008) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00011591   |   0.00013411   |   0.00016791   |   0.00021321   |   0.00031856   |
|         | (↓ 0.00000399) | (↓ 0.00000334) | (↓ 0.00000447) | (↓ 0.00000517) | (↓ 0.00000562) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000363   |   0.00003805   |   0.00005572   |   0.00007394   |   0.00011252   |
|         | (↓ 0.00000020) | (↓ 0.00000073) | (↓ 0.00000165) | (↓ 0.00000200) | (↓ 0.00000262) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-4 |   0.00004349   |   0.00004358   |   0.00004508   |    0.00005113   |    0.00006733   |
|         | (↓ 0.00000003) | (↓ 0.00000018) | (↓ 0.00000015) | (↓ -0.00000014) | (↓ -0.00000046) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00003604   |   0.00002772   |   0.00001842   |   0.00001530   |   0.00002124   |
|         | (↓ 0.00000228) | (↓ 0.00000278) | (↓ 0.00000132) | (↓ 0.00000057) | (↓ 0.00000061) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00000968   |   0.00001059   |   0.00001069   |   0.00001077   |   0.00001263   |
|         | (↓ -0.00000004) | (↓ 0.00000010) | (↓ 0.00000017) | (↓ 0.00000016) | (↓ 0.00000009) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-7 |    0.00000892   |    0.00000889   |   0.00000793   |   0.00000520   |   0.00000258   |
|         | (↓ -0.00000013) | (↓ -0.00000008) | (↓ 0.00000012) | (↓ 0.00000038) | (↓ 0.00000007) |
+---------+-----------------+-----------------+----------------+----------------+----------------+

2023-06-28 03:33:44,246 - block_trainer.py[357] - INFO: epoch 57 (409.545541s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00095498   |    0.00106411   |    0.00111514   |    0.00103400   |    0.00105017   |
|         | (↓ -0.00003821) | (↓ -0.00003642) | (↓ -0.00003071) | (↓ -0.00003203) | (↓ -0.00003539) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00001418   |    0.00003952   |    0.00008325   |   0.00023627   |   0.00043830   |
|         | (↓ -0.00000087) | (↓ -0.00000095) | (↓ -0.00000081) | (↓ 0.00000110) | (↓ 0.00000663) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-2 |   0.00011506   |   0.00013345   |    0.00016795   |    0.00021349   |    0.00032107   |
|         | (↓ 0.00000085) | (↓ 0.00000066) | (↓ -0.00000004) | (↓ -0.00000028) | (↓ -0.00000251) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000387   |   0.00003766   |   0.00005464   |   0.00007256   |   0.00011061   |
|         | (↓ -0.00000025) | (↓ 0.00000038) | (↓ 0.00000108) | (↓ 0.00000138) | (↓ 0.00000190) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00004370   |    0.00004398   |    0.00004524   |   0.00005093   |   0.00006693   |
|         | (↓ -0.00000021) | (↓ -0.00000040) | (↓ -0.00000016) | (↓ 0.00000020) | (↓ 0.00000039) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00003320   |   0.00002507   |   0.00001731   |   0.00001470   |   0.00002064   |
|         | (↓ 0.00000283) | (↓ 0.00000264) | (↓ 0.00000111) | (↓ 0.00000060) | (↓ 0.00000060) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00001011   |    0.00001072   |    0.00001083   |    0.00001087   |    0.00001268   |
|         | (↓ -0.00000043) | (↓ -0.00000012) | (↓ -0.00000014) | (↓ -0.00000010) | (↓ -0.00000004) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00000878   |   0.00000877   |   0.00000780   |   0.00000513   |   0.00000251   |
|         | (↓ 0.00000014) | (↓ 0.00000012) | (↓ 0.00000013) | (↓ 0.00000007) | (↓ 0.00000007) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-28 03:40:33,918 - block_trainer.py[357] - INFO: epoch 58 (409.671074s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00090324   |   0.00101170   |   0.00105945   |   0.00098386   |   0.00100614   |
|         | (↓ 0.00005174) | (↓ 0.00005241) | (↓ 0.00005569) | (↓ 0.00005015) | (↓ 0.00004403) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001333   |   0.00003859   |   0.00008227   |   0.00023287   |   0.00042977   |
|         | (↓ 0.00000084) | (↓ 0.00000093) | (↓ 0.00000097) | (↓ 0.00000340) | (↓ 0.00000853) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00011045   |   0.00012962   |   0.00016463   |   0.00021119   |   0.00031692   |
|         | (↓ 0.00000460) | (↓ 0.00000383) | (↓ 0.00000332) | (↓ 0.00000229) | (↓ 0.00000415) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000371   |   0.00003690   |   0.00005308   |   0.00007075   |   0.00010816   |
|         | (↓ 0.00000016) | (↓ 0.00000076) | (↓ 0.00000156) | (↓ 0.00000181) | (↓ 0.00000245) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+-----------------+-----------------+----------------+
| block-4 |   0.00004355   |   0.00004373   |    0.00004536   |    0.00005110   |   0.00006682   |
|         | (↓ 0.00000015) | (↓ 0.00000025) | (↓ -0.00000011) | (↓ -0.00000017) | (↓ 0.00000012) |
+---------+----------------+----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00002999   |   0.00002311   |   0.00001642   |   0.00001420   |   0.00002008   |
|         | (↓ 0.00000321) | (↓ 0.00000196) | (↓ 0.00000089) | (↓ 0.00000051) | (↓ 0.00000055) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00000959   |   0.00001049   |   0.00001069   |   0.00001085   |   0.00001267   |
|         | (↓ 0.00000052) | (↓ 0.00000023) | (↓ 0.00000013) | (↓ 0.00000002) | (↓ 0.00000001) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+----------------+----------------+
| block-7 |    0.00000901   |   0.00000869   |    0.00000841   |   0.00000510   |   0.00000245   |
|         | (↓ -0.00000023) | (↓ 0.00000008) | (↓ -0.00000061) | (↓ 0.00000003) | (↓ 0.00000006) |
+---------+-----------------+----------------+-----------------+----------------+----------------+

2023-06-28 03:47:23,629 - block_trainer.py[357] - INFO: epoch 59 (409.711359s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00088927   |   0.00099462   |   0.00103656   |   0.00096100   |   0.00098449   |
|         | (↓ 0.00001397) | (↓ 0.00001709) | (↓ 0.00002290) | (↓ 0.00002285) | (↓ 0.00002165) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001296   |   0.00003824   |   0.00008195   |   0.00023067   |   0.00042190   |
|         | (↓ 0.00000037) | (↓ 0.00000035) | (↓ 0.00000032) | (↓ 0.00000220) | (↓ 0.00000787) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-2 |   0.00010940   |   0.00012951   |    0.00016524   |    0.00021201   |    0.00031765   |
|         | (↓ 0.00000105) | (↓ 0.00000011) | (↓ -0.00000061) | (↓ -0.00000082) | (↓ -0.00000073) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000356   |   0.00003621   |   0.00005179   |   0.00006910   |   0.00010585   |
|         | (↓ 0.00000014) | (↓ 0.00000069) | (↓ 0.00000128) | (↓ 0.00000164) | (↓ 0.00000231) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00004142   |   0.00004216   |   0.00004424   |   0.00005066   |   0.00006653   |
|         | (↓ 0.00000212) | (↓ 0.00000157) | (↓ 0.00000112) | (↓ 0.00000045) | (↓ 0.00000029) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00002679   |   0.00002182   |   0.00001565   |   0.00001368   |   0.00001950   |
|         | (↓ 0.00000321) | (↓ 0.00000129) | (↓ 0.00000077) | (↓ 0.00000052) | (↓ 0.00000058) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-6 |   0.00000909   |   0.00001037   |    0.00001071   |   0.00001077   |   0.00001264   |
|         | (↓ 0.00000050) | (↓ 0.00000012) | (↓ -0.00000002) | (↓ 0.00000008) | (↓ 0.00000003) |
+---------+----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00000889   |   0.00000834   |   0.00000779   |   0.00000505   |   0.00000239   |
|         | (↓ 0.00000012) | (↓ 0.00000035) | (↓ 0.00000062) | (↓ 0.00000005) | (↓ 0.00000006) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-28 03:54:13,175 - block_trainer.py[357] - INFO: epoch 60 (409.545969s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00093502   |    0.00103611   |    0.00107153   |    0.00099663   |    0.00102045   |
|         | (↓ -0.00004575) | (↓ -0.00004149) | (↓ -0.00003497) | (↓ -0.00003563) | (↓ -0.00003596) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00001424   |    0.00003950   |    0.00008324   |   0.00023003   |   0.00041648   |
|         | (↓ -0.00000128) | (↓ -0.00000126) | (↓ -0.00000129) | (↓ 0.00000065) | (↓ 0.00000542) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00011133   |    0.00013166   |    0.00016758   |    0.00021500   |    0.00032115   |
|         | (↓ -0.00000193) | (↓ -0.00000215) | (↓ -0.00000233) | (↓ -0.00000299) | (↓ -0.00000350) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000392   |   0.00003587   |   0.00005089   |   0.00006796   |   0.00010408   |
|         | (↓ -0.00000035) | (↓ 0.00000033) | (↓ 0.00000090) | (↓ 0.00000114) | (↓ 0.00000177) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00004249   |    0.00004302   |    0.00004492   |    0.00005137   |    0.00006679   |
|         | (↓ -0.00000107) | (↓ -0.00000086) | (↓ -0.00000068) | (↓ -0.00000071) | (↓ -0.00000025) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00002438   |   0.00002091   |   0.00001508   |   0.00001327   |   0.00001902   |
|         | (↓ 0.00000241) | (↓ 0.00000091) | (↓ 0.00000057) | (↓ 0.00000041) | (↓ 0.00000048) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+-----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+-----------------+----------------+----------------+----------------+-----------------+
| block-6 |    0.00000922   |   0.00001018   |   0.00001048   |   0.00001073   |    0.00001271   |
|         | (↓ -0.00000012) | (↓ 0.00000019) | (↓ 0.00000023) | (↓ 0.00000004) | (↓ -0.00000007) |
+---------+-----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-7 |   0.00000875   |   0.00000825   |    0.00000786   |   0.00000493   |   0.00000234   |
|         | (↓ 0.00000014) | (↓ 0.00000009) | (↓ -0.00000008) | (↓ 0.00000012) | (↓ 0.00000005) |
+---------+----------------+----------------+-----------------+----------------+----------------+

2023-06-28 04:01:02,616 - block_trainer.py[357] - INFO: epoch 61 (409.440712s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00089972   |   0.00099872   |   0.00102921   |   0.00095963   |   0.00098760   |
|         | (↓ 0.00003530) | (↓ 0.00003738) | (↓ 0.00004231) | (↓ 0.00003700) | (↓ 0.00003285) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001371   |   0.00003886   |   0.00008252   |   0.00022803   |   0.00040885   |
|         | (↓ 0.00000053) | (↓ 0.00000064) | (↓ 0.00000073) | (↓ 0.00000199) | (↓ 0.00000763) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00010916   |   0.00012961   |   0.00016386   |   0.00020967   |   0.00031555   |
|         | (↓ 0.00000217) | (↓ 0.00000205) | (↓ 0.00000371) | (↓ 0.00000532) | (↓ 0.00000561) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000370   |   0.00003510   |   0.00004964   |   0.00006639   |   0.00010187   |
|         | (↓ 0.00000022) | (↓ 0.00000078) | (↓ 0.00000126) | (↓ 0.00000157) | (↓ 0.00000221) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00004114   |   0.00004187   |   0.00004369   |   0.00005007   |   0.00006656   |
|         | (↓ 0.00000135) | (↓ 0.00000115) | (↓ 0.00000123) | (↓ 0.00000130) | (↓ 0.00000023) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00002272   |   0.00002003   |   0.00001452   |   0.00001284   |   0.00001848   |
|         | (↓ 0.00000166) | (↓ 0.00000088) | (↓ 0.00000057) | (↓ 0.00000043) | (↓ 0.00000054) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00000883   |   0.00000986   |   0.00001032   |   0.00001055   |   0.00001256   |
|         | (↓ 0.00000039) | (↓ 0.00000032) | (↓ 0.00000017) | (↓ 0.00000018) | (↓ 0.00000015) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+-----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
| block-7 |    0.00000876   |    0.00000846   |   0.00000774   |    0.00000497   |   0.00000229   |
|         | (↓ -0.00000001) | (↓ -0.00000021) | (↓ 0.00000012) | (↓ -0.00000004) | (↓ 0.00000005) |
+---------+-----------------+-----------------+----------------+-----------------+----------------+

2023-06-28 04:07:52,436 - block_trainer.py[357] - INFO: epoch 62 (409.819860s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00087874   |   0.00097703   |   0.00100242   |   0.00093574   |   0.00096864   |
|         | (↓ 0.00002098) | (↓ 0.00002169) | (↓ 0.00002679) | (↓ 0.00002389) | (↓ 0.00001897) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00001348   |   0.00003867   |   0.00008228   |   0.00022584   |   0.00040311   |
|         | (↓ 0.00000023) | (↓ 0.00000019) | (↓ 0.00000024) | (↓ 0.00000219) | (↓ 0.00000574) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |   0.00010873   |    0.00013033   |    0.00016610   |    0.00021207   |    0.00031586   |
|         | (↓ 0.00000043) | (↓ -0.00000072) | (↓ -0.00000224) | (↓ -0.00000240) | (↓ -0.00000031) |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00000369   |   0.00003452   |   0.00004839   |   0.00006460   |   0.00009985   |
|         | (↓ 0.00000001) | (↓ 0.00000058) | (↓ 0.00000124) | (↓ 0.00000179) | (↓ 0.00000202) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-4 |   0.00004106   |   0.00004169   |    0.00004374   |   0.00004959   |   0.00006550   |
|         | (↓ 0.00000008) | (↓ 0.00000018) | (↓ -0.00000005) | (↓ 0.00000048) | (↓ 0.00000106) |
+---------+----------------+----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00002150   |   0.00001928   |   0.00001398   |   0.00001246   |   0.00001798   |
|         | (↓ 0.00000122) | (↓ 0.00000075) | (↓ 0.00000053) | (↓ 0.00000038) | (↓ 0.00000051) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00000908   |    0.00001001   |   0.00001030   |   0.00001054   |   0.00001249   |
|         | (↓ -0.00000025) | (↓ -0.00000015) | (↓ 0.00000001) | (↓ 0.00000001) | (↓ 0.00000007) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00000863   |   0.00000817   |   0.00000758   |   0.00000477   |   0.00000224   |
|         | (↓ 0.00000013) | (↓ 0.00000030) | (↓ 0.00000016) | (↓ 0.00000020) | (↓ 0.00000005) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-28 04:14:42,134 - block_trainer.py[357] - INFO: epoch 63 (409.697721s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00087517   |   0.00096999   |   0.00099134   |   0.00092812   |   0.00096286   |
|         | (↓ 0.00000357) | (↓ 0.00000704) | (↓ 0.00001108) | (↓ 0.00000762) | (↓ 0.00000577) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00001367   |    0.00003887   |    0.00008258   |   0.00022424   |   0.00039765   |
|         | (↓ -0.00000020) | (↓ -0.00000020) | (↓ -0.00000030) | (↓ 0.00000160) | (↓ 0.00000546) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00010681   |   0.00012897   |   0.00016435   |   0.00021030   |   0.00031573   |
|         | (↓ 0.00000192) | (↓ 0.00000137) | (↓ 0.00000176) | (↓ 0.00000177) | (↓ 0.00000013) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000377   |   0.00003404   |   0.00004754   |   0.00006310   |   0.00009802   |
|         | (↓ -0.00000008) | (↓ 0.00000049) | (↓ 0.00000085) | (↓ 0.00000150) | (↓ 0.00000183) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |   0.00004055   |    0.00004185   |    0.00004403   |    0.00005039   |    0.00006615   |
|         | (↓ 0.00000052) | (↓ -0.00000015) | (↓ -0.00000028) | (↓ -0.00000080) | (↓ -0.00000065) |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00002053   |   0.00001869   |   0.00001353   |   0.00001214   |   0.00001752   |
|         | (↓ 0.00000097) | (↓ 0.00000058) | (↓ 0.00000046) | (↓ 0.00000032) | (↓ 0.00000045) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00000945   |    0.00001006   |    0.00001042   |    0.00001073   |    0.00001260   |
|         | (↓ -0.00000037) | (↓ -0.00000005) | (↓ -0.00000012) | (↓ -0.00000019) | (↓ -0.00000011) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-7 |   0.00000848   |    0.00000822   |    0.00000759   |   0.00000476   |   0.00000221   |
|         | (↓ 0.00000015) | (↓ -0.00000005) | (↓ -0.00000001) | (↓ 0.00000001) | (↓ 0.00000003) |
+---------+----------------+-----------------+-----------------+----------------+----------------+

2023-06-28 04:21:31,667 - block_trainer.py[357] - INFO: epoch 64 (409.532467s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00092098   |    0.00101211   |    0.00102701   |    0.00096459   |    0.00100150   |
|         | (↓ -0.00004581) | (↓ -0.00004211) | (↓ -0.00003567) | (↓ -0.00003647) | (↓ -0.00003864) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00001397   |    0.00003917   |    0.00008282   |   0.00022387   |   0.00039386   |
|         | (↓ -0.00000029) | (↓ -0.00000030) | (↓ -0.00000024) | (↓ 0.00000037) | (↓ 0.00000379) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00010746   |    0.00012916   |    0.00016481   |    0.00021133   |    0.00031609   |
|         | (↓ -0.00000065) | (↓ -0.00000020) | (↓ -0.00000046) | (↓ -0.00000103) | (↓ -0.00000036) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00000388   |   0.00003362   |   0.00004675   |   0.00006190   |   0.00009652   |
|         | (↓ -0.00000011) | (↓ 0.00000042) | (↓ 0.00000079) | (↓ 0.00000120) | (↓ 0.00000150) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
| block-4 |    0.00004095   |    0.00004195   |   0.00004400   |    0.00005056   |    0.00006642   |
|         | (↓ -0.00000041) | (↓ -0.00000011) | (↓ 0.00000003) | (↓ -0.00000017) | (↓ -0.00000027) |
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00001963   |   0.00001816   |   0.00001313   |   0.00001182   |   0.00001708   |
|         | (↓ 0.00000090) | (↓ 0.00000053) | (↓ 0.00000040) | (↓ 0.00000032) | (↓ 0.00000045) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+----------------+-----------------+-----------------+
| block-6 |   0.00000885   |    0.00001007   |   0.00001040   |    0.00001076   |    0.00001262   |
|         | (↓ 0.00000060) | (↓ -0.00000001) | (↓ 0.00000003) | (↓ -0.00000003) | (↓ -0.00000002) |
+---------+----------------+-----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+-----------------+----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+-----------------+----------------+----------------+
| block-7 |   0.00000842   |   0.00000811   |    0.00000782   |   0.00000460   |   0.00000215   |
|         | (↓ 0.00000006) | (↓ 0.00000011) | (↓ -0.00000022) | (↓ 0.00000016) | (↓ 0.00000005) |
+---------+----------------+----------------+-----------------+----------------+----------------+

2023-06-28 04:21:31,702 - server_block_profiler.py[193] - INFO: raw block info: {"index": 0, "id": "block-0", "size": 315890, "FLOPs": 151781376.0, "param": 74112.0, "input_size": [64, 32, 32], "output_size": [64, 32, 32]}
2023-06-28 04:21:31,720 - server_block_profiler.py[193] - INFO: raw block info: {"index": 1, "id": "block-1", "size": 313409, "FLOPs": 151519232.0, "param": 73984.0, "input_size": [64, 32, 32], "output_size": [64, 32, 32]}
2023-06-28 04:21:31,740 - server_block_profiler.py[193] - INFO: raw block info: {"index": 2, "id": "block-2", "size": 899539, "FLOPs": 113377280.0, "param": 221440.0, "input_size": [64, 32, 32], "output_size": [128, 16, 16]}
2023-06-28 04:21:31,761 - server_block_profiler.py[193] - INFO: raw block info: {"index": 3, "id": "block-3", "size": 1200193, "FLOPs": 151257088.0, "param": 295424.0, "input_size": [128, 16, 16], "output_size": [128, 16, 16]}
2023-06-28 04:21:31,790 - server_block_profiler.py[193] - INFO: raw block info: {"index": 4, "id": "block-4", "size": 3555795, "FLOPs": 113311744.0, "param": 885248.0, "input_size": [128, 16, 16], "output_size": [256, 8, 8]}
2023-06-28 04:21:31,822 - server_block_profiler.py[193] - INFO: raw block info: {"index": 5, "id": "block-5", "size": 4743297, "FLOPs": 151126016.0, "param": 1180672.0, "input_size": [256, 8, 8], "output_size": [256, 8, 8]}
2023-06-28 04:21:31,860 - server_block_profiler.py[193] - INFO: raw block info: {"index": 6, "id": "block-6", "size": 14176723, "FLOPs": 113278976.0, "param": 3539968.0, "input_size": [256, 8, 8], "output_size": [512, 4, 4]}
2023-06-28 04:21:31,904 - server_block_profiler.py[193] - INFO: raw block info: {"index": 7, "id": "block-7", "size": 18907265, "FLOPs": 151060480.0, "param": 4720640.0, "input_size": [512, 4, 4], "output_size": [512, 4, 4]}
2023-06-28 04:21:37,421 - server_block_profiler.py[264] - INFO: profile blocks acc drop
2023-06-28 04:22:03,482 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:22:08,849 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:22:13,746 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:22:16,319 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:22:21,640 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:22:26,474 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:22:28,998 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:22:34,101 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:22:38,710 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:22:41,111 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:22:46,127 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:22:50,654 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:22:53,040 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:23:13,681 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:23:19,048 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2023-06-28 04:23:19,048 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:23:19,048 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2023-06-28 04:23:21,614 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:23:26,933 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2023-06-28 04:23:31,770 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2023-06-28 04:23:34,304 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:23:39,403 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2023-06-28 04:23:44,030 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2023-06-28 04:23:46,503 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:23:51,518 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2023-06-28 04:23:56,048 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2023-06-28 04:23:56,048 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:23:56,048 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:24:16,515 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:24:21,891 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2023-06-28 04:24:21,892 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:24:21,892 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2023-06-28 04:24:24,400 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:24:29,706 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2023-06-28 04:24:34,556 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2023-06-28 04:24:36,998 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:24:42,179 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2023-06-28 04:24:46,881 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2023-06-28 04:24:49,276 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:24:54,365 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2023-06-28 04:24:58,973 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2023-06-28 04:24:58,973 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:24:58,973 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:25:19,650 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:25:25,015 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2023-06-28 04:25:25,015 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:25:25,016 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2023-06-28 04:25:27,604 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:25:32,902 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2023-06-28 04:25:37,717 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2023-06-28 04:25:40,237 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:25:45,346 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2023-06-28 04:25:49,997 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2023-06-28 04:25:52,382 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:25:57,364 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2023-06-28 04:26:01,861 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2023-06-28 04:26:01,861 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:26:01,861 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:26:22,244 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:26:27,670 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2023-06-28 04:26:27,670 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:26:27,670 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2023-06-28 04:26:30,166 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:26:35,468 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2023-06-28 04:26:40,269 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2023-06-28 04:26:42,712 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:26:47,904 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2023-06-28 04:26:52,588 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2023-06-28 04:26:54,985 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:27:00,085 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2023-06-28 04:27:04,680 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2023-06-28 04:27:04,680 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:27:04,680 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:27:25,304 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:27:30,681 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2023-06-28 04:27:30,681 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:27:30,682 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2023-06-28 04:27:33,274 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:27:38,513 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2023-06-28 04:27:43,257 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2023-06-28 04:27:45,730 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:27:50,846 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2023-06-28 04:27:55,466 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2023-06-28 04:27:57,852 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:28:02,846 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2023-06-28 04:28:07,343 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2023-06-28 04:28:07,343 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:28:07,344 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:28:27,864 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:28:33,212 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2023-06-28 04:28:33,212 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:28:33,213 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2023-06-28 04:28:35,696 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:28:40,957 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2023-06-28 04:28:45,760 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2023-06-28 04:28:48,168 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:28:53,349 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2023-06-28 04:28:58,069 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2023-06-28 04:29:00,459 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:29:05,537 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2023-06-28 04:29:10,147 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2023-06-28 04:29:10,147 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:29:10,147 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:29:30,954 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:29:36,288 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2023-06-28 04:29:36,289 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-28 04:29:36,289 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2023-06-28 04:29:38,850 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:29:44,066 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2023-06-28 04:29:48,840 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2023-06-28 04:29:51,286 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:29:56,404 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2023-06-28 04:30:01,069 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2023-06-28 04:30:03,467 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-28 04:30:08,447 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2023-06-28 04:30:12,985 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2023-06-28 04:30:12,985 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-28 04:30:12,986 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.0) acc drop: -0.00010000014056762059
2023-06-28 04:30:12,995 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-28 04:30:12,995 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.2) acc drop: -0.0001666666939854622
2023-06-28 04:30:13,003 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.2) size drop: 55360B (0.053MB), FLOPs drop: 28.361M, param drop: 0.014M
2023-06-28 04:30:13,003 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.4) acc drop: -0.00013333341727654138
2023-06-28 04:30:13,011 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.4) size drop: 115520B (0.110MB), FLOPs drop: 59.085M, param drop: 0.029M
2023-06-28 04:30:13,012 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.6) acc drop: -0.00013333341727654138
2023-06-28 04:30:13,020 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.6) size drop: 175680B (0.168MB), FLOPs drop: 89.809M, param drop: 0.044M
2023-06-28 04:30:13,020 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.8) acc drop: -0.00013333341727654138
2023-06-28 04:30:13,029 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.8) size drop: 235840B (0.225MB), FLOPs drop: 120.533M, param drop: 0.059M
2023-06-28 04:30:13,030 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.0) acc drop: 0.0
2023-06-28 04:30:13,038 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-28 04:30:13,038 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.2) acc drop: 3.33332767089208e-05
2023-06-28 04:30:13,046 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.2) size drop: 55360B (0.053MB), FLOPs drop: 28.361M, param drop: 0.014M
2023-06-28 04:30:13,047 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.4) acc drop: 0.0
2023-06-28 04:30:13,055 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.4) size drop: 115520B (0.110MB), FLOPs drop: 59.085M, param drop: 0.029M
2023-06-28 04:30:13,055 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.6) acc drop: 3.33332767089208e-05
2023-06-28 04:30:13,064 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.6) size drop: 175680B (0.168MB), FLOPs drop: 89.809M, param drop: 0.044M
2023-06-28 04:30:13,064 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.8) acc drop: 0.0
2023-06-28 04:30:13,072 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.8) size drop: 235840B (0.225MB), FLOPs drop: 120.533M, param drop: 0.059M
2023-06-28 04:30:13,073 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.0) acc drop: 6.66665534178416e-05
2023-06-28 04:30:13,083 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-28 04:30:13,083 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.2) acc drop: 9.999983012676239e-05
2023-06-28 04:30:13,094 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.2) size drop: 173056B (0.165MB), FLOPs drop: 22.144M, param drop: 0.043M
2023-06-28 04:30:13,094 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.4) acc drop: 0.0001333331068356832
2023-06-28 04:30:13,103 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.4) size drop: 353280B (0.337MB), FLOPs drop: 45.174M, param drop: 0.088M
2023-06-28 04:30:13,103 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.6) acc drop: 6.66665534178416e-05
2023-06-28 04:30:13,111 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.6) size drop: 526336B (0.502MB), FLOPs drop: 67.318M, param drop: 0.131M
2023-06-28 04:30:13,112 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.8) acc drop: 0.0001333331068356832
2023-06-28 04:30:13,118 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.8) size drop: 706560B (0.674MB), FLOPs drop: 90.348M, param drop: 0.176M
2023-06-28 04:30:13,119 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.0) acc drop: -3.33332767089208e-05
2023-06-28 04:30:13,129 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-28 04:30:13,129 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.2) acc drop: 6.66665534178416e-05
2023-06-28 04:30:13,139 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.2) size drop: 230720B (0.220MB), FLOPs drop: 29.517M, param drop: 0.058M
2023-06-28 04:30:13,139 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.4) acc drop: 3.33332767089208e-05
2023-06-28 04:30:13,147 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.4) size drop: 470848B (0.449MB), FLOPs drop: 60.214M, param drop: 0.118M
2023-06-28 04:30:13,148 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.6) acc drop: 9.999983012676239e-05
2023-06-28 04:30:13,155 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.6) size drop: 701504B (0.669MB), FLOPs drop: 89.731M, param drop: 0.175M
2023-06-28 04:30:13,155 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.8) acc drop: 3.33332767089208e-05
2023-06-28 04:30:13,163 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.8) size drop: 941632B (0.898MB), FLOPs drop: 120.429M, param drop: 0.235M
2023-06-28 04:30:13,163 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.0) acc drop: -0.00016666638354460397
2023-06-28 04:30:13,175 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-28 04:30:13,175 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.2) acc drop: 3.3333587149779e-05
2023-06-28 04:30:13,186 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.2) size drop: 705792B (0.673MB), FLOPs drop: 22.574M, param drop: 0.176M
2023-06-28 04:30:13,186 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.4) acc drop: 3.104408582051595e-10
2023-06-28 04:30:13,195 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.4) size drop: 1411584B (1.346MB), FLOPs drop: 45.148M, param drop: 0.353M
2023-06-28 04:30:13,195 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.6) acc drop: 3.104408582051595e-10
2023-06-28 04:30:13,203 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.6) size drop: 2117376B (2.019MB), FLOPs drop: 67.721M, param drop: 0.529M
2023-06-28 04:30:13,203 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.8) acc drop: -6.66665534178416e-05
2023-06-28 04:30:13,210 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.8) size drop: 2823168B (2.692MB), FLOPs drop: 90.295M, param drop: 0.705M
2023-06-28 04:30:13,210 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.0) acc drop: -3.33332767089208e-05
2023-06-28 04:30:13,228 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-28 04:30:13,228 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.2) acc drop: 0.0
2023-06-28 04:30:13,246 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.2) size drop: 940928B (0.897MB), FLOPs drop: 30.094M, param drop: 0.235M
2023-06-28 04:30:13,246 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.4) acc drop: -6.66665534178416e-05
2023-06-28 04:30:13,262 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.4) size drop: 1881728B (1.795MB), FLOPs drop: 60.188M, param drop: 0.470M
2023-06-28 04:30:13,263 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.6) acc drop: -9.999983012676239e-05
2023-06-28 04:30:13,278 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.6) size drop: 2822528B (2.692MB), FLOPs drop: 90.282M, param drop: 0.705M
2023-06-28 04:30:13,279 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.8) acc drop: 0.0
2023-06-28 04:30:13,292 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.8) size drop: 3763328B (3.589MB), FLOPs drop: 120.376M, param drop: 0.940M
2023-06-28 04:30:13,292 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.0) acc drop: -0.00013333341727654138
2023-06-28 04:30:13,341 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-28 04:30:13,341 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.2) acc drop: -0.00010000014056762059
2023-06-28 04:30:13,367 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.2) size drop: 2821632B (2.691MB), FLOPs drop: 22.567M, param drop: 0.705M
2023-06-28 04:30:13,367 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.4) acc drop: -3.33332767089208e-05
2023-06-28 04:30:13,388 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.4) size drop: 5643264B (5.382MB), FLOPs drop: 45.135M, param drop: 1.410M
2023-06-28 04:30:13,388 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.6) acc drop: -6.66665534178416e-05
2023-06-28 04:30:13,404 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.6) size drop: 8492800B (8.099MB), FLOPs drop: 67.923M, param drop: 2.123M
2023-06-28 04:30:13,404 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.8) acc drop: -0.00010000014056762059
2023-06-28 04:30:13,416 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.8) size drop: 11314432B (10.790MB), FLOPs drop: 90.490M, param drop: 2.828M
2023-06-28 04:30:13,417 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.0) acc drop: -9.999983012676239e-05
2023-06-28 04:30:13,479 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-28 04:30:13,479 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.2) acc drop: -9.999983012676239e-05
2023-06-28 04:30:13,527 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.2) size drop: 3761728B (3.587MB), FLOPs drop: 30.088M, param drop: 0.940M
2023-06-28 04:30:13,527 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.4) acc drop: -0.00023333293696244559
2023-06-28 04:30:13,557 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.4) size drop: 7523392B (7.175MB), FLOPs drop: 60.175M, param drop: 1.880M
2023-06-28 04:30:13,557 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.6) acc drop: -3.33332767089208e-05
2023-06-28 04:30:13,577 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.6) size drop: 11322240B (10.798MB), FLOPs drop: 90.558M, param drop: 2.830M
2023-06-28 04:30:13,578 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.8) acc drop: 3.3333587149779e-05
2023-06-28 04:30:13,592 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.8) size drop: 15083904B (14.385MB), FLOPs drop: 120.645M, param drop: 3.770M
2023-06-28 04:30:13,806 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 0, "id": "block-0", "latency": 0.0009506745600700381}
2023-06-28 04:30:13,972 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 1, "id": "block-1", "latency": 0.0008079411184787749}
2023-06-28 04:30:14,083 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 2, "id": "block-2", "latency": 0.0005906998383998869}
2023-06-28 04:30:14,245 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 3, "id": "block-3", "latency": 0.0007941721618175507}
2023-06-28 04:30:14,372 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 4, "id": "block-4", "latency": 0.0007415830421447754}
2023-06-28 04:30:14,538 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 5, "id": "block-5", "latency": 0.0008191667211055753}
2023-06-28 04:30:14,733 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 6, "id": "block-6", "latency": 0.0010053964787721634}
2023-06-28 04:30:14,992 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 7, "id": "block-7", "latency": 0.0013386131203174591}
2023-06-28 04:30:14,996 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2023-06-28 04:30:15,001 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.0) from file
2023-06-28 04:30:15,005 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-28 04:30:15,008 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2023-06-28 04:30:15,012 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-28 04:30:15,016 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2023-06-28 04:30:15,022 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.0) from file
2023-06-28 04:30:15,030 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.0) from file
2023-06-28 04:30:15,041 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.0) from file
2023-06-28 04:30:16,044 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-28 04:30:16,226 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.2) latency rel drop: -0.756% (0.001s -> 0.001s)
2023-06-28 04:30:16,410 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.4) latency rel drop: -1.437% (0.001s -> 0.001s)
2023-06-28 04:30:16,590 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.6) latency rel drop: 0.317% (0.001s -> 0.001s)
2023-06-28 04:30:16,772 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.8) latency rel drop: 0.197% (0.001s -> 0.001s)
2023-06-28 04:30:17,091 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-28 04:30:17,249 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.2) latency rel drop: 0.909% (0.001s -> 0.001s)
2023-06-28 04:30:17,409 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.4) latency rel drop: -0.530% (0.001s -> 0.001s)
2023-06-28 04:30:17,567 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.6) latency rel drop: 1.074% (0.001s -> 0.001s)
2023-06-28 04:30:17,727 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.8) latency rel drop: -0.709% (0.001s -> 0.001s)
2023-06-28 04:30:17,943 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-28 04:30:18,048 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.2) latency rel drop: 5.270% (0.001s -> 0.001s)
2023-06-28 04:30:18,149 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.4) latency rel drop: 10.229% (0.001s -> 0.001s)
2023-06-28 04:30:18,248 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.6) latency rel drop: 14.814% (0.001s -> 0.000s)
2023-06-28 04:30:18,346 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.8) latency rel drop: 15.612% (0.001s -> 0.000s)
2023-06-28 04:30:18,666 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-28 04:30:18,825 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.2) latency rel drop: -0.141% (0.001s -> 0.001s)
2023-06-28 04:30:18,984 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.4) latency rel drop: 0.643% (0.001s -> 0.001s)
2023-06-28 04:30:19,143 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.6) latency rel drop: 0.967% (0.001s -> 0.001s)
2023-06-28 04:30:19,304 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.8) latency rel drop: -1.982% (0.001s -> 0.001s)
2023-06-28 04:30:19,549 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-28 04:30:19,666 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.2) latency rel drop: 7.238% (0.001s -> 0.001s)
2023-06-28 04:30:19,775 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.4) latency rel drop: 15.307% (0.001s -> 0.001s)
2023-06-28 04:30:19,881 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.6) latency rel drop: 22.652% (0.001s -> 0.001s)
2023-06-28 04:30:19,979 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.8) latency rel drop: 30.873% (0.001s -> 0.000s)
2023-06-28 04:30:20,304 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-28 04:30:20,463 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.2) latency rel drop: 4.383% (0.001s -> 0.001s)
2023-06-28 04:30:20,621 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.4) latency rel drop: 4.960% (0.001s -> 0.001s)
2023-06-28 04:30:20,778 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.6) latency rel drop: 5.254% (0.001s -> 0.001s)
2023-06-28 04:30:20,937 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.8) latency rel drop: 4.005% (0.001s -> 0.001s)
2023-06-28 04:30:21,324 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-28 04:30:21,494 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.2) latency rel drop: 11.327% (0.001s -> 0.001s)
2023-06-28 04:30:21,642 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.4) latency rel drop: 22.059% (0.001s -> 0.001s)
2023-06-28 04:30:21,765 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.6) latency rel drop: 33.581% (0.001s -> 0.001s)
2023-06-28 04:30:21,870 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.8) latency rel drop: 44.386% (0.001s -> 0.001s)
2023-06-28 04:30:22,387 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-28 04:30:22,622 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.2) latency rel drop: 8.346% (0.001s -> 0.001s)
2023-06-28 04:30:22,833 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.4) latency rel drop: 16.874% (0.001s -> 0.001s)
2023-06-28 04:30:23,020 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.6) latency rel drop: 26.164% (0.001s -> 0.001s)
2023-06-28 04:30:23,187 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.8) latency rel drop: 35.019% (0.001s -> 0.001s)
2023-06-28 04:30:23,187 - optimal_runtime.py[21] - INFO: init adaptive model runtime
2023-06-28 04:30:23,246 - optimal_runtime.py[147] - INFO: load blocks metrics
2023-06-28 04:30:23,263 - optimal_runtime.py[176] - INFO: load model metrics
2023-06-28 04:30:23,267 - optimal_runtime.py[187] - INFO: load sparest blocks for initializing model
2023-06-28 04:30:23,267 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:23,271 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.8) from file
2023-06-28 04:30:23,275 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.8) from file
2023-06-28 04:30:23,277 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.8) from file
2023-06-28 04:30:23,280 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.8) from file
2023-06-28 04:30:23,283 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.8) from file
2023-06-28 04:30:23,287 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.8) from file
2023-06-28 04:30:23,290 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.8) from file
2023-06-28 04:30:23,295 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.8) from file
2023-06-28 04:30:23,412 - gen_series_legodnn_models.py[17] - INFO: min model size: 0.908MB, max model size: 43.886MB
2023-06-28 04:30:23,413 - gen_series_legodnn_models.py[28] - INFO: target model size: 0.908MB
2023-06-28 04:30:23,413 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 951737.0B (0.908MB), try to adapt blocks
2023-06-28 04:30:23,417 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:23,430 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010022560119628906
2023-06-28 04:30:23,430 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006014400087296963, 0.0004701760113239288, 0.000335999995470047, 0.0005807360000908374, 0.0003869439959526062, 0.000626303993165493, 0.0005887679979205132, 0.000949920006096363]
2023-06-28 04:30:23,431 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.578
2023-06-28 04:30:23,431 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.731
2023-06-28 04:30:23,431 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.484
2023-06-28 04:30:23,431 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.395
2023-06-28 04:30:23,431 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.325
2023-06-28 04:30:23,431 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.256
2023-06-28 04:30:23,431 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.950
2023-06-28 04:30:23,431 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.916
2023-06-28 04:30:23,433 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:23,433 - optimal_runtime.py[116] - INFO: avg ratio: 1.4072254375581277
2023-06-28 04:30:23,433 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029882557108966575
2023-06-28 04:30:23,434 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060263 0.00046686 0.00039816 0.00056945 0.00055976 0.00065243
 0.00105867 0.00146184]
2023-06-28 04:30:23,438 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:23,544 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:23,544 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:23,546 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060263 0.00046686 0.00039816 0.00056945 0.00055976 0.00065243
 0.00105867 0.00146184]
2023-06-28 04:30:23,547 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:23,629 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:23,629 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:23,631 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060263 0.00046686 0.00039816 0.00056945 0.00055976 0.00065243
 0.00105867 0.00146184]
2023-06-28 04:30:23,633 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:23,742 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:23,743 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:23,743 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 239746944.0,
  'blocks_sparsity': [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.0017587301173106818,
  'esti_test_accuracy': 0.00930000034471353,
  'is_relaxed': True,
  'model_size': 9864333.0,
  'update_swap_mem_cost': 0,
  'update_swap_time_cost': 0.000148773193359375}
2023-06-28 04:30:23,764 - gen_series_legodnn_models.py[28] - INFO: target model size: 1.342MB
2023-06-28 04:30:23,764 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 1406947.8686868688B (1.342MB), try to adapt blocks
2023-06-28 04:30:23,766 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:23,779 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009612031936645508
2023-06-28 04:30:23,779 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006044160015881063, 0.00044899199157953266, 0.00032582399994134906, 0.00046825599670410157, 0.00038729599118232725, 0.0006216320134699345, 0.000578976009041071, 0.0009424960240721702]
2023-06-28 04:30:23,779 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.570
2023-06-28 04:30:23,779 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.812
2023-06-28 04:30:23,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.530
2023-06-28 04:30:23,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.730
2023-06-28 04:30:23,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.324
2023-06-28 04:30:23,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.265
2023-06-28 04:30:23,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.966
2023-06-28 04:30:23,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.923
2023-06-28 04:30:23,780 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:23,780 - optimal_runtime.py[116] - INFO: avg ratio: 1.4220731330917162
2023-06-28 04:30:23,780 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029570556903495853
2023-06-28 04:30:23,781 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060561 0.00044583 0.0003861  0.00045915 0.00056027 0.00064757
 0.00104107 0.00145042]
2023-06-28 04:30:23,783 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:23,874 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:23,874 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:23,876 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060561 0.00044583 0.0003861  0.00045915 0.00056027 0.00064757
 0.00104107 0.00145042]
2023-06-28 04:30:23,878 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:23,986 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:23,986 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:23,988 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060561 0.00044583 0.0003861  0.00045915 0.00056027 0.00064757
 0.00104107 0.00145042]
2023-06-28 04:30:23,990 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:24,079 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:24,080 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:24,080 - gen_series_legodnn_models.py[28] - INFO: target model size: 1.776MB
2023-06-28 04:30:24,080 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 1862158.7373737374B (1.776MB), try to adapt blocks
2023-06-28 04:30:24,082 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:24,097 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01069315242767334
2023-06-28 04:30:24,097 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006419200040400028, 0.0004567359983921051, 0.0003421759977936744, 0.000472960002720356, 0.0003680319972336292, 0.0006060480140149593, 0.0006732800006866455, 0.0009713279753923416]
2023-06-28 04:30:24,097 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.478
2023-06-28 04:30:24,097 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.781
2023-06-28 04:30:24,097 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.457
2023-06-28 04:30:24,097 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.712
2023-06-28 04:30:24,097 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.393
2023-06-28 04:30:24,097 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.298
2023-06-28 04:30:24,097 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.830
2023-06-28 04:30:24,098 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.896
2023-06-28 04:30:24,098 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:24,098 - optimal_runtime.py[116] - INFO: avg ratio: 1.4063194254473201
2023-06-28 04:30:24,098 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002990180875134079
2023-06-28 04:30:24,098 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064319 0.00045352 0.00040548 0.00046377 0.0005324  0.00063133
 0.00121064 0.00149479]
2023-06-28 04:30:24,100 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:24,201 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:24,201 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:24,204 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064319 0.00045352 0.00040548 0.00046377 0.0005324  0.00063133
 0.00121064 0.00149479]
2023-06-28 04:30:24,205 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:24,291 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:24,291 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:24,294 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064319 0.00045352 0.00040548 0.00046377 0.0005324  0.00063133
 0.00121064 0.00149479]
2023-06-28 04:30:24,295 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:24,401 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:24,402 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:24,402 - gen_series_legodnn_models.py[28] - INFO: target model size: 2.210MB
2023-06-28 04:30:24,402 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 2317369.606060606B (2.210MB), try to adapt blocks
2023-06-28 04:30:24,404 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:24,417 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009618880271911621
2023-06-28 04:30:24,417 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000597120001912117, 0.00043209599703550344, 0.0003186879977583885, 0.00045427199825644486, 0.00037574400007724763, 0.000607775989919901, 0.0005638400092720985, 0.0009243519753217698]
2023-06-28 04:30:24,418 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.589
2023-06-28 04:30:24,418 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.883
2023-06-28 04:30:24,418 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.564
2023-06-28 04:30:24,418 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.783
2023-06-28 04:30:24,418 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.364
2023-06-28 04:30:24,418 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.294
2023-06-28 04:30:24,418 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.992
2023-06-28 04:30:24,418 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.941
2023-06-28 04:30:24,418 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:24,419 - optimal_runtime.py[116] - INFO: avg ratio: 1.4528158401368432
2023-06-28 04:30:24,419 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002894482104425591
2023-06-28 04:30:24,419 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005983  0.00042905 0.00037764 0.00044544 0.00054356 0.00063313
 0.00101385 0.00142249]
2023-06-28 04:30:24,421 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:24,505 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:24,505 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:24,507 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005983  0.00042905 0.00037764 0.00044544 0.00054356 0.00063313
 0.00101385 0.00142249]
2023-06-28 04:30:24,509 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:24,609 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:24,609 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:24,611 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005983  0.00042905 0.00037764 0.00044544 0.00054356 0.00063313
 0.00101385 0.00142249]
2023-06-28 04:30:24,613 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:24,694 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:24,695 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:24,695 - gen_series_legodnn_models.py[28] - INFO: target model size: 2.644MB
2023-06-28 04:30:24,695 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 2772580.474747475B (2.644MB), try to adapt blocks
2023-06-28 04:30:24,697 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:24,709 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009186592102050781
2023-06-28 04:30:24,710 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005525439977645874, 0.0004215039983391762, 0.0003087040074169636, 0.0004862079955637455, 0.00036182399094104764, 0.0005907839983701706, 0.0005515200160443783, 0.0009243519864976404]
2023-06-28 04:30:24,710 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.717
2023-06-28 04:30:24,710 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.930
2023-06-28 04:30:24,710 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.615
2023-06-28 04:30:24,710 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.666
2023-06-28 04:30:24,710 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.417
2023-06-28 04:30:24,710 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.331
2023-06-28 04:30:24,710 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.014
2023-06-28 04:30:24,710 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.941
2023-06-28 04:30:24,710 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:24,711 - optimal_runtime.py[116] - INFO: avg ratio: 1.5491031923562133
2023-06-28 04:30:24,711 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002714570256553417
2023-06-28 04:30:24,711 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00055364 0.00041854 0.00036581 0.00047676 0.00052342 0.00061543
 0.0009917  0.00142249]
2023-06-28 04:30:24,713 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:24,807 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:24,808 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:24,810 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00055364 0.00041854 0.00036581 0.00047676 0.00052342 0.00061543
 0.0009917  0.00142249]
2023-06-28 04:30:24,811 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:24,898 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:24,898 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:24,900 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00055364 0.00041854 0.00036581 0.00047676 0.00052342 0.00061543
 0.0009917  0.00142249]
2023-06-28 04:30:24,902 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,005 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,006 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:25,007 - gen_series_legodnn_models.py[28] - INFO: target model size: 3.078MB
2023-06-28 04:30:25,007 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 3227791.3434343436B (3.078MB), try to adapt blocks
2023-06-28 04:30:25,008 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:25,023 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01043769645690918
2023-06-28 04:30:25,024 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007308159917593001, 0.0005045760050415993, 0.0003385599963366985, 0.0004755839928984642, 0.0003906560018658638, 0.0006240640096366406, 0.000577088002115488, 0.0009365760348737241]
2023-06-28 04:30:25,024 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.298
2023-06-28 04:30:25,024 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.613
2023-06-28 04:30:25,024 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.472
2023-06-28 04:30:25,024 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.703
2023-06-28 04:30:25,024 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.312
2023-06-28 04:30:25,024 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.260
2023-06-28 04:30:25,024 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.969
2023-06-28 04:30:25,024 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.929
2023-06-28 04:30:25,025 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:25,025 - optimal_runtime.py[116] - INFO: avg ratio: 1.3357305093340774
2023-06-28 04:30:25,025 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031482019920309984
2023-06-28 04:30:25,025 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00073226 0.00050102 0.00040119 0.00046634 0.00056513 0.0006501
 0.00103767 0.00144131]
2023-06-28 04:30:25,027 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,112 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,112 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:25,114 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00073226 0.00050102 0.00040119 0.00046634 0.00056513 0.0006501
 0.00103767 0.00144131]
2023-06-28 04:30:25,116 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,191 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,191 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:25,194 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00073226 0.00050102 0.00040119 0.00046634 0.00056513 0.0006501
 0.00103767 0.00144131]
2023-06-28 04:30:25,195 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,285 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,286 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:25,287 - gen_series_legodnn_models.py[28] - INFO: target model size: 3.512MB
2023-06-28 04:30:25,287 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 3683002.212121212B (3.512MB), try to adapt blocks
2023-06-28 04:30:25,289 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:25,304 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011649632453918457
2023-06-28 04:30:25,305 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007524799928069115, 0.00045683199912309653, 0.00035609600692987445, 0.0005941119864583016, 0.00038294399902224536, 0.0006611520200967788, 0.0005815040096640587, 0.001025087997317314]
2023-06-28 04:30:25,305 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.261
2023-06-28 04:30:25,305 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.781
2023-06-28 04:30:25,305 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.400
2023-06-28 04:30:25,305 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.363
2023-06-28 04:30:25,305 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.339
2023-06-28 04:30:25,305 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.189
2023-06-28 04:30:25,305 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.962
2023-06-28 04:30:25,305 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.849
2023-06-28 04:30:25,306 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:25,306 - optimal_runtime.py[116] - INFO: avg ratio: 1.3104030259447284
2023-06-28 04:30:25,306 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003209050473056136
2023-06-28 04:30:25,306 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00075397 0.00045361 0.00042197 0.00058256 0.00055397 0.00068874
 0.00104561 0.00157752]
2023-06-28 04:30:25,308 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,403 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,403 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:25,406 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00075397 0.00045361 0.00042197 0.00058256 0.00055397 0.00068874
 0.00104561 0.00157752]
2023-06-28 04:30:25,407 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,490 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,490 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:25,492 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00075397 0.00045361 0.00042197 0.00058256 0.00055397 0.00068874
 0.00104561 0.00157752]
2023-06-28 04:30:25,494 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,589 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,590 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:25,591 - gen_series_legodnn_models.py[28] - INFO: target model size: 3.947MB
2023-06-28 04:30:25,591 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 4138213.0808080807B (3.947MB), try to adapt blocks
2023-06-28 04:30:25,593 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:25,607 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01020844841003418
2023-06-28 04:30:25,607 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006120960041880607, 0.0004388480000197888, 0.00034841599315404894, 0.0005585599914193153, 0.00042185599356889725, 0.000608288001269102, 0.0005842560082674026, 0.0009285440035164356]
2023-06-28 04:30:25,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.550
2023-06-28 04:30:25,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.854
2023-06-28 04:30:25,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.431
2023-06-28 04:30:25,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.450
2023-06-28 04:30:25,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.215
2023-06-28 04:30:25,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.293
2023-06-28 04:30:25,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.957
2023-06-28 04:30:25,608 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.937
2023-06-28 04:30:25,608 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:25,608 - optimal_runtime.py[116] - INFO: avg ratio: 1.3877424735787849
2023-06-28 04:30:25,608 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030302087962024086
2023-06-28 04:30:25,608 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061331 0.00043576 0.00041287 0.0005477  0.00061027 0.00063367
 0.00105056 0.00142895]
2023-06-28 04:30:25,610 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,690 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,690 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:25,693 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061331 0.00043576 0.00041287 0.0005477  0.00061027 0.00063367
 0.00105056 0.00142895]
2023-06-28 04:30:25,694 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,788 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,789 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:25,791 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061331 0.00043576 0.00041287 0.0005477  0.00061027 0.00063367
 0.00105056 0.00142895]
2023-06-28 04:30:25,793 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:25,885 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:25,885 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:25,886 - gen_series_legodnn_models.py[28] - INFO: target model size: 4.381MB
2023-06-28 04:30:25,886 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 4593423.94949495B (4.381MB), try to adapt blocks
2023-06-28 04:30:25,888 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:25,901 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009709471702575684
2023-06-28 04:30:25,901 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006280639991164208, 0.0004525120072066784, 0.0003160959891974926, 0.00046489600464701657, 0.0003752000071108341, 0.0006114240065217019, 0.0005643520131707191, 0.0009399039894342423]
2023-06-28 04:30:25,901 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.511
2023-06-28 04:30:25,901 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.798
2023-06-28 04:30:25,901 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.577
2023-06-28 04:30:25,901 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.742
2023-06-28 04:30:25,901 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.366
2023-06-28 04:30:25,901 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.286
2023-06-28 04:30:25,901 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.991
2023-06-28 04:30:25,901 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.925
2023-06-28 04:30:25,902 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:25,902 - optimal_runtime.py[116] - INFO: avg ratio: 1.43501553865992
2023-06-28 04:30:25,902 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029303860042024874
2023-06-28 04:30:25,903 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062931 0.00044933 0.00037457 0.00045586 0.00054277 0.00063693
 0.00101477 0.00144643]
2023-06-28 04:30:25,904 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,010 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,010 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:26,012 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062931 0.00044933 0.00037457 0.00045586 0.00054277 0.00063693
 0.00101477 0.00144643]
2023-06-28 04:30:26,014 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,094 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,095 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:26,097 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062931 0.00044933 0.00037457 0.00045586 0.00054277 0.00063693
 0.00101477 0.00144643]
2023-06-28 04:30:26,098 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,206 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,206 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:26,207 - gen_series_legodnn_models.py[28] - INFO: target model size: 4.815MB
2023-06-28 04:30:26,207 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 5048634.818181818B (4.815MB), try to adapt blocks
2023-06-28 04:30:26,209 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:26,222 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010101728439331055
2023-06-28 04:30:26,223 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005627200119197369, 0.0005150720030069351, 0.0004368320032954215, 0.00046694399788975715, 0.00037955200299620627, 0.0006191040091216564, 0.0005667839944362641, 0.0009432320334017277]
2023-06-28 04:30:26,223 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.686
2023-06-28 04:30:26,223 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.580
2023-06-28 04:30:26,223 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.141
2023-06-28 04:30:26,223 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.734
2023-06-28 04:30:26,223 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.351
2023-06-28 04:30:26,223 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.270
2023-06-28 04:30:26,223 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-28 04:30:26,223 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.922
2023-06-28 04:30:26,223 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2023-06-28 04:30:26,224 - optimal_runtime.py[116] - INFO: avg ratio: 1.3354075825278189
2023-06-28 04:30:26,224 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031489632868057513
2023-06-28 04:30:26,224 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00056383 0.00051144 0.00051765 0.00045787 0.00054907 0.00064493
 0.00101914 0.00145155]
2023-06-28 04:30:26,226 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,306 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,306 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:26,309 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00056383 0.00051144 0.00051765 0.00045787 0.00054907 0.00064493
 0.00101914 0.00145155]
2023-06-28 04:30:26,310 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,386 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,387 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:26,389 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00056383 0.00051144 0.00051765 0.00045787 0.00054907 0.00064493
 0.00101914 0.00145155]
2023-06-28 04:30:26,390 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,480 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,481 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:26,481 - gen_series_legodnn_models.py[28] - INFO: target model size: 5.249MB
2023-06-28 04:30:26,481 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 5503845.686868687B (5.249MB), try to adapt blocks
2023-06-28 04:30:26,483 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:26,499 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011954336166381837
2023-06-28 04:30:26,500 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0008373120129108429, 0.00046924799680709835, 0.0005151680037379265, 0.0005102719999849797, 0.0004224640056490898, 0.000690591998398304, 0.0005954880043864251, 0.0010199039839208124]
2023-06-28 04:30:26,500 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.133
2023-06-28 04:30:26,500 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.734
2023-06-28 04:30:26,500 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.968
2023-06-28 04:30:26,500 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.587
2023-06-28 04:30:26,500 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.213
2023-06-28 04:30:26,500 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.139
2023-06-28 04:30:26,500 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.939
2023-06-28 04:30:26,500 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.853
2023-06-28 04:30:26,501 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5, 6]),)
2023-06-28 04:30:26,501 - optimal_runtime.py[116] - INFO: avg ratio: 1.0783640034439057
2023-06-28 04:30:26,501 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003899564003316498
2023-06-28 04:30:26,502 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00083897 0.00046594 0.00061047 0.00050035 0.00061114 0.0007194
 0.00107076 0.00156954]
2023-06-28 04:30:26,504 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,595 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,595 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:26,597 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00083897 0.00046594 0.00061047 0.00050035 0.00061114 0.0007194
 0.00107076 0.00156954]
2023-06-28 04:30:26,599 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,674 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,674 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:26,676 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00083897 0.00046594 0.00061047 0.00050035 0.00061114 0.0007194
 0.00107076 0.00156954]
2023-06-28 04:30:26,678 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,782 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,782 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:26,782 - gen_series_legodnn_models.py[28] - INFO: target model size: 5.683MB
2023-06-28 04:30:26,782 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 5959056.555555556B (5.683MB), try to adapt blocks
2023-06-28 04:30:26,784 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:26,799 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010069151878356934
2023-06-28 04:30:26,799 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005831679962575436, 0.00042966400459408755, 0.0003059200048446655, 0.0004366400055587291, 0.00036511999368667603, 0.0006082239896059037, 0.0005560960024595261, 0.0009164160341024399]
2023-06-28 04:30:26,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.627
2023-06-28 04:30:26,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.894
2023-06-28 04:30:26,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.629
2023-06-28 04:30:26,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.855
2023-06-28 04:30:26,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.404
2023-06-28 04:30:26,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.293
2023-06-28 04:30:26,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.005
2023-06-28 04:30:26,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.949
2023-06-28 04:30:26,800 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:26,800 - optimal_runtime.py[116] - INFO: avg ratio: 1.4883264403762901
2023-06-28 04:30:26,800 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028254214507127512
2023-06-28 04:30:26,800 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058432 0.00042664 0.00036251 0.00042815 0.00052819 0.0006336
 0.00099993 0.00141028]
2023-06-28 04:30:26,802 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,888 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,889 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:26,891 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058432 0.00042664 0.00036251 0.00042815 0.00052819 0.0006336
 0.00099993 0.00141028]
2023-06-28 04:30:26,892 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:26,969 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:26,969 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:26,971 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058432 0.00042664 0.00036251 0.00042815 0.00052819 0.0006336
 0.00099993 0.00141028]
2023-06-28 04:30:26,973 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,063 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,064 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:27,064 - gen_series_legodnn_models.py[28] - INFO: target model size: 6.117MB
2023-06-28 04:30:27,064 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 6414267.424242424B (6.117MB), try to adapt blocks
2023-06-28 04:30:27,066 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:27,081 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011089088439941407
2023-06-28 04:30:27,082 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0008031040057539941, 0.000516064003109932, 0.00034240000694990157, 0.00046348800510168076, 0.0004563519917428493, 0.0006870720013976097, 0.0006228800192475319, 0.0009426240175962448]
2023-06-28 04:30:27,082 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.181
2023-06-28 04:30:27,082 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.577
2023-06-28 04:30:27,082 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.456
2023-06-28 04:30:27,082 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.747
2023-06-28 04:30:27,082 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.123
2023-06-28 04:30:27,082 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.145
2023-06-28 04:30:27,082 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.898
2023-06-28 04:30:27,082 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.923
2023-06-28 04:30:27,083 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:27,083 - optimal_runtime.py[116] - INFO: avg ratio: 1.2262723661461739
2023-06-28 04:30:27,083 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003429213253428938
2023-06-28 04:30:27,084 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00080469 0.00051243 0.00040574 0.00045448 0.00066017 0.00071574
 0.00112001 0.00145061]
2023-06-28 04:30:27,085 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,170 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,171 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:27,173 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00080469 0.00051243 0.00040574 0.00045448 0.00066017 0.00071574
 0.00112001 0.00145061]
2023-06-28 04:30:27,174 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,255 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,255 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:27,257 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00080469 0.00051243 0.00040574 0.00045448 0.00066017 0.00071574
 0.00112001 0.00145061]
2023-06-28 04:30:27,258 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,362 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,363 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:27,364 - gen_series_legodnn_models.py[28] - INFO: target model size: 6.551MB
2023-06-28 04:30:27,364 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 6869478.292929293B (6.551MB), try to adapt blocks
2023-06-28 04:30:27,366 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:27,380 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010354656219482422
2023-06-28 04:30:27,380 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000681439995765686, 0.0004387199990451336, 0.0003221440054476261, 0.00044806399568915364, 0.00037337600439786914, 0.0006043839901685715, 0.0005584319978952408, 0.0009214080311357977]
2023-06-28 04:30:27,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.392
2023-06-28 04:30:27,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.855
2023-06-28 04:30:27,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.547
2023-06-28 04:30:27,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.808
2023-06-28 04:30:27,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.373
2023-06-28 04:30:27,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.301
2023-06-28 04:30:27,381 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.001
2023-06-28 04:30:27,381 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.944
2023-06-28 04:30:27,381 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:27,381 - optimal_runtime.py[116] - INFO: avg ratio: 1.4034456691276072
2023-06-28 04:30:27,381 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029963036993915673
2023-06-28 04:30:27,382 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00068279 0.00043563 0.00038174 0.00043936 0.00054013 0.0006296
 0.00100413 0.00141796]
2023-06-28 04:30:27,383 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,475 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,476 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:27,478 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00068279 0.00043563 0.00038174 0.00043936 0.00054013 0.0006296
 0.00100413 0.00141796]
2023-06-28 04:30:27,479 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,562 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,562 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:27,564 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00068279 0.00043563 0.00038174 0.00043936 0.00054013 0.0006296
 0.00100413 0.00141796]
2023-06-28 04:30:27,566 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,661 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,662 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:27,662 - gen_series_legodnn_models.py[28] - INFO: target model size: 6.985MB
2023-06-28 04:30:27,662 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 7324689.161616161B (6.985MB), try to adapt blocks
2023-06-28 04:30:27,664 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:27,679 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011102047920227051
2023-06-28 04:30:27,680 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006778880022466183, 0.0005291199944913388, 0.00033907200023531914, 0.00048287999257445337, 0.00038390399515628816, 0.0006272960044443608, 0.0005888000130653381, 0.0009742400087416172]
2023-06-28 04:30:27,680 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.400
2023-06-28 04:30:27,680 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.538
2023-06-28 04:30:27,680 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.470
2023-06-28 04:30:27,680 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.677
2023-06-28 04:30:27,680 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.335
2023-06-28 04:30:27,680 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.254
2023-06-28 04:30:27,680 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.950
2023-06-28 04:30:27,680 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.893
2023-06-28 04:30:27,681 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5]),)
2023-06-28 04:30:27,681 - optimal_runtime.py[116] - INFO: avg ratio: 1.3992867511297455
2023-06-28 04:30:27,681 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030052092231324288
2023-06-28 04:30:27,681 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067923 0.00052539 0.0004018  0.00047349 0.00055536 0.00065347
 0.00105873 0.00149927]
2023-06-28 04:30:27,683 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,768 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,769 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:27,771 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067923 0.00052539 0.0004018  0.00047349 0.00055536 0.00065347
 0.00105873 0.00149927]
2023-06-28 04:30:27,772 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,856 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,856 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:27,858 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067923 0.00052539 0.0004018  0.00047349 0.00055536 0.00065347
 0.00105873 0.00149927]
2023-06-28 04:30:27,860 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:27,958 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:27,959 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:27,959 - gen_series_legodnn_models.py[28] - INFO: target model size: 7.419MB
2023-06-28 04:30:27,959 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 7779900.03030303B (7.419MB), try to adapt blocks
2023-06-28 04:30:27,961 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:27,976 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011155232429504395
2023-06-28 04:30:27,977 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007616320066154004, 0.0004544959962368012, 0.0003631360083818435, 0.000452416006475687, 0.00043526399508118626, 0.0006605760008096695, 0.000597888007760048, 0.0009626240022480488]
2023-06-28 04:30:27,977 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.246
2023-06-28 04:30:27,977 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.790
2023-06-28 04:30:27,977 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.373
2023-06-28 04:30:27,977 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.790
2023-06-28 04:30:27,977 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.178
2023-06-28 04:30:27,977 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.190
2023-06-28 04:30:27,977 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.935
2023-06-28 04:30:27,977 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.904
2023-06-28 04:30:27,978 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:27,978 - optimal_runtime.py[116] - INFO: avg ratio: 1.2466542569840744
2023-06-28 04:30:27,978 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033731481096252675
2023-06-28 04:30:27,979 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00076314 0.0004513  0.00043032 0.00044362 0.00062966 0.00068814
 0.00107507 0.00148139]
2023-06-28 04:30:27,980 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,062 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,063 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:28,065 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00076314 0.0004513  0.00043032 0.00044362 0.00062966 0.00068814
 0.00107507 0.00148139]
2023-06-28 04:30:28,066 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,147 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,148 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:28,150 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00076314 0.0004513  0.00043032 0.00044362 0.00062966 0.00068814
 0.00107507 0.00148139]
2023-06-28 04:30:28,151 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,248 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,248 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:28,249 - gen_series_legodnn_models.py[28] - INFO: target model size: 7.854MB
2023-06-28 04:30:28,249 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 8235110.898989899B (7.854MB), try to adapt blocks
2023-06-28 04:30:28,250 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:28,266 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010901439666748046
2023-06-28 04:30:28,266 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007057280093431471, 0.00047347199916839596, 0.00032924799993634224, 0.00048688000440597534, 0.0003969920016825199, 0.0006073920056223869, 0.0005714559964835644, 0.0010580800026655196]
2023-06-28 04:30:28,266 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.344
2023-06-28 04:30:28,266 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.719
2023-06-28 04:30:28,266 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.514
2023-06-28 04:30:28,266 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.663
2023-06-28 04:30:28,266 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.291
2023-06-28 04:30:28,266 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.295
2023-06-28 04:30:28,266 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.978
2023-06-28 04:30:28,267 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.822
2023-06-28 04:30:28,267 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:28,267 - optimal_runtime.py[116] - INFO: avg ratio: 1.3610900108119082
2023-06-28 04:30:28,267 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030895454502628344
2023-06-28 04:30:28,268 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00070712 0.00047014 0.00039016 0.00047742 0.0005743  0.00063273
 0.00102754 0.00162829]
2023-06-28 04:30:28,270 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,359 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,359 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:28,361 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00070712 0.00047014 0.00039016 0.00047742 0.0005743  0.00063273
 0.00102754 0.00162829]
2023-06-28 04:30:28,362 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,441 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,442 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:28,444 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00070712 0.00047014 0.00039016 0.00047742 0.0005743  0.00063273
 0.00102754 0.00162829]
2023-06-28 04:30:28,445 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,546 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,547 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:28,547 - gen_series_legodnn_models.py[28] - INFO: target model size: 8.288MB
2023-06-28 04:30:28,547 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 8690321.767676767B (8.288MB), try to adapt blocks
2023-06-28 04:30:28,549 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:28,564 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010817760467529297
2023-06-28 04:30:28,564 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006976639963686467, 0.00045369600132107727, 0.0003232319988310337, 0.00047078400477766993, 0.00038601599261164666, 0.0007233599908649922, 0.0005633920095860958, 0.0009192319996654988]
2023-06-28 04:30:28,564 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.360
2023-06-28 04:30:28,564 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.793
2023-06-28 04:30:28,565 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.542
2023-06-28 04:30:28,565 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.720
2023-06-28 04:30:28,565 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.328
2023-06-28 04:30:28,565 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.087
2023-06-28 04:30:28,565 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.992
2023-06-28 04:30:28,565 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.946
2023-06-28 04:30:28,565 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:28,565 - optimal_runtime.py[116] - INFO: avg ratio: 1.3293097102626779
2023-06-28 04:30:28,565 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003163408359870602
2023-06-28 04:30:28,566 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00069904 0.0004505  0.00038303 0.00046163 0.00055842 0.00075354
 0.00101304 0.00141462]
2023-06-28 04:30:28,568 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,653 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,653 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:28,655 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00069904 0.0004505  0.00038303 0.00046163 0.00055842 0.00075354
 0.00101304 0.00141462]
2023-06-28 04:30:28,657 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,734 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,735 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:28,737 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00069904 0.0004505  0.00038303 0.00046163 0.00055842 0.00075354
 0.00101304 0.00141462]
2023-06-28 04:30:28,738 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,842 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,843 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:28,844 - gen_series_legodnn_models.py[28] - INFO: target model size: 8.722MB
2023-06-28 04:30:28,844 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 9145532.636363637B (8.722MB), try to adapt blocks
2023-06-28 04:30:28,845 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:28,860 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010706944465637207
2023-06-28 04:30:28,860 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006736319996416569, 0.0004669759981334209, 0.0003251200020313263, 0.0004496320076286792, 0.00040550399199128153, 0.0006118720024824142, 0.0006120639964938164, 0.0009653439857065676]
2023-06-28 04:30:28,860 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.408
2023-06-28 04:30:28,860 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.742
2023-06-28 04:30:28,860 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.533
2023-06-28 04:30:28,860 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.801
2023-06-28 04:30:28,860 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.264
2023-06-28 04:30:28,860 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.285
2023-06-28 04:30:28,860 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.914
2023-06-28 04:30:28,861 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.901
2023-06-28 04:30:28,861 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:28,861 - optimal_runtime.py[116] - INFO: avg ratio: 1.3727637368402799
2023-06-28 04:30:28,861 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030632725336853716
2023-06-28 04:30:28,862 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067497 0.00046369 0.00038527 0.00044089 0.00058661 0.0006374
 0.00110056 0.00148558]
2023-06-28 04:30:28,863 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:28,947 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:28,947 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:28,949 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067497 0.00046369 0.00038527 0.00044089 0.00058661 0.0006374
 0.00110056 0.00148558]
2023-06-28 04:30:28,951 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:29,028 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:29,028 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:29,030 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067497 0.00046369 0.00038527 0.00044089 0.00058661 0.0006374
 0.00110056 0.00148558]
2023-06-28 04:30:29,032 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:29,126 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:29,126 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:29,127 - gen_series_legodnn_models.py[28] - INFO: target model size: 9.156MB
2023-06-28 04:30:29,127 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 9600743.505050505B (9.156MB), try to adapt blocks
2023-06-28 04:30:29,129 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:29,144 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010887871742248536
2023-06-28 04:30:29,144 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007559359967708587, 0.0005409279949963093, 0.0003215360045433044, 0.0005345279984176159, 0.00041839999705553055, 0.0006547520011663437, 0.0005797759965062141, 0.0009534079879522324]
2023-06-28 04:30:29,144 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.255
2023-06-28 04:30:29,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.504
2023-06-28 04:30:29,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.550
2023-06-28 04:30:29,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.515
2023-06-28 04:30:29,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.225
2023-06-28 04:30:29,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.201
2023-06-28 04:30:29,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.964
2023-06-28 04:30:29,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.912
2023-06-28 04:30:29,145 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 4, 5]),)
2023-06-28 04:30:29,146 - optimal_runtime.py[116] - INFO: avg ratio: 1.227116763058868
2023-06-28 04:30:29,146 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0034268535618565184
2023-06-28 04:30:29,146 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00075743 0.00053712 0.00038102 0.00052414 0.00060527 0.00068207
 0.00104251 0.00146721]
2023-06-28 04:30:29,148 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:29,238 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:29,238 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-28 04:30:29,240 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00075743 0.00053712 0.00038102 0.00052414 0.00060527 0.00068207
 0.00104251 0.00146721]
2023-06-28 04:30:29,241 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:29,319 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:29,320 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-28 04:30:29,322 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00075743 0.00053712 0.00038102 0.00052414 0.00060527 0.00068207
 0.00104251 0.00146721]
2023-06-28 04:30:29,324 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:29,424 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:29,425 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:29,425 - gen_series_legodnn_models.py[28] - INFO: target model size: 9.590MB
2023-06-28 04:30:29,425 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 10055954.373737374B (9.590MB), try to adapt blocks
2023-06-28 04:30:29,427 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:29,442 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010690784454345703
2023-06-28 04:30:29,442 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005792639963328838, 0.0004959360025823116, 0.00034060799330472947, 0.000488767996430397, 0.00037993599101901053, 0.0006541440114378929, 0.0005752640143036842, 0.0009608639739453793]
2023-06-28 04:30:29,443 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.638
2023-06-28 04:30:29,443 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.641
2023-06-28 04:30:29,443 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.464
2023-06-28 04:30:29,443 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.657
2023-06-28 04:30:29,443 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.349
2023-06-28 04:30:29,443 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.202
2023-06-28 04:30:29,443 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.972
2023-06-28 04:30:29,443 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.905
2023-06-28 04:30:29,444 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 4, 5]),)
2023-06-28 04:30:29,444 - optimal_runtime.py[116] - INFO: avg ratio: 1.338293678099465
2023-06-28 04:30:29,444 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031421723939351874
2023-06-28 04:30:29,444 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058041 0.00049244 0.00040362 0.00047927 0.00054962 0.00068144
 0.00103439 0.00147868]
2023-06-28 04:30:29,446 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:29,536 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:29,537 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:29,541 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.6) from file
2023-06-28 04:30:29,541 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 262776704.0,
  'blocks_sparsity': [0.8, 0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.0019202998489535935,
  'esti_test_accuracy': 0.00936666689813137,
  'is_relaxed': False,
  'model_size': 10044557.0,
  'update_swap_mem_cost': 566182.0,
  'update_swap_time_cost': 0.003806591033935547}
2023-06-28 04:30:29,562 - gen_series_legodnn_models.py[28] - INFO: target model size: 10.024MB
2023-06-28 04:30:29,562 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 10511165.242424242B (10.024MB), try to adapt blocks
2023-06-28 04:30:29,564 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:29,577 - optimal_runtime.py[77] - INFO: infer time of current model: 0.00963907241821289
2023-06-28 04:30:29,577 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006010239906609059, 0.0004503360018134117, 0.0003252480030059814, 0.00048192000016570094, 0.0003872959986329079, 0.0006285439990460872, 0.0005665920078754425, 0.000927744034677744]
2023-06-28 04:30:29,578 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.579
2023-06-28 04:30:29,578 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.807
2023-06-28 04:30:29,578 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.547
2023-06-28 04:30:29,578 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.681
2023-06-28 04:30:29,578 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.324
2023-06-28 04:30:29,578 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.251
2023-06-28 04:30:29,578 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-28 04:30:29,578 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.938
2023-06-28 04:30:29,578 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:29,579 - optimal_runtime.py[116] - INFO: avg ratio: 1.4762070714552005
2023-06-28 04:30:29,579 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028486176035973144
2023-06-28 04:30:29,579 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060221 0.00044716 0.00038181 0.00047255 0.00056027 0.00065477
 0.0010188  0.00142771]
2023-06-28 04:30:29,581 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:29,671 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:29,671 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:29,677 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2023-06-28 04:30:29,678 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 354948992.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.0016577711867594236,
  'esti_test_accuracy': 0.009400000174840292,
  'is_relaxed': False,
  'model_size': 10225037.0,
  'update_swap_mem_cost': 340580.0,
  'update_swap_time_cost': 0.006014347076416016}
2023-06-28 04:30:29,701 - gen_series_legodnn_models.py[28] - INFO: target model size: 10.458MB
2023-06-28 04:30:29,701 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 10966376.111111112B (10.458MB), try to adapt blocks
2023-06-28 04:30:29,703 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:29,718 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011504768371582031
2023-06-28 04:30:29,719 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007971519939601423, 0.00047225601226091385, 0.0003710079975426197, 0.0005289920009672641, 0.00047708800435066227, 0.0006823039986193179, 0.0006162239909172059, 0.0009902399964630605]
2023-06-28 04:30:29,719 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.202
2023-06-28 04:30:29,719 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.723
2023-06-28 04:30:29,719 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.356
2023-06-28 04:30:29,719 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.531
2023-06-28 04:30:29,719 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.075
2023-06-28 04:30:29,719 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.153
2023-06-28 04:30:29,719 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.907
2023-06-28 04:30:29,719 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.878
2023-06-28 04:30:29,720 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:29,720 - optimal_runtime.py[116] - INFO: avg ratio: 1.1962239781506225
2023-06-28 04:30:29,720 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003515352916435714
2023-06-28 04:30:29,720 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00079117 0.00046893 0.00043553 0.00051871 0.00069017 0.00071077
 0.00110804 0.00152389]
2023-06-28 04:30:29,723 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:29,824 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:29,825 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-28 04:30:29,825 - gen_series_legodnn_models.py[28] - INFO: target model size: 10.892MB
2023-06-28 04:30:29,825 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 11421586.97979798B (10.892MB), try to adapt blocks
2023-06-28 04:30:29,827 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:29,841 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010027584075927734
2023-06-28 04:30:29,841 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000686944004148245, 0.0004705919995903969, 0.00032265600562095644, 0.00048457600921392435, 0.0003817280046641827, 0.0006236160174012184, 0.0005923520065844059, 0.0009703999757766723]
2023-06-28 04:30:29,841 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.394
2023-06-28 04:30:29,841 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.729
2023-06-28 04:30:29,841 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.560
2023-06-28 04:30:29,841 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.671
2023-06-28 04:30:29,841 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.343
2023-06-28 04:30:29,841 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.261
2023-06-28 04:30:29,841 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.944
2023-06-28 04:30:29,841 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.896
2023-06-28 04:30:29,842 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:29,842 - optimal_runtime.py[116] - INFO: avg ratio: 1.389450904544851
2023-06-28 04:30:29,842 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003026482934047694
2023-06-28 04:30:29,842 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00068179 0.00046728 0.00037877 0.00047516 0.00055222 0.00064963
 0.00106512 0.00149336]
2023-06-28 04:30:29,844 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:29,941 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:29,942 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.8, 0.8, 0.6, 0.8, 0.8]
2023-06-28 04:30:29,950 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.6) from file
2023-06-28 04:30:29,951 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 385043072.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.8, 0.8, 0.6, 0.8, 0.8],
  'esti_latency': 0.001787913188707138,
  'esti_test_accuracy': 0.009500000004967054,
  'is_relaxed': False,
  'model_size': 11165837.0,
  'update_swap_mem_cost': 2900738.0,
  'update_swap_time_cost': 0.008440017700195312}
2023-06-28 04:30:29,979 - gen_series_legodnn_models.py[28] - INFO: target model size: 11.327MB
2023-06-28 04:30:29,979 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 11876797.848484848B (11.327MB), try to adapt blocks
2023-06-28 04:30:29,982 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:29,996 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010821311950683594
2023-06-28 04:30:29,997 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000692543987184763, 0.0004980159886181355, 0.00032515199854969977, 0.0004769920036196709, 0.00038831999525427817, 0.0007061760015785694, 0.0005713599883019923, 0.0009415040202438831]
2023-06-28 04:30:29,997 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.383
2023-06-28 04:30:29,997 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.634
2023-06-28 04:30:29,997 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.548
2023-06-28 04:30:29,997 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.698
2023-06-28 04:30:29,997 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.320
2023-06-28 04:30:29,997 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.099
2023-06-28 04:30:29,997 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.979
2023-06-28 04:30:29,997 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.924
2023-06-28 04:30:29,998 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:29,998 - optimal_runtime.py[116] - INFO: avg ratio: 1.3374620418258933
2023-06-28 04:30:29,998 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031441262023117187
2023-06-28 04:30:29,998 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00068735 0.00049451 0.0003817  0.00046772 0.00056175 0.00074534
 0.00102737 0.00144889]
2023-06-28 04:30:30,000 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:30,095 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:30,095 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.8, 0.8, 0.6, 0.8, 0.8]
2023-06-28 04:30:30,100 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-28 04:30:30,101 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 505576064.0,
  'blocks_sparsity': [0.2, 0.0, 0.6, 0.8, 0.8, 0.6, 0.8, 0.8],
  'esti_latency': 0.0019260568693766713,
  'esti_test_accuracy': 0.009500000004967054,
  'is_relaxed': False,
  'model_size': 11401677.0,
  'update_swap_mem_cost': 390978.0,
  'update_swap_time_cost': 0.0051610469818115234}
2023-06-28 04:30:30,123 - gen_series_legodnn_models.py[28] - INFO: target model size: 11.761MB
2023-06-28 04:30:30,123 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 12332008.717171717B (11.761MB), try to adapt blocks
2023-06-28 04:30:30,125 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:30,138 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009752896308898926
2023-06-28 04:30:30,138 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006071680113673211, 0.00047465600445866586, 0.00032502400502562524, 0.000514080010354519, 0.0003906559944152832, 0.0006856640130281449, 0.0005711679980158806, 0.0009514879956841469]
2023-06-28 04:30:30,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.578
2023-06-28 04:30:30,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.702
2023-06-28 04:30:30,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.548
2023-06-28 04:30:30,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.575
2023-06-28 04:30:30,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.312
2023-06-28 04:30:30,139 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.132
2023-06-28 04:30:30,139 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.979
2023-06-28 04:30:30,139 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.914
2023-06-28 04:30:30,139 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:30,139 - optimal_runtime.py[116] - INFO: avg ratio: 1.4290777308959548
2023-06-28 04:30:30,139 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029425617371181905
2023-06-28 04:30:30,140 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060261 0.00047466 0.00038155 0.00050409 0.00056513 0.00072369
 0.00102703 0.00146425]
2023-06-28 04:30:30,141 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:30,246 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:30,247 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.8]
2023-06-28 04:30:30,252 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.8) from file
2023-06-28 04:30:30,259 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-28 04:30:30,259 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 505471616.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.8],
  'esti_latency': 0.0017128363407522473,
  'esti_test_accuracy': 0.009566666558384895,
  'is_relaxed': False,
  'model_size': 12107469.0,
  'update_swap_mem_cost': 1849732.0,
  'update_swap_time_cost': 0.011959552764892578}
2023-06-28 04:30:30,282 - gen_series_legodnn_models.py[28] - INFO: target model size: 12.195MB
2023-06-28 04:30:30,282 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 12787219.585858585B (12.195MB), try to adapt blocks
2023-06-28 04:30:30,284 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:30,297 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010038751602172852
2023-06-28 04:30:30,298 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006170559898018836, 0.0004631680026650429, 0.0003341439962387085, 0.000598496001213789, 0.0003938560038805008, 0.0007160640023648738, 0.0005824960097670555, 0.000960511978715658]
2023-06-28 04:30:30,298 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.552
2023-06-28 04:30:30,298 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.757
2023-06-28 04:30:30,298 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.506
2023-06-28 04:30:30,298 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.327
2023-06-28 04:30:30,298 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.302
2023-06-28 04:30:30,298 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.084
2023-06-28 04:30:30,298 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.960
2023-06-28 04:30:30,298 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.906
2023-06-28 04:30:30,299 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:30,299 - optimal_runtime.py[116] - INFO: avg ratio: 1.3541239540441061
2023-06-28 04:30:30,299 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031054390831381407
2023-06-28 04:30:30,299 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061243 0.00045991 0.00039225 0.0005985  0.00056976 0.00075577
 0.0010474  0.00147814]
2023-06-28 04:30:30,301 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:30,400 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:30,401 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.8]
2023-06-28 04:30:30,401 - gen_series_legodnn_models.py[28] - INFO: target model size: 12.629MB
2023-06-28 04:30:30,401 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 13242430.454545455B (12.629MB), try to adapt blocks
2023-06-28 04:30:30,403 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:30,416 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009725983619689942
2023-06-28 04:30:30,416 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005851840004324913, 0.0004493119977414608, 0.00031721600145101546, 0.0005520320013165474, 0.0003743359968066215, 0.0006853439882397651, 0.0005660480037331582, 0.0009240639843046663]
2023-06-28 04:30:30,416 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.637
2023-06-28 04:30:30,416 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.811
2023-06-28 04:30:30,416 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.586
2023-06-28 04:30:30,416 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.439
2023-06-28 04:30:30,416 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.369
2023-06-28 04:30:30,416 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.132
2023-06-28 04:30:30,416 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.988
2023-06-28 04:30:30,417 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.941
2023-06-28 04:30:30,417 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:30,417 - optimal_runtime.py[116] - INFO: avg ratio: 1.4327342551795346
2023-06-28 04:30:30,417 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002935051936602981
2023-06-28 04:30:30,417 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058079 0.00044615 0.00037238 0.00055203 0.00054152 0.00072335
 0.00101782 0.00142205]
2023-06-28 04:30:30,419 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:30,517 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:30,517 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.8]
2023-06-28 04:30:30,518 - gen_series_legodnn_models.py[28] - INFO: target model size: 13.063MB
2023-06-28 04:30:30,518 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 13697641.323232323B (13.063MB), try to adapt blocks
2023-06-28 04:30:30,519 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:30,535 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011534144401550293
2023-06-28 04:30:30,536 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006610240004956723, 0.0004674879983067512, 0.00036694399267435076, 0.0005978879965841771, 0.0004480640068650246, 0.0007247040160000324, 0.0006401280015707016, 0.0010443840064108373]
2023-06-28 04:30:30,536 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.449
2023-06-28 04:30:30,536 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.741
2023-06-28 04:30:30,536 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.371
2023-06-28 04:30:30,536 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.328
2023-06-28 04:30:30,536 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.144
2023-06-28 04:30:30,536 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.071
2023-06-28 04:30:30,537 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.873
2023-06-28 04:30:30,537 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.833
2023-06-28 04:30:30,537 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:30,537 - optimal_runtime.py[116] - INFO: avg ratio: 1.2727436901885116
2023-06-28 04:30:30,538 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033040033768930175
2023-06-28 04:30:30,538 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065606 0.0004642  0.00043076 0.00059789 0.00064818 0.00076489
 0.00115103 0.00160721]
2023-06-28 04:30:30,540 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:30,632 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:30,633 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.8]
2023-06-28 04:30:30,633 - gen_series_legodnn_models.py[28] - INFO: target model size: 13.497MB
2023-06-28 04:30:30,633 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 14152852.191919193B (13.497MB), try to adapt blocks
2023-06-28 04:30:30,635 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:30,648 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009507295608520507
2023-06-28 04:30:30,648 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000580640010535717, 0.00043068799749016763, 0.0003059519939124584, 0.0005415039956569672, 0.0003695999979972839, 0.0006816319935023785, 0.0005850240029394627, 0.0009184639975428582]
2023-06-28 04:30:30,648 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.650
2023-06-28 04:30:30,648 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.889
2023-06-28 04:30:30,648 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.645
2023-06-28 04:30:30,648 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.467
2023-06-28 04:30:30,649 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.387
2023-06-28 04:30:30,649 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.139
2023-06-28 04:30:30,649 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.956
2023-06-28 04:30:30,649 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.947
2023-06-28 04:30:30,649 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:30,649 - optimal_runtime.py[116] - INFO: avg ratio: 1.4573133879211764
2023-06-28 04:30:30,649 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028855491791650047
2023-06-28 04:30:30,650 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00057628 0.00042766 0.00035916 0.0005415  0.00053467 0.00071943
 0.00105194 0.00141343]
2023-06-28 04:30:30,651 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:30,740 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:30,740 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.8, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:30,746 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.8) from file
2023-06-28 04:30:30,752 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2023-06-28 04:30:30,753 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 475338368.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.8, 0.0, 0.6, 0.8, 0.8],
  'esti_latency': 0.0018507783579119158,
  'esti_test_accuracy': 0.009599999835093817,
  'is_relaxed': False,
  'model_size': 13989005.0,
  'update_swap_mem_cost': 5747176.0,
  'update_swap_time_cost': 0.012169599533081055}
2023-06-28 04:30:30,780 - gen_series_legodnn_models.py[28] - INFO: target model size: 13.931MB
2023-06-28 04:30:30,781 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 14608063.06060606B (13.931MB), try to adapt blocks
2023-06-28 04:30:30,783 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:30,798 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011182399749755859
2023-06-28 04:30:30,798 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006929279975593091, 0.0005383359938859939, 0.00034297600388526916, 0.0005147840082645416, 0.0007328640073537827, 0.000705024003982544, 0.0006232000030577183, 0.0009594560265541076]
2023-06-28 04:30:30,798 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.382
2023-06-28 04:30:30,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.511
2023-06-28 04:30:30,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.467
2023-06-28 04:30:30,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.573
2023-06-28 04:30:30,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.012
2023-06-28 04:30:30,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.101
2023-06-28 04:30:30,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.897
2023-06-28 04:30:30,799 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.907
2023-06-28 04:30:30,799 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:30,799 - optimal_runtime.py[116] - INFO: avg ratio: 1.2405558664872962
2023-06-28 04:30:30,800 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00338973001047445
2023-06-28 04:30:30,800 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00068773 0.00053454 0.00040262 0.00050478 0.00073286 0.00074412
 0.00112059 0.00147652]
2023-06-28 04:30:30,802 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:30,901 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:30,902 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.4, 0.6, 0.4, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:30,907 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-28 04:30:30,911 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2023-06-28 04:30:30,911 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 597000832.0,
  'blocks_sparsity': [0.2, 0.4, 0.6, 0.4, 0.0, 0.6, 0.8, 0.8],
  'esti_latency': 0.0022813268707264855,
  'esti_test_accuracy': 0.009599999835093817,
  'is_relaxed': False,
  'model_size': 14580109.0,
  'update_swap_mem_cost': 1263364.0,
  'update_swap_time_cost': 0.009118795394897461}
2023-06-28 04:30:30,935 - gen_series_legodnn_models.py[28] - INFO: target model size: 14.365MB
2023-06-28 04:30:30,935 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 15063273.92929293B (14.365MB), try to adapt blocks
2023-06-28 04:30:30,937 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:30,951 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010417471885681153
2023-06-28 04:30:30,951 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006263039968907834, 0.00047404799982905387, 0.0003332800045609474, 0.0005360000021755695, 0.0006219839900732041, 0.0007124160155653954, 0.0005751999951899052, 0.000955872006714344]
2023-06-28 04:30:30,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.529
2023-06-28 04:30:30,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.713
2023-06-28 04:30:30,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.510
2023-06-28 04:30:30,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.472
2023-06-28 04:30:30,952 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.192
2023-06-28 04:30:30,952 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.089
2023-06-28 04:30:30,952 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.972
2023-06-28 04:30:30,952 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.910
2023-06-28 04:30:30,952 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:30,952 - optimal_runtime.py[116] - INFO: avg ratio: 1.3586105145724594
2023-06-28 04:30:30,952 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030951839435936056
2023-06-28 04:30:30,953 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062161 0.00047155 0.00039124 0.00053947 0.00062198 0.00075192
 0.00103428 0.001471  ]
2023-06-28 04:30:30,955 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:31,056 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:31,057 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:31,061 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.8) from file
2023-06-28 04:30:31,066 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-28 04:30:31,066 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 595766912.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8],
  'esti_latency': 0.0020315549794145712,
  'esti_test_accuracy': 0.009666666388511658,
  'is_relaxed': False,
  'model_size': 14930637.0,
  'update_swap_mem_cost': 2204996.0,
  'update_swap_time_cost': 0.009259939193725586}
2023-06-28 04:30:31,090 - gen_series_legodnn_models.py[28] - INFO: target model size: 14.800MB
2023-06-28 04:30:31,090 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 15518484.797979798B (14.800MB), try to adapt blocks
2023-06-28 04:30:31,092 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:31,105 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010068991661071777
2023-06-28 04:30:31,106 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005959360003471374, 0.00046329599991440774, 0.00032447999715805054, 0.0005784639976918696, 0.0006081920079886913, 0.0007034239992499351, 0.0005915839783847332, 0.0009430720061063766]
2023-06-28 04:30:31,106 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.607
2023-06-28 04:30:31,106 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.756
2023-06-28 04:30:31,106 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.551
2023-06-28 04:30:31,106 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.373
2023-06-28 04:30:31,106 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.219
2023-06-28 04:30:31,106 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.103
2023-06-28 04:30:31,106 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.945
2023-06-28 04:30:31,106 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.922
2023-06-28 04:30:31,107 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:31,107 - optimal_runtime.py[116] - INFO: avg ratio: 1.31158599089737
2023-06-28 04:30:31,107 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00320615611899378
2023-06-28 04:30:31,107 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059147 0.00046003 0.00038091 0.00057846 0.00060819 0.00074243
 0.00106374 0.0014513 ]
2023-06-28 04:30:31,109 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:31,207 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:31,208 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:31,208 - gen_series_legodnn_models.py[28] - INFO: target model size: 15.234MB
2023-06-28 04:30:31,208 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 15973695.666666666B (15.234MB), try to adapt blocks
2023-06-28 04:30:31,210 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:31,225 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011347040176391602
2023-06-28 04:30:31,226 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0008241280205547809, 0.0004740480072796345, 0.00033392000198364255, 0.0005854080095887184, 0.000610784001648426, 0.000697984017431736, 0.000674847986549139, 0.0009618880115449429]
2023-06-28 04:30:31,226 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.162
2023-06-28 04:30:31,226 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.716
2023-06-28 04:30:31,226 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.507
2023-06-28 04:30:31,226 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.357
2023-06-28 04:30:31,226 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.214
2023-06-28 04:30:31,226 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.112
2023-06-28 04:30:31,227 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.829
2023-06-28 04:30:31,227 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.904
2023-06-28 04:30:31,227 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:31,227 - optimal_runtime.py[116] - INFO: avg ratio: 1.211247094181989
2023-06-28 04:30:31,227 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003471751941037311
2023-06-28 04:30:31,228 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00081795 0.00047071 0.00039199 0.00058541 0.00061078 0.00073669
 0.00121346 0.00148026]
2023-06-28 04:30:31,230 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:31,338 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:31,338 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:31,338 - gen_series_legodnn_models.py[28] - INFO: target model size: 15.668MB
2023-06-28 04:30:31,339 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 16428906.535353536B (15.668MB), try to adapt blocks
2023-06-28 04:30:31,340 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:31,354 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010203136444091796
2023-06-28 04:30:31,354 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005933760106563567, 0.0004490560069680214, 0.0003338879942893982, 0.0005650880001485348, 0.0006080320030450821, 0.0006829760074615478, 0.0005666880011558533, 0.0009347839877009392]
2023-06-28 04:30:31,354 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.614
2023-06-28 04:30:31,354 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.812
2023-06-28 04:30:31,355 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.507
2023-06-28 04:30:31,355 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.405
2023-06-28 04:30:31,355 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.220
2023-06-28 04:30:31,355 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.136
2023-06-28 04:30:31,355 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-28 04:30:31,355 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.931
2023-06-28 04:30:31,355 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:31,355 - optimal_runtime.py[116] - INFO: avg ratio: 1.3765511994676884
2023-06-28 04:30:31,355 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030548442018925644
2023-06-28 04:30:31,356 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058892 0.00044589 0.00039195 0.00056509 0.00060803 0.00072085
 0.00101897 0.00143855]
2023-06-28 04:30:31,358 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:31,456 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:31,457 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.4, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:31,467 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-28 04:30:31,468 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 657215104.0,
  'blocks_sparsity': [0.2, 0.4, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8],
  'esti_latency': 0.002009674116549133,
  'esti_test_accuracy': 0.009666666388511658,
  'is_relaxed': False,
  'model_size': 15050957.0,
  'update_swap_mem_cost': 275458.0,
  'update_swap_time_cost': 0.01064157485961914}
2023-06-28 04:30:31,508 - gen_series_legodnn_models.py[28] - INFO: target model size: 16.102MB
2023-06-28 04:30:31,508 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 16884117.404040404B (16.102MB), try to adapt blocks
2023-06-28 04:30:31,510 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:31,525 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010791232109069824
2023-06-28 04:30:31,525 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006532159931957722, 0.0004800000041723251, 0.0003122560009360313, 0.0005821760110557079, 0.0006437440067529679, 0.0007344960086047649, 0.0006208320036530494, 0.0009456640109419823]
2023-06-28 04:30:31,525 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.466
2023-06-28 04:30:31,525 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.692
2023-06-28 04:30:31,525 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.611
2023-06-28 04:30:31,526 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.364
2023-06-28 04:30:31,526 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.152
2023-06-28 04:30:31,526 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.057
2023-06-28 04:30:31,526 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.901
2023-06-28 04:30:31,526 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.920
2023-06-28 04:30:31,526 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:31,526 - optimal_runtime.py[116] - INFO: avg ratio: 1.2597960326110083
2023-06-28 04:30:31,526 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033379605439673283
2023-06-28 04:30:31,527 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064832 0.00047747 0.00036656 0.00058218 0.00064374 0.00077523
 0.00111633 0.00145529]
2023-06-28 04:30:31,529 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:31,624 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:31,624 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:31,629 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.8) from file
2023-06-28 04:30:31,629 - gen_series_legodnn_models.py[28] - INFO: target model size: 16.536MB
2023-06-28 04:30:31,629 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 17339328.272727273B (16.536MB), try to adapt blocks
2023-06-28 04:30:31,631 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:31,644 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009859807968139648
2023-06-28 04:30:31,644 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006048320010304452, 0.0004497919902205467, 0.0003086719959974289, 0.0005590720027685165, 0.0005958720222115517, 0.0006751999966800213, 0.0005784320086240769, 0.0009282880164682866]
2023-06-28 04:30:31,645 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.584
2023-06-28 04:30:31,645 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.809
2023-06-28 04:30:31,645 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.630
2023-06-28 04:30:31,645 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.421
2023-06-28 04:30:31,645 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.245
2023-06-28 04:30:31,645 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.149
2023-06-28 04:30:31,645 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.967
2023-06-28 04:30:31,645 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.937
2023-06-28 04:30:31,645 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:31,645 - optimal_runtime.py[116] - INFO: avg ratio: 1.4056791801196638
2023-06-28 04:30:31,646 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002991542814160585
2023-06-28 04:30:31,646 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060029 0.00044662 0.00036235 0.00055907 0.00059587 0.00071264
 0.00104009 0.00142855]
2023-06-28 04:30:31,648 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:31,761 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:31,761 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.4, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:31,766 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-28 04:30:31,766 - gen_series_legodnn_models.py[28] - INFO: target model size: 16.970MB
2023-06-28 04:30:31,767 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 17794539.141414143B (16.970MB), try to adapt blocks
2023-06-28 04:30:31,768 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:31,782 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010358783721923828
2023-06-28 04:30:31,782 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006537279933691025, 0.0004675840064883233, 0.00031548799946904185, 0.000566271997988224, 0.0006043199971318246, 0.0006836799941956997, 0.0005711680129170418, 0.0009355519972741602]
2023-06-28 04:30:31,783 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.465
2023-06-28 04:30:31,783 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.737
2023-06-28 04:30:31,783 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.595
2023-06-28 04:30:31,783 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.402
2023-06-28 04:30:31,783 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.227
2023-06-28 04:30:31,783 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.135
2023-06-28 04:30:31,783 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.979
2023-06-28 04:30:31,783 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.930
2023-06-28 04:30:31,784 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:31,784 - optimal_runtime.py[116] - INFO: avg ratio: 1.3075100555903174
2023-06-28 04:30:31,784 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032161507533520063
2023-06-28 04:30:31,784 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064882 0.00046512 0.00037035 0.00056627 0.00060432 0.00072159
 0.00102703 0.00143973]
2023-06-28 04:30:31,786 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:31,885 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:31,886 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:31,896 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.8) from file
2023-06-28 04:30:31,897 - gen_series_legodnn_models.py[28] - INFO: target model size: 17.404MB
2023-06-28 04:30:31,897 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 18249750.01010101B (17.404MB), try to adapt blocks
2023-06-28 04:30:31,901 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:31,924 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01559318447113037
2023-06-28 04:30:31,924 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0009283200055360795, 0.0007042880132794381, 0.00046316800266504285, 0.0007748480066657067, 0.0006763839945197105, 0.0007866239845752716, 0.0006506240069866181, 0.0010497280210256575]
2023-06-28 04:30:31,924 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.032
2023-06-28 04:30:31,924 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.155
2023-06-28 04:30:31,924 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.086
2023-06-28 04:30:31,924 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.025
2023-06-28 04:30:31,924 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.096
2023-06-28 04:30:31,925 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-28 04:30:31,925 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.859
2023-06-28 04:30:31,925 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.829
2023-06-28 04:30:31,925 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:31,925 - optimal_runtime.py[116] - INFO: avg ratio: 1.0452449530907368
2023-06-28 04:30:31,925 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004023123419890914
2023-06-28 04:30:31,926 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00092136 0.00069933 0.00054371 0.00077485 0.00067638 0.00083025
 0.0011699  0.00161544]
2023-06-28 04:30:31,928 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:32,036 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:32,037 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.8]
2023-06-28 04:30:32,038 - gen_series_legodnn_models.py[28] - INFO: target model size: 17.838MB
2023-06-28 04:30:32,038 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 18704960.87878788B (17.838MB), try to adapt blocks
2023-06-28 04:30:32,040 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:32,056 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012310432434082032
2023-06-28 04:30:32,057 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0008314879946410656, 0.0006392000019550323, 0.00034892799705266955, 0.0006241599954664708, 0.0006430720165371895, 0.0007216320112347602, 0.0007343679964542389, 0.0009850239790976047]
2023-06-28 04:30:32,057 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.152
2023-06-28 04:30:32,057 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.273
2023-06-28 04:30:32,057 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.442
2023-06-28 04:30:32,057 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.272
2023-06-28 04:30:32,057 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.153
2023-06-28 04:30:32,057 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.076
2023-06-28 04:30:32,057 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.761
2023-06-28 04:30:32,058 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.883
2023-06-28 04:30:32,058 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5]),)
2023-06-28 04:30:32,058 - optimal_runtime.py[116] - INFO: avg ratio: 1.1852050176601976
2023-06-28 04:30:32,058 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0035480354771057457
2023-06-28 04:30:32,059 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00082525 0.0006347  0.00040961 0.00062416 0.00064307 0.00076165
 0.00132048 0.00151586]
2023-06-28 04:30:32,061 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:32,157 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:32,158 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.6, 0.8, 0.8, 0.6, 0.8, 0.4]
2023-06-28 04:30:32,164 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.8) from file
2023-06-28 04:30:32,168 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.8) from file
2023-06-28 04:30:32,171 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.8) from file
2023-06-28 04:30:32,181 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.4) from file
2023-06-28 04:30:32,182 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 353340864.0,
  'blocks_sparsity': [0.8, 0.8, 0.6, 0.8, 0.8, 0.6, 0.8, 0.4],
  'esti_latency': 0.0024221490009473916,
  'esti_test_accuracy': 0.009733333252370358,
  'is_relaxed': False,
  'model_size': 18545869.0,
  'update_swap_mem_cost': 21294990.0,
  'update_swap_time_cost': 0.023375749588012695}
2023-06-28 04:30:32,205 - gen_series_legodnn_models.py[28] - INFO: target model size: 18.273MB
2023-06-28 04:30:32,206 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 19160171.74747475B (18.273MB), try to adapt blocks
2023-06-28 04:30:32,208 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:32,221 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009910240173339843
2023-06-28 04:30:32,221 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005973759926855565, 0.0004431999921798707, 0.0003200639970600605, 0.00047081600129604345, 0.00038086399435997007, 0.0006829119883477689, 0.0005776960030198097, 0.0011799359880387782]
2023-06-28 04:30:32,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.588
2023-06-28 04:30:32,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.836
2023-06-28 04:30:32,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.572
2023-06-28 04:30:32,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.720
2023-06-28 04:30:32,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.346
2023-06-28 04:30:32,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.136
2023-06-28 04:30:32,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.968
2023-06-28 04:30:32,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.943
2023-06-28 04:30:32,222 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:32,222 - optimal_runtime.py[116] - INFO: avg ratio: 1.410725787686831
2023-06-28 04:30:32,222 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029808411294425345
2023-06-28 04:30:32,223 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059856 0.00044008 0.00037572 0.00046166 0.00055097 0.00072078
 0.00103877 0.00141945]
2023-06-28 04:30:32,224 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:32,328 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:32,329 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.8, 0.8, 0.6, 0.8, 0.4]
2023-06-28 04:30:32,336 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2023-06-28 04:30:32,337 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 445513152.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.8, 0.8, 0.6, 0.8, 0.4],
  'esti_latency': 0.0020334221445370035,
  'esti_test_accuracy': 0.009766666529079279,
  'is_relaxed': False,
  'model_size': 18726349.0,
  'update_swap_mem_cost': 340580.0,
  'update_swap_time_cost': 0.00796055793762207}
2023-06-28 04:30:32,370 - gen_series_legodnn_models.py[28] - INFO: target model size: 18.707MB
2023-06-28 04:30:32,371 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 19615382.616161615B (18.707MB), try to adapt blocks
2023-06-28 04:30:32,373 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:32,386 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010123264312744141
2023-06-28 04:30:32,386 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000603520005941391, 0.00046556800603866574, 0.0003226559981703758, 0.0004683840125799179, 0.000393887996673584, 0.0006902079917490482, 0.000572639986872673, 0.0011874560378491877]
2023-06-28 04:30:32,386 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.587
2023-06-28 04:30:32,386 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.748
2023-06-28 04:30:32,387 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.560
2023-06-28 04:30:32,387 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.729
2023-06-28 04:30:32,387 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.301
2023-06-28 04:30:32,387 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.124
2023-06-28 04:30:32,387 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.976
2023-06-28 04:30:32,387 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.937
2023-06-28 04:30:32,387 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:32,387 - optimal_runtime.py[116] - INFO: avg ratio: 1.3931510181477804
2023-06-28 04:30:32,387 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030184448028419387
2023-06-28 04:30:32,388 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059899 0.00046229 0.00037877 0.00045928 0.00056981 0.00072848
 0.00102967 0.0014285 ]
2023-06-28 04:30:32,390 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:32,485 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:32,487 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.4]
2023-06-28 04:30:32,503 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2023-06-28 04:30:32,515 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-28 04:30:32,516 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 504493504.0,
  'blocks_sparsity': [0.6, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.4],
  'esti_latency': 0.0020514446251812955,
  'esti_test_accuracy': 0.009799999805788199,
  'is_relaxed': False,
  'model_size': 19547661.0,
  'update_swap_mem_cost': 1859494.0,
  'update_swap_time_cost': 0.028877973556518555}
2023-06-28 04:30:32,548 - gen_series_legodnn_models.py[28] - INFO: target model size: 19.141MB
2023-06-28 04:30:32,548 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 20070593.484848484B (19.141MB), try to adapt blocks
2023-06-28 04:30:32,550 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:32,563 - optimal_runtime.py[77] - INFO: infer time of current model: 0.00997164821624756
2023-06-28 04:30:32,563 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006136319972574711, 0.0004206079952418804, 0.0003035520017147064, 0.0005688319951295852, 0.00037244800105690955, 0.0006856640055775641, 0.0005665920041501523, 0.0011962559968233108]
2023-06-28 04:30:32,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.544
2023-06-28 04:30:32,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.935
2023-06-28 04:30:32,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.658
2023-06-28 04:30:32,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.396
2023-06-28 04:30:32,564 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.376
2023-06-28 04:30:32,564 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.132
2023-06-28 04:30:32,564 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-28 04:30:32,564 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.930
2023-06-28 04:30:32,564 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:32,564 - optimal_runtime.py[116] - INFO: avg ratio: 1.4212981503413171
2023-06-28 04:30:32,564 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00295866806643791
2023-06-28 04:30:32,565 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061558 0.00041765 0.00035634 0.00056883 0.00053879 0.00072369
 0.0010188  0.00143908]
2023-06-28 04:30:32,567 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:32,673 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:32,673 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.4]
2023-06-28 04:30:32,679 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2023-06-28 04:30:32,680 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 565941696.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.4],
  'esti_latency': 0.002014094789466149,
  'esti_test_accuracy': 0.00983333308249712,
  'is_relaxed': False,
  'model_size': 19667981.0,
  'update_swap_mem_cost': 400740.0,
  'update_swap_time_cost': 0.005942106246948242}
2023-06-28 04:30:32,705 - gen_series_legodnn_models.py[28] - INFO: target model size: 19.575MB
2023-06-28 04:30:32,705 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 20525804.353535354B (19.575MB), try to adapt blocks
2023-06-28 04:30:32,707 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:32,720 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010006591796875
2023-06-28 04:30:32,721 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006145600005984306, 0.0004538879990577698, 0.0003217600025236607, 0.0005903679989278317, 0.0003815679997205734, 0.0006859840229153633, 0.0005696639865636826, 0.001171071980148554]
2023-06-28 04:30:32,721 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.559
2023-06-28 04:30:32,721 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.793
2023-06-28 04:30:32,721 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.564
2023-06-28 04:30:32,721 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.345
2023-06-28 04:30:32,721 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.343
2023-06-28 04:30:32,721 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.131
2023-06-28 04:30:32,721 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.982
2023-06-28 04:30:32,721 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.950
2023-06-28 04:30:32,722 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:32,722 - optimal_runtime.py[116] - INFO: avg ratio: 1.3885193275557222
2023-06-28 04:30:32,722 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030285134436728737
2023-06-28 04:30:32,722 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060995 0.00045069 0.00037772 0.00059037 0.00055198 0.00072403
 0.00102432 0.00140879]
2023-06-28 04:30:32,724 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:32,826 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:32,827 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.4]
2023-06-28 04:30:32,827 - gen_series_legodnn_models.py[28] - INFO: target model size: 20.009MB
2023-06-28 04:30:32,827 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 20981015.222222224B (20.009MB), try to adapt blocks
2023-06-28 04:30:32,829 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:32,846 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012244992256164551
2023-06-28 04:30:32,846 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0008521599993109701, 0.0005044160038232803, 0.0003498560003936291, 0.0006348799988627434, 0.00040492799878120425, 0.0006864320039749146, 0.0005801600143313408, 0.0014326399937272072]
2023-06-28 04:30:32,846 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.124
2023-06-28 04:30:32,847 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.613
2023-06-28 04:30:32,847 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.438
2023-06-28 04:30:32,847 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.251
2023-06-28 04:30:32,847 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.266
2023-06-28 04:30:32,847 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.131
2023-06-28 04:30:32,847 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.964
2023-06-28 04:30:32,847 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.777
2023-06-28 04:30:32,848 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5, 6]),)
2023-06-28 04:30:32,848 - optimal_runtime.py[116] - INFO: avg ratio: 1.1956067932092456
2023-06-28 04:30:32,848 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003517167578995322
2023-06-28 04:30:32,848 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00084577 0.00050086 0.0004107  0.00063488 0.00058578 0.0007245
 0.0010432  0.00172345]
2023-06-28 04:30:32,850 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:32,955 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:32,955 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.0, 0.8, 0.6, 0.8, 0.4]
2023-06-28 04:30:32,960 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-28 04:30:32,960 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 686474688.0,
  'blocks_sparsity': [0.2, 0.0, 0.6, 0.0, 0.8, 0.6, 0.8, 0.4],
  'esti_latency': 0.0024899589347723437,
  'esti_test_accuracy': 0.00983333308249712,
  'is_relaxed': False,
  'model_size': 19903821.0,
  'update_swap_mem_cost': 390978.0,
  'update_swap_time_cost': 0.004921436309814453}
2023-06-28 04:30:32,986 - gen_series_legodnn_models.py[28] - INFO: target model size: 20.443MB
2023-06-28 04:30:32,986 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 21436226.09090909B (20.443MB), try to adapt blocks
2023-06-28 04:30:32,988 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:33,001 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010102784156799317
2023-06-28 04:30:33,001 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006102720052003862, 0.0004743359982967377, 0.00032863999903202056, 0.0005960640013217926, 0.00042239999771118164, 0.000682208001613617, 0.0005646720193326472, 0.0011781759820878503]
2023-06-28 04:30:33,002 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.570
2023-06-28 04:30:33,002 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.703
2023-06-28 04:30:33,002 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.531
2023-06-28 04:30:33,002 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.332
2023-06-28 04:30:33,002 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.214
2023-06-28 04:30:33,002 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.138
2023-06-28 04:30:33,002 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.990
2023-06-28 04:30:33,002 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.944
2023-06-28 04:30:33,002 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:33,003 - optimal_runtime.py[116] - INFO: avg ratio: 1.303695506643388
2023-06-28 04:30:33,003 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032255610523112717
2023-06-28 04:30:33,003 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060569 0.00047434 0.00038579 0.00059606 0.00061105 0.00072004
 0.00101535 0.00141733]
2023-06-28 04:30:33,005 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:33,106 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:33,106 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.8, 0.6, 0.8, 0.4]
2023-06-28 04:30:33,112 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.8) from file
2023-06-28 04:30:33,113 - gen_series_legodnn_models.py[28] - INFO: target model size: 20.877MB
2023-06-28 04:30:33,113 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 21891436.95959596B (20.877MB), try to adapt blocks
2023-06-28 04:30:33,114 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:33,130 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011773440361022949
2023-06-28 04:30:33,131 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006404800079762936, 0.0005079359896481037, 0.0003495040014386177, 0.0006347199976444244, 0.0005365120023488998, 0.0007179839871823788, 0.0005748800076544285, 0.0014184639491140842]
2023-06-28 04:30:33,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.496
2023-06-28 04:30:33,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.602
2023-06-28 04:30:33,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.440
2023-06-28 04:30:33,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.251
2023-06-28 04:30:33,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.955
2023-06-28 04:30:33,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.081
2023-06-28 04:30:33,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.973
2023-06-28 04:30:33,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.784
2023-06-28 04:30:33,132 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5, 6]),)
2023-06-28 04:30:33,132 - optimal_runtime.py[116] - INFO: avg ratio: 1.1400075530546352
2023-06-28 04:30:33,132 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0036887031485313237
2023-06-28 04:30:33,132 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063567 0.00050436 0.00041028 0.00063472 0.00077613 0.0007578
 0.0010337  0.0017064 ]
2023-06-28 04:30:33,134 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:33,231 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:33,232 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.8, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:33,237 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.8) from file
2023-06-28 04:30:33,242 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2023-06-28 04:30:33,242 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 535808448.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.8, 0.0, 0.6, 0.8, 0.4],
  'esti_latency': 0.002862316775989516,
  'esti_test_accuracy': 0.009866666359206041,
  'is_relaxed': False,
  'model_size': 21549517.0,
  'update_swap_mem_cost': 5747176.0,
  'update_swap_time_cost': 0.010292530059814453}
2023-06-28 04:30:33,268 - gen_series_legodnn_models.py[28] - INFO: target model size: 21.311MB
2023-06-28 04:30:33,268 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 22346647.82828283B (21.311MB), try to adapt blocks
2023-06-28 04:30:33,270 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:33,284 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010143744468688964
2023-06-28 04:30:33,284 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006337599940598011, 0.0004622079953551292, 0.0003202880024909973, 0.0004680959917604924, 0.0006002879999577999, 0.000683616004884243, 0.0005754879936575889, 0.0011756160110235215]
2023-06-28 04:30:33,284 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.511
2023-06-28 04:30:33,284 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.760
2023-06-28 04:30:33,284 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.571
2023-06-28 04:30:33,284 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.730
2023-06-28 04:30:33,284 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.235
2023-06-28 04:30:33,284 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.135
2023-06-28 04:30:33,284 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.972
2023-06-28 04:30:33,284 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.947
2023-06-28 04:30:33,285 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5]),)
2023-06-28 04:30:33,285 - optimal_runtime.py[116] - INFO: avg ratio: 1.3632902591076619
2023-06-28 04:30:33,285 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030845591554762466
2023-06-28 04:30:33,285 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062901 0.00045895 0.00037599 0.000459   0.00060029 0.00072153
 0.00103479 0.00141425]
2023-06-28 04:30:33,287 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:33,387 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:33,387 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:33,394 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.8) from file
2023-06-28 04:30:33,401 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-28 04:30:33,402 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 564064704.0,
  'blocks_sparsity': [0.8, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4],
  'esti_latency': 0.002295018851101895,
  'esti_test_accuracy': 0.009899999635914961,
  'is_relaxed': False,
  'model_size': 22310669.0,
  'update_swap_mem_cost': 1799334.0,
  'update_swap_time_cost': 0.014070510864257812}
2023-06-28 04:30:33,434 - gen_series_legodnn_models.py[28] - INFO: target model size: 21.746MB
2023-06-28 04:30:33,434 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 22801858.696969695B (21.746MB), try to adapt blocks
2023-06-28 04:30:33,436 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:33,450 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010362336158752442
2023-06-28 04:30:33,450 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006038400009274483, 0.0004436159953474999, 0.00032195200026035307, 0.000587648008018732, 0.0006123199909925461, 0.0006753280013799667, 0.0005744640082120895, 0.00120992000028491]
2023-06-28 04:30:33,450 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.571
2023-06-28 04:30:33,450 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.834
2023-06-28 04:30:33,450 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.563
2023-06-28 04:30:33,450 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.351
2023-06-28 04:30:33,451 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.211
2023-06-28 04:30:33,451 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.149
2023-06-28 04:30:33,451 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.973
2023-06-28 04:30:33,451 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.920
2023-06-28 04:30:33,451 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:33,451 - optimal_runtime.py[116] - INFO: avg ratio: 1.3692039989985993
2023-06-28 04:30:33,451 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003071236611474741
2023-06-28 04:30:33,452 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060503 0.00044049 0.00037794 0.00058765 0.00061232 0.00071278
 0.00103295 0.00145552]
2023-06-28 04:30:33,454 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:33,541 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:33,542 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:33,547 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2023-06-28 04:30:33,548 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 656236992.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4],
  'esti_latency': 0.002281405318622779,
  'esti_test_accuracy': 0.009933332912623882,
  'is_relaxed': False,
  'model_size': 22491149.0,
  'update_swap_mem_cost': 340580.0,
  'update_swap_time_cost': 0.005850791931152344}
2023-06-28 04:30:33,575 - gen_series_legodnn_models.py[28] - INFO: target model size: 22.180MB
2023-06-28 04:30:33,575 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 23257069.565656565B (22.180MB), try to adapt blocks
2023-06-28 04:30:33,577 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:33,591 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010464735984802246
2023-06-28 04:30:33,591 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006179840005934239, 0.000457855999469757, 0.0003378560058772564, 0.0005812480151653291, 0.0006129920110106469, 0.0006897920072078705, 0.0005768640041351319, 0.0012117760144174099]
2023-06-28 04:30:33,591 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.550
2023-06-28 04:30:33,591 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.777
2023-06-28 04:30:33,591 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.489
2023-06-28 04:30:33,591 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.366
2023-06-28 04:30:33,591 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.210
2023-06-28 04:30:33,591 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.125
2023-06-28 04:30:33,592 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.969
2023-06-28 04:30:33,592 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.918
2023-06-28 04:30:33,592 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:33,592 - optimal_runtime.py[116] - INFO: avg ratio: 1.3481211523889938
2023-06-28 04:30:33,592 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031192667238031345
2023-06-28 04:30:33,593 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061335 0.00045463 0.00039661 0.00058125 0.00061299 0.00072804
 0.00103727 0.00145775]
2023-06-28 04:30:33,595 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:33,694 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:33,695 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:33,696 - gen_series_legodnn_models.py[28] - INFO: target model size: 22.614MB
2023-06-28 04:30:33,696 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 23712280.434343435B (22.614MB), try to adapt blocks
2023-06-28 04:30:33,697 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:33,713 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011728704452514649
2023-06-28 04:30:33,714 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007614079937338829, 0.0005369600057601928, 0.0003408320024609566, 0.0005864000022411346, 0.0006164799891412258, 0.0007056320086121559, 0.0005898880176246166, 0.0011827520057559014]
2023-06-28 04:30:33,714 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.258
2023-06-28 04:30:33,714 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.515
2023-06-28 04:30:33,714 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.476
2023-06-28 04:30:33,714 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.354
2023-06-28 04:30:33,714 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.203
2023-06-28 04:30:33,714 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.100
2023-06-28 04:30:33,714 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.948
2023-06-28 04:30:33,714 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.941
2023-06-28 04:30:33,715 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:33,715 - optimal_runtime.py[116] - INFO: avg ratio: 1.228791008838869
2023-06-28 04:30:33,715 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00342218442359513
2023-06-28 04:30:33,715 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0007557  0.00053318 0.0004001  0.0005864  0.00061648 0.00074476
 0.00106069 0.00142284]
2023-06-28 04:30:33,717 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:33,807 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:33,808 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:33,808 - gen_series_legodnn_models.py[28] - INFO: target model size: 23.048MB
2023-06-28 04:30:33,808 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 24167491.303030305B (23.048MB), try to adapt blocks
2023-06-28 04:30:33,810 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:33,824 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010791007995605468
2023-06-28 04:30:33,825 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006355520002543926, 0.000472800001502037, 0.0003314880058169365, 0.0005659199990332127, 0.0006077119968831539, 0.0007015360072255134, 0.0005756160095334054, 0.0012074560075998307]
2023-06-28 04:30:33,825 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.507
2023-06-28 04:30:33,825 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.721
2023-06-28 04:30:33,825 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.518
2023-06-28 04:30:33,825 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.403
2023-06-28 04:30:33,825 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.220
2023-06-28 04:30:33,825 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.106
2023-06-28 04:30:33,825 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.971
2023-06-28 04:30:33,825 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.922
2023-06-28 04:30:33,826 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:33,826 - optimal_runtime.py[116] - INFO: avg ratio: 1.3510109619923931
2023-06-28 04:30:33,826 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031125946188479557
2023-06-28 04:30:33,826 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063078 0.00046947 0.00038913 0.00056592 0.00060771 0.00074044
 0.00103503 0.00145256]
2023-06-28 04:30:33,828 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:33,939 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:33,940 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:33,940 - gen_series_legodnn_models.py[28] - INFO: target model size: 23.482MB
2023-06-28 04:30:33,940 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 24622702.17171717B (23.482MB), try to adapt blocks
2023-06-28 04:30:33,942 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:33,956 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010132608413696289
2023-06-28 04:30:33,956 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005861440077424048, 0.0004507199972867966, 0.000317696001380682, 0.0005492799989879131, 0.0005951360054314136, 0.0006626880057156086, 0.0005581440143287181, 0.0011723840124905109]
2023-06-28 04:30:33,956 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.634
2023-06-28 04:30:33,956 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.805
2023-06-28 04:30:33,956 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.584
2023-06-28 04:30:33,956 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.446
2023-06-28 04:30:33,956 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.246
2023-06-28 04:30:33,956 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.171
2023-06-28 04:30:33,956 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.002
2023-06-28 04:30:33,956 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.949
2023-06-28 04:30:33,957 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:33,957 - optimal_runtime.py[116] - INFO: avg ratio: 1.4162298362972001
2023-06-28 04:30:33,957 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002969256361168527
2023-06-28 04:30:33,957 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058175 0.00044755 0.00037294 0.00054928 0.00059514 0.00069944
 0.00100361 0.00141036]
2023-06-28 04:30:33,959 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:34,052 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:34,053 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:34,054 - gen_series_legodnn_models.py[28] - INFO: target model size: 23.916MB
2023-06-28 04:30:34,054 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 25077913.04040404B (23.916MB), try to adapt blocks
2023-06-28 04:30:34,055 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:34,071 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011800576210021972
2023-06-28 04:30:34,072 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007096960023045541, 0.0005051520057022572, 0.00032719999924302103, 0.0006346239894628525, 0.0006134080216288567, 0.0007303359881043433, 0.0006184320114552976, 0.0012410560101270675]
2023-06-28 04:30:34,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.350
2023-06-28 04:30:34,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.611
2023-06-28 04:30:34,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.538
2023-06-28 04:30:34,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.251
2023-06-28 04:30:34,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.209
2023-06-28 04:30:34,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.063
2023-06-28 04:30:34,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.904
2023-06-28 04:30:34,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.897
2023-06-28 04:30:34,073 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:34,073 - optimal_runtime.py[116] - INFO: avg ratio: 1.2181840928930456
2023-06-28 04:30:34,073 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003451981908838903
2023-06-28 04:30:34,074 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00070437 0.00050159 0.0003841  0.00063462 0.00061341 0.00077084
 0.00111201 0.00149298]
2023-06-28 04:30:34,076 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:34,179 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:34,179 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:34,180 - gen_series_legodnn_models.py[28] - INFO: target model size: 24.350MB
2023-06-28 04:30:34,180 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 25533123.90909091B (24.350MB), try to adapt blocks
2023-06-28 04:30:34,181 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:34,196 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010475263595581055
2023-06-28 04:30:34,196 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006144640035927296, 0.0005498879961669445, 0.00031942400336265565, 0.0005534399971365929, 0.0005987839922308922, 0.0006727999895811081, 0.000568960003554821, 0.0012148160003125667]
2023-06-28 04:30:34,196 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.559
2023-06-28 04:30:34,196 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.480
2023-06-28 04:30:34,196 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.575
2023-06-28 04:30:34,196 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.435
2023-06-28 04:30:34,196 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.238
2023-06-28 04:30:34,196 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.154
2023-06-28 04:30:34,196 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.983
2023-06-28 04:30:34,196 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.916
2023-06-28 04:30:34,197 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4, 5]),)
2023-06-28 04:30:34,197 - optimal_runtime.py[116] - INFO: avg ratio: 1.3266839421916043
2023-06-28 04:30:34,197 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003169669366281363
2023-06-28 04:30:34,197 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060985 0.00054602 0.00037497 0.00055344 0.00059878 0.00071011
 0.00102306 0.00146141]
2023-06-28 04:30:34,199 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:34,287 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:34,288 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:34,288 - gen_series_legodnn_models.py[28] - INFO: target model size: 24.784MB
2023-06-28 04:30:34,288 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 25988334.77777778B (24.784MB), try to adapt blocks
2023-06-28 04:30:34,290 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:34,305 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011193056106567383
2023-06-28 04:30:34,306 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006462399959564209, 0.00046761600300669663, 0.00034569600597023965, 0.0006243520118296147, 0.0006839360073208809, 0.000690624013543129, 0.0005996800102293492, 0.0011985280066728592]
2023-06-28 04:30:34,306 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.482
2023-06-28 04:30:34,306 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.740
2023-06-28 04:30:34,306 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.456
2023-06-28 04:30:34,306 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.272
2023-06-28 04:30:34,306 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.084
2023-06-28 04:30:34,306 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.124
2023-06-28 04:30:34,306 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.932
2023-06-28 04:30:34,306 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.928
2023-06-28 04:30:34,307 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:34,307 - optimal_runtime.py[116] - INFO: avg ratio: 1.2835770629555394
2023-06-28 04:30:34,307 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003276117633809557
2023-06-28 04:30:34,307 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064139 0.00046432 0.00040581 0.00062435 0.00068394 0.00072892
 0.00107829 0.00144182]
2023-06-28 04:30:34,309 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:34,411 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:34,412 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:34,412 - gen_series_legodnn_models.py[28] - INFO: target model size: 25.219MB
2023-06-28 04:30:34,412 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 26443545.646464646B (25.219MB), try to adapt blocks
2023-06-28 04:30:34,414 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:34,427 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010332159996032715
2023-06-28 04:30:34,427 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006203199997544289, 0.0004645440056920052, 0.0003083519972860813, 0.0005344000086188315, 0.0005914559774100781, 0.0006474879980087279, 0.000570656020194292, 0.0011679999865591528]
2023-06-28 04:30:34,428 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.544
2023-06-28 04:30:34,428 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.752
2023-06-28 04:30:34,428 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.632
2023-06-28 04:30:34,428 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.486
2023-06-28 04:30:34,428 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.254
2023-06-28 04:30:34,428 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.199
2023-06-28 04:30:34,428 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.980
2023-06-28 04:30:34,428 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.953
2023-06-28 04:30:34,428 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:34,428 - optimal_runtime.py[116] - INFO: avg ratio: 1.3706848159863023
2023-06-28 04:30:34,429 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003067918606274359
2023-06-28 04:30:34,429 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061567 0.00046127 0.00036198 0.0005344  0.00059146 0.00068339
 0.00102611 0.00140509]
2023-06-28 04:30:34,431 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:34,517 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:34,518 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:34,518 - gen_series_legodnn_models.py[28] - INFO: target model size: 25.653MB
2023-06-28 04:30:34,518 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 26898756.515151516B (25.653MB), try to adapt blocks
2023-06-28 04:30:34,520 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:34,535 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010776543617248535
2023-06-28 04:30:34,535 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006286399960517884, 0.00043977599218487744, 0.00031366400420665744, 0.000554816011339426, 0.0005927679948508739, 0.0006877120099961757, 0.000606015995144844, 0.0012330879904329777]
2023-06-28 04:30:34,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.524
2023-06-28 04:30:34,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.850
2023-06-28 04:30:34,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.604
2023-06-28 04:30:34,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.431
2023-06-28 04:30:34,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.251
2023-06-28 04:30:34,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.129
2023-06-28 04:30:34,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.923
2023-06-28 04:30:34,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.902
2023-06-28 04:30:34,536 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:34,536 - optimal_runtime.py[116] - INFO: avg ratio: 1.3877948647913032
2023-06-28 04:30:34,536 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003030094401548671
2023-06-28 04:30:34,537 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062392 0.00043668 0.00036821 0.00055482 0.00059277 0.00072585
 0.00108969 0.00148339]
2023-06-28 04:30:34,538 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:34,644 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:34,645 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:34,645 - gen_series_legodnn_models.py[28] - INFO: target model size: 26.087MB
2023-06-28 04:30:34,645 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 27353967.383838385B (26.087MB), try to adapt blocks
2023-06-28 04:30:34,647 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:34,661 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010110367774963379
2023-06-28 04:30:34,661 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000607551995664835, 0.0004531840011477471, 0.00031241599842905994, 0.0005450560040771961, 0.0005919360220432281, 0.0006615040041506291, 0.0005600000098347664, 0.0011797440089285375]
2023-06-28 04:30:34,661 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.577
2023-06-28 04:30:34,661 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.795
2023-06-28 04:30:34,661 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.611
2023-06-28 04:30:34,661 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.457
2023-06-28 04:30:34,661 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.253
2023-06-28 04:30:34,661 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.173
2023-06-28 04:30:34,662 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.998
2023-06-28 04:30:34,662 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.943
2023-06-28 04:30:34,662 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:34,662 - optimal_runtime.py[116] - INFO: avg ratio: 1.4140744833850625
2023-06-28 04:30:34,662 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029737821449374326
2023-06-28 04:30:34,663 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060299 0.00044999 0.00036675 0.00054506 0.00059194 0.00069819
 0.00100695 0.00141922]
2023-06-28 04:30:34,664 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:34,756 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:34,756 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:34,757 - gen_series_legodnn_models.py[28] - INFO: target model size: 26.521MB
2023-06-28 04:30:34,757 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 27809178.25252525B (26.521MB), try to adapt blocks
2023-06-28 04:30:34,758 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:34,773 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01115340805053711
2023-06-28 04:30:34,774 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000683008000254631, 0.00046854399517178534, 0.00032444800436496734, 0.0005583040043711662, 0.0006005119942128659, 0.0006790400184690953, 0.0006840960010886191, 0.0012173440307378768]
2023-06-28 04:30:34,774 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.402
2023-06-28 04:30:34,774 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.737
2023-06-28 04:30:34,774 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.551
2023-06-28 04:30:34,774 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.422
2023-06-28 04:30:34,774 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.235
2023-06-28 04:30:34,774 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.143
2023-06-28 04:30:34,774 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.817
2023-06-28 04:30:34,774 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.914
2023-06-28 04:30:34,775 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:34,775 - optimal_runtime.py[116] - INFO: avg ratio: 1.3507402922984222
2023-06-28 04:30:34,775 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003113218339808782
2023-06-28 04:30:34,776 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067788 0.00046524 0.00038087 0.0005583  0.00060051 0.0007167
 0.00123008 0.00146445]
2023-06-28 04:30:34,777 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:34,882 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:34,883 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:34,883 - gen_series_legodnn_models.py[28] - INFO: target model size: 26.955MB
2023-06-28 04:30:34,883 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 28264389.12121212B (26.955MB), try to adapt blocks
2023-06-28 04:30:34,885 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:34,898 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009961631774902344
2023-06-28 04:30:34,898 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005895680002868176, 0.00044358399510383614, 0.00030579200014472005, 0.000548640001565218, 0.0005948480069637299, 0.0006503040082752705, 0.0005584000051021576, 0.0011751680187880994]
2023-06-28 04:30:34,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.625
2023-06-28 04:30:34,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.834
2023-06-28 04:30:34,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.646
2023-06-28 04:30:34,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.448
2023-06-28 04:30:34,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.247
2023-06-28 04:30:34,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.193
2023-06-28 04:30:34,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.001
2023-06-28 04:30:34,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.947
2023-06-28 04:30:34,899 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:34,899 - optimal_runtime.py[116] - INFO: avg ratio: 1.4315819305284878
2023-06-28 04:30:34,899 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002937414450844413
2023-06-28 04:30:34,900 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058514 0.00044046 0.00035897 0.00054864 0.00059485 0.00068637
 0.00100407 0.00141371]
2023-06-28 04:30:34,902 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:34,990 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:34,991 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:34,991 - gen_series_legodnn_models.py[28] - INFO: target model size: 27.389MB
2023-06-28 04:30:34,991 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 28719599.98989899B (27.389MB), try to adapt blocks
2023-06-28 04:30:34,993 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:35,008 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01153228759765625
2023-06-28 04:30:35,009 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00062355200573802, 0.0005469120033085346, 0.0003564159981906414, 0.0005524480119347572, 0.000635039996355772, 0.0007628479897975923, 0.0007070079967379571, 0.0012218559756875039]
2023-06-28 04:30:35,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.536
2023-06-28 04:30:35,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.488
2023-06-28 04:30:35,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.412
2023-06-28 04:30:35,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.438
2023-06-28 04:30:35,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.168
2023-06-28 04:30:35,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.017
2023-06-28 04:30:35,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.791
2023-06-28 04:30:35,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.911
2023-06-28 04:30:35,010 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 3, 4, 5]),)
2023-06-28 04:30:35,010 - optimal_runtime.py[116] - INFO: avg ratio: 1.3044598894955637
2023-06-28 04:30:35,010 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032236709493062756
2023-06-28 04:30:35,011 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061887 0.00054306 0.0004184  0.00055245 0.00063504 0.00080515
 0.00127128 0.00146988]
2023-06-28 04:30:35,013 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:35,113 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:35,114 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:35,114 - gen_series_legodnn_models.py[28] - INFO: target model size: 27.823MB
2023-06-28 04:30:35,114 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 29174810.85858586B (27.823MB), try to adapt blocks
2023-06-28 04:30:35,116 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:35,129 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010014240264892577
2023-06-28 04:30:35,129 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005791359953582287, 0.000448544006794691, 0.0003079360015690327, 0.0005442879982292653, 0.0005908480174839497, 0.0006554880179464816, 0.0005668800175189972, 0.0011707200072705746]
2023-06-28 04:30:35,129 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.654
2023-06-28 04:30:35,129 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.814
2023-06-28 04:30:35,129 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.634
2023-06-28 04:30:35,130 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.459
2023-06-28 04:30:35,130 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.255
2023-06-28 04:30:35,130 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.184
2023-06-28 04:30:35,130 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.986
2023-06-28 04:30:35,130 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.950
2023-06-28 04:30:35,130 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:35,130 - optimal_runtime.py[116] - INFO: avg ratio: 1.4372586559346379
2023-06-28 04:30:35,130 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029258125758634223
2023-06-28 04:30:35,131 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00057479 0.00044539 0.00036149 0.00054429 0.00059085 0.00069184
 0.00101932 0.00140836]
2023-06-28 04:30:35,132 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:35,216 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:35,216 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:35,217 - gen_series_legodnn_models.py[28] - INFO: target model size: 28.257MB
2023-06-28 04:30:35,217 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 29630021.727272727B (28.257MB), try to adapt blocks
2023-06-28 04:30:35,218 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:35,233 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010700703620910645
2023-06-28 04:30:35,233 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006399680115282535, 0.00047321600094437597, 0.00031571200489997865, 0.0005484159886837006, 0.0006095359995961189, 0.0006785280182957649, 0.0005820480063557625, 0.0011820480227470395]
2023-06-28 04:30:35,233 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.497
2023-06-28 04:30:35,233 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.719
2023-06-28 04:30:35,233 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.594
2023-06-28 04:30:35,233 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.448
2023-06-28 04:30:35,233 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.217
2023-06-28 04:30:35,233 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.144
2023-06-28 04:30:35,234 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.961
2023-06-28 04:30:35,234 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.941
2023-06-28 04:30:35,234 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:35,234 - optimal_runtime.py[116] - INFO: avg ratio: 1.3263314144059946
2023-06-28 04:30:35,234 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003170511837861749
2023-06-28 04:30:35,235 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063517 0.00046988 0.00037062 0.00054842 0.00060954 0.00071616
 0.00104659 0.00142199]
2023-06-28 04:30:35,237 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:35,352 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:35,352 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:35,353 - gen_series_legodnn_models.py[28] - INFO: target model size: 28.692MB
2023-06-28 04:30:35,353 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 30085232.595959596B (28.692MB), try to adapt blocks
2023-06-28 04:30:35,355 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:35,369 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0104017915725708
2023-06-28 04:30:35,369 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006621119976043702, 0.0004687039963901043, 0.0003194559998810291, 0.0005587520003318787, 0.0005996799916028978, 0.0006739200092852115, 0.0005665280073881149, 0.0011759680360555647]
2023-06-28 04:30:35,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.447
2023-06-28 04:30:35,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.736
2023-06-28 04:30:35,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.575
2023-06-28 04:30:35,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.421
2023-06-28 04:30:35,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.237
2023-06-28 04:30:35,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.152
2023-06-28 04:30:35,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-28 04:30:35,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.946
2023-06-28 04:30:35,370 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:35,370 - optimal_runtime.py[116] - INFO: avg ratio: 1.3140743563432118
2023-06-28 04:30:35,370 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003200084858214687
2023-06-28 04:30:35,370 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065714 0.0004654  0.00037501 0.00055875 0.00059968 0.00071129
 0.00101868 0.00141468]
2023-06-28 04:30:35,372 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:35,466 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:35,467 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:35,467 - gen_series_legodnn_models.py[28] - INFO: target model size: 29.126MB
2023-06-28 04:30:35,467 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 30540443.464646466B (29.126MB), try to adapt blocks
2023-06-28 04:30:35,469 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:35,486 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012066880226135253
2023-06-28 04:30:35,486 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000713856004178524, 0.0004881920032203198, 0.0003266559988260269, 0.0006053759977221488, 0.0007092160061001777, 0.0007499520108103753, 0.0006161279864609242, 0.0012716159895062445]
2023-06-28 04:30:35,486 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.342
2023-06-28 04:30:35,486 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.667
2023-06-28 04:30:35,486 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.540
2023-06-28 04:30:35,487 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.312
2023-06-28 04:30:35,487 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.046
2023-06-28 04:30:35,487 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.035
2023-06-28 04:30:35,487 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.908
2023-06-28 04:30:35,487 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.875
2023-06-28 04:30:35,487 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:35,488 - optimal_runtime.py[116] - INFO: avg ratio: 1.1835542831554524
2023-06-28 04:30:35,488 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0035529840161541647
2023-06-28 04:30:35,488 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0007085  0.00048475 0.00038346 0.00060538 0.00070922 0.00079154
 0.00110787 0.00152974]
2023-06-28 04:30:35,490 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:35,596 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:35,597 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:35,597 - gen_series_legodnn_models.py[28] - INFO: target model size: 29.560MB
2023-06-28 04:30:35,597 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 30995654.333333332B (29.560MB), try to adapt blocks
2023-06-28 04:30:35,599 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:35,613 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010379263877868652
2023-06-28 04:30:35,613 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000608640007674694, 0.0004573119916021824, 0.0003418559990823269, 0.000554784007370472, 0.0005960960015654564, 0.0006966720037162304, 0.0005607360042631627, 0.0011756160110235215]
2023-06-28 04:30:35,613 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.574
2023-06-28 04:30:35,613 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.779
2023-06-28 04:30:35,613 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.472
2023-06-28 04:30:35,613 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.431
2023-06-28 04:30:35,613 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.244
2023-06-28 04:30:35,613 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.114
2023-06-28 04:30:35,613 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.997
2023-06-28 04:30:35,613 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.947
2023-06-28 04:30:35,614 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:35,614 - optimal_runtime.py[116] - INFO: avg ratio: 1.3670658008957741
2023-06-28 04:30:35,614 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030760402663475932
2023-06-28 04:30:35,614 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060407 0.00045409 0.00040131 0.00055478 0.0005961  0.00073531
 0.00100827 0.00141425]
2023-06-28 04:30:35,616 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:35,708 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:35,709 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:35,709 - gen_series_legodnn_models.py[28] - INFO: target model size: 29.994MB
2023-06-28 04:30:35,709 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 31450865.2020202B (29.994MB), try to adapt blocks
2023-06-28 04:30:35,712 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:35,727 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01110707187652588
2023-06-28 04:30:35,727 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000622591994702816, 0.0004722559973597526, 0.00033759999647736547, 0.0005635200031101704, 0.0006106879971921443, 0.0006710719987750053, 0.0005718719884753227, 0.0012711360305547714]
2023-06-28 04:30:35,727 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.539
2023-06-28 04:30:35,727 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.723
2023-06-28 04:30:35,727 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.491
2023-06-28 04:30:35,727 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.409
2023-06-28 04:30:35,727 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.214
2023-06-28 04:30:35,727 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.157
2023-06-28 04:30:35,727 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.978
2023-06-28 04:30:35,727 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.875
2023-06-28 04:30:35,728 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:35,728 - optimal_runtime.py[116] - INFO: avg ratio: 1.3618396792102487
2023-06-28 04:30:35,728 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003087844710723036
2023-06-28 04:30:35,728 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061792 0.00046893 0.00039631 0.00056352 0.00061069 0.00070829
 0.00102829 0.00152916]
2023-06-28 04:30:35,731 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:35,839 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:35,840 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:35,841 - gen_series_legodnn_models.py[28] - INFO: target model size: 30.428MB
2023-06-28 04:30:35,841 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 31906076.07070707B (30.428MB), try to adapt blocks
2023-06-28 04:30:35,843 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:35,857 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010395648002624512
2023-06-28 04:30:35,857 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006279039978981018, 0.00046604799851775164, 0.000317440003156662, 0.0005573440007865429, 0.0006050879880785942, 0.0006732160001993179, 0.0005744319818913937, 0.0011800319701433183]
2023-06-28 04:30:35,857 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.525
2023-06-28 04:30:35,857 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.746
2023-06-28 04:30:35,857 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.585
2023-06-28 04:30:35,857 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.425
2023-06-28 04:30:35,858 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.226
2023-06-28 04:30:35,858 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.153
2023-06-28 04:30:35,858 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.973
2023-06-28 04:30:35,858 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.943
2023-06-28 04:30:35,858 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:35,858 - optimal_runtime.py[116] - INFO: avg ratio: 1.3828027124762698
2023-06-28 04:30:35,858 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003041033556241514
2023-06-28 04:30:35,859 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062319 0.00046277 0.00037264 0.00055734 0.00060509 0.00071055
 0.0010329  0.00141956]
2023-06-28 04:30:35,860 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:35,947 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:35,948 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:35,948 - gen_series_legodnn_models.py[28] - INFO: target model size: 30.862MB
2023-06-28 04:30:35,948 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 32361286.93939394B (30.862MB), try to adapt blocks
2023-06-28 04:30:35,950 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:35,965 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010957632064819336
2023-06-28 04:30:35,965 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006319679990410805, 0.0004555840045213699, 0.0003386240005493164, 0.0005606080032885075, 0.0006238399967551232, 0.0006857279986143113, 0.0005692799985408782, 0.001228383991867304]
2023-06-28 04:30:35,966 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.516
2023-06-28 04:30:35,966 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.786
2023-06-28 04:30:35,966 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.486
2023-06-28 04:30:35,966 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.417
2023-06-28 04:30:35,966 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.189
2023-06-28 04:30:35,966 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.132
2023-06-28 04:30:35,966 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.982
2023-06-28 04:30:35,966 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.906
2023-06-28 04:30:35,967 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:35,967 - optimal_runtime.py[116] - INFO: avg ratio: 1.3477732181642161
2023-06-28 04:30:35,967 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003120071977709945
2023-06-28 04:30:35,967 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062723 0.00045238 0.00039751 0.00056061 0.00062384 0.00072376
 0.00102363 0.00147773]
2023-06-28 04:30:35,969 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:36,078 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:36,078 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:36,079 - gen_series_legodnn_models.py[28] - INFO: target model size: 31.296MB
2023-06-28 04:30:36,079 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 32816497.808080807B (31.296MB), try to adapt blocks
2023-06-28 04:30:36,080 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:36,094 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010254336357116698
2023-06-28 04:30:36,094 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005968000069260597, 0.00045974399149417873, 0.00030723199993371963, 0.0005709119886159896, 0.0005920639932155609, 0.00066796800121665, 0.0005642560049891472, 0.0012030719816684722]
2023-06-28 04:30:36,094 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.605
2023-06-28 04:30:36,094 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.770
2023-06-28 04:30:36,094 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.638
2023-06-28 04:30:36,094 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.391
2023-06-28 04:30:36,095 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.253
2023-06-28 04:30:36,095 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.162
2023-06-28 04:30:36,095 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.991
2023-06-28 04:30:36,095 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.925
2023-06-28 04:30:36,095 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:36,095 - optimal_runtime.py[116] - INFO: avg ratio: 1.3526283082641228
2023-06-28 04:30:36,095 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003108872869664205
2023-06-28 04:30:36,096 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059232 0.00045651 0.00036066 0.00057091 0.00059206 0.00070501
 0.0010146  0.00144728]
2023-06-28 04:30:36,097 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:36,191 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:36,192 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:36,192 - gen_series_legodnn_models.py[28] - INFO: target model size: 31.730MB
2023-06-28 04:30:36,192 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 33271708.676767677B (31.730MB), try to adapt blocks
2023-06-28 04:30:36,194 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:36,209 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011500255584716797
2023-06-28 04:30:36,210 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007739520072937012, 0.00048572799935936927, 0.00033113599941134457, 0.0005899839960038663, 0.0006304960176348687, 0.0006957440041005612, 0.0005763199962675571, 0.0012758079990744591]
2023-06-28 04:30:36,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.238
2023-06-28 04:30:36,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.675
2023-06-28 04:30:36,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.520
2023-06-28 04:30:36,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.346
2023-06-28 04:30:36,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.176
2023-06-28 04:30:36,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.116
2023-06-28 04:30:36,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.970
2023-06-28 04:30:36,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.872
2023-06-28 04:30:36,211 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:36,211 - optimal_runtime.py[116] - INFO: avg ratio: 1.2188594934232737
2023-06-28 04:30:36,211 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0034500690793256177
2023-06-28 04:30:36,211 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00076815 0.00048231 0.00038872 0.00058998 0.0006305  0.00073433
 0.00103629 0.00153478]
2023-06-28 04:30:36,213 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:36,317 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:36,317 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:36,317 - gen_series_legodnn_models.py[28] - INFO: target model size: 32.164MB
2023-06-28 04:30:36,317 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 33726919.54545455B (32.164MB), try to adapt blocks
2023-06-28 04:30:36,319 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:36,335 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010708831787109374
2023-06-28 04:30:36,336 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005986239947378635, 0.00046275201067328455, 0.00032175999879837037, 0.0005542399995028973, 0.0006048640049993992, 0.0006641599833965301, 0.0005729920044541359, 0.0011981119848787785]
2023-06-28 04:30:36,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.600
2023-06-28 04:30:36,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.758
2023-06-28 04:30:36,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.564
2023-06-28 04:30:36,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.433
2023-06-28 04:30:36,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.226
2023-06-28 04:30:36,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.169
2023-06-28 04:30:36,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.976
2023-06-28 04:30:36,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.929
2023-06-28 04:30:36,337 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:36,337 - optimal_runtime.py[116] - INFO: avg ratio: 1.398299937120246
2023-06-28 04:30:36,337 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030073300718031167
2023-06-28 04:30:36,337 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059413 0.00045949 0.00037772 0.00055424 0.00060486 0.00070099
 0.00103031 0.00144132]
2023-06-28 04:30:36,339 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:36,431 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:36,432 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.8, 0.4]
2023-06-28 04:30:36,432 - gen_series_legodnn_models.py[28] - INFO: target model size: 32.599MB
2023-06-28 04:30:36,432 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 34182130.41414142B (32.599MB), try to adapt blocks
2023-06-28 04:30:36,434 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:36,450 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012267231941223145
2023-06-28 04:30:36,450 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006985600069165229, 0.0004889280050992965, 0.00033311999961733817, 0.0006442879922688008, 0.0006168640032410621, 0.0007742400094866753, 0.0006019840054213999, 0.001266080003231764]
2023-06-28 04:30:36,450 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.371
2023-06-28 04:30:36,450 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.664
2023-06-28 04:30:36,450 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.511
2023-06-28 04:30:36,450 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.233
2023-06-28 04:30:36,450 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.202
2023-06-28 04:30:36,451 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.002
2023-06-28 04:30:36,451 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.929
2023-06-28 04:30:36,451 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.879
2023-06-28 04:30:36,451 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:36,451 - optimal_runtime.py[116] - INFO: avg ratio: 1.202111785829885
2023-06-28 04:30:36,451 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003498135115112504
2023-06-28 04:30:36,452 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00069332 0.00048548 0.00039105 0.00064429 0.00061686 0.00081718
 0.00108244 0.00152308]
2023-06-28 04:30:36,454 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:36,554 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:36,555 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:36,560 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-28 04:30:36,568 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.0) from file
2023-06-28 04:30:36,569 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 867260416.0,
  'blocks_sparsity': [0.2, 0.0, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4],
  'esti_latency': 0.0031455095765791467,
  'esti_test_accuracy': 0.009966666189332804,
  'is_relaxed': False,
  'model_size': 34041421.0,
  'update_swap_mem_cost': 17429992.0,
  'update_swap_time_cost': 0.013878822326660156}
2023-06-28 04:30:36,598 - gen_series_legodnn_models.py[28] - INFO: target model size: 33.033MB
2023-06-28 04:30:36,598 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 34637341.28282829B (33.033MB), try to adapt blocks
2023-06-28 04:30:36,600 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:36,614 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010815135955810547
2023-06-28 04:30:36,614 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006080960035324096, 0.0004600959978997708, 0.00034041599184274677, 0.0005780799984931946, 0.0006089919954538345, 0.0006920960023999215, 0.001015263982117176, 0.00118275198712945]
2023-06-28 04:30:36,615 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.575
2023-06-28 04:30:36,615 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.756
2023-06-28 04:30:36,615 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.478
2023-06-28 04:30:36,615 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.374
2023-06-28 04:30:36,615 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.218
2023-06-28 04:30:36,615 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.121
2023-06-28 04:30:36,615 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.990
2023-06-28 04:30:36,615 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.941
2023-06-28 04:30:36,615 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:36,616 - optimal_runtime.py[116] - INFO: avg ratio: 1.3532594381415708
2023-06-28 04:30:36,616 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003107422961022942
2023-06-28 04:30:36,616 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060353 0.0004601  0.00039962 0.00057808 0.00060899 0.00073048
 0.00101526 0.00142284]
2023-06-28 04:30:36,618 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:36,717 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:36,718 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:36,724 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2023-06-28 04:30:36,724 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 934578176.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4],
  'esti_latency': 0.0028335193644308384,
  'esti_test_accuracy': 0.009966666189332804,
  'is_relaxed': False,
  'model_size': 34567757.0,
  'update_swap_mem_cost': 1272742.0,
  'update_swap_time_cost': 0.006033658981323242}
2023-06-28 04:30:36,764 - gen_series_legodnn_models.py[28] - INFO: target model size: 33.467MB
2023-06-28 04:30:36,764 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 35092552.15151515B (33.467MB), try to adapt blocks
2023-06-28 04:30:36,766 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:36,781 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010972928047180176
2023-06-28 04:30:36,781 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006092480011284352, 0.00046118400245904925, 0.0003969920016825199, 0.0005702080018818379, 0.0006078400015830993, 0.0007560319900512696, 0.0010101119801402092, 0.001189408041536808]
2023-06-28 04:30:36,781 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.572
2023-06-28 04:30:36,781 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.752
2023-06-28 04:30:36,781 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.488
2023-06-28 04:30:36,781 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.393
2023-06-28 04:30:36,781 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.220
2023-06-28 04:30:36,781 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.027
2023-06-28 04:30:36,782 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.995
2023-06-28 04:30:36,782 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.936
2023-06-28 04:30:36,782 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:36,782 - optimal_runtime.py[116] - INFO: avg ratio: 1.3399050722735866
2023-06-28 04:30:36,782 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003138393560348804
2023-06-28 04:30:36,783 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060468 0.00046118 0.00039699 0.00057021 0.00060784 0.00079796
 0.00101011 0.00143084]
2023-06-28 04:30:36,784 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:36,873 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:36,874 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:36,874 - gen_series_legodnn_models.py[28] - INFO: target model size: 33.901MB
2023-06-28 04:30:36,874 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 35547763.02020202B (33.901MB), try to adapt blocks
2023-06-28 04:30:36,876 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:36,890 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01100595188140869
2023-06-28 04:30:36,890 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006270720064640045, 0.0004546879976987839, 0.000393023993819952, 0.000555392000824213, 0.0005997120030224323, 0.0006992640048265456, 0.0010187200009822844, 0.0011665600389242172]
2023-06-28 04:30:36,891 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.528
2023-06-28 04:30:36,891 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.777
2023-06-28 04:30:36,891 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.503
2023-06-28 04:30:36,891 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.430
2023-06-28 04:30:36,891 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.237
2023-06-28 04:30:36,891 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.110
2023-06-28 04:30:36,891 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-28 04:30:36,891 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.954
2023-06-28 04:30:36,891 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:36,892 - optimal_runtime.py[116] - INFO: avg ratio: 1.361377853183595
2023-06-28 04:30:36,892 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030888922134794106
2023-06-28 04:30:36,892 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062237 0.00045469 0.00039302 0.00055539 0.00059971 0.00073804
 0.00101872 0.00140336]
2023-06-28 04:30:36,894 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:36,989 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:36,989 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:36,990 - gen_series_legodnn_models.py[28] - INFO: target model size: 34.335MB
2023-06-28 04:30:36,990 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 36002973.88888889B (34.335MB), try to adapt blocks
2023-06-28 04:30:36,992 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:37,008 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012678720474243165
2023-06-28 04:30:37,009 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007234559953212738, 0.0005924480110406875, 0.00043564799800515177, 0.0006231999956071377, 0.0006582400165498256, 0.0007254720032215119, 0.0010305600240826606, 0.00140406396985054]
2023-06-28 04:30:37,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.324
2023-06-28 04:30:37,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.364
2023-06-28 04:30:37,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.356
2023-06-28 04:30:37,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.274
2023-06-28 04:30:37,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.127
2023-06-28 04:30:37,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.070
2023-06-28 04:30:37,009 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.976
2023-06-28 04:30:37,010 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.793
2023-06-28 04:30:37,010 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5, 6]),)
2023-06-28 04:30:37,010 - optimal_runtime.py[116] - INFO: avg ratio: 1.154074497444729
2023-06-28 04:30:37,010 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0036437417685018345
2023-06-28 04:30:37,011 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00071803 0.00059245 0.00043565 0.0006232  0.00065824 0.0007657
 0.00103056 0.00168907]
2023-06-28 04:30:37,012 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:37,105 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:37,105 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:37,106 - gen_series_legodnn_models.py[28] - INFO: target model size: 34.769MB
2023-06-28 04:30:37,106 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 36458184.75757576B (34.769MB), try to adapt blocks
2023-06-28 04:30:37,107 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:37,121 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010100799560546875
2023-06-28 04:30:37,121 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005415359921753407, 0.0004279679991304874, 0.00037231999635696413, 0.0005270720086991787, 0.0005955200083553791, 0.0006554559879004956, 0.0009987519942224027, 0.0011567679941654205]
2023-06-28 04:30:37,121 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.769
2023-06-28 04:30:37,121 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.888
2023-06-28 04:30:37,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.587
2023-06-28 04:30:37,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.507
2023-06-28 04:30:37,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.245
2023-06-28 04:30:37,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.184
2023-06-28 04:30:37,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.007
2023-06-28 04:30:37,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.962
2023-06-28 04:30:37,122 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:37,122 - optimal_runtime.py[116] - INFO: avg ratio: 1.380667763823559
2023-06-28 04:30:37,122 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030457359550834823
2023-06-28 04:30:37,123 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00053747 0.00042797 0.00037232 0.00052707 0.00059552 0.0006918
 0.00099875 0.00139158]
2023-06-28 04:30:37,124 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:37,204 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:37,205 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:37,205 - gen_series_legodnn_models.py[28] - INFO: target model size: 35.203MB
2023-06-28 04:30:37,205 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 36913395.62626263B (35.203MB), try to adapt blocks
2023-06-28 04:30:37,207 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:37,222 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011100159645080567
2023-06-28 04:30:37,222 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006149119958281517, 0.00045257600396871565, 0.00040588799864053725, 0.0005942079946398735, 0.0006091839894652366, 0.0006943359971046448, 0.001022944014519453, 0.0012101119793951512]
2023-06-28 04:30:37,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.558
2023-06-28 04:30:37,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.785
2023-06-28 04:30:37,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.455
2023-06-28 04:30:37,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.337
2023-06-28 04:30:37,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.217
2023-06-28 04:30:37,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.118
2023-06-28 04:30:37,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.983
2023-06-28 04:30:37,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.920
2023-06-28 04:30:37,223 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:37,223 - optimal_runtime.py[116] - INFO: avg ratio: 1.3369408105063116
2023-06-28 04:30:37,223 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031453519985747123
2023-06-28 04:30:37,223 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006103  0.00045258 0.00040589 0.00059421 0.00060918 0.00073284
 0.00102294 0.00145575]
2023-06-28 04:30:37,225 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:37,335 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:37,336 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:37,336 - gen_series_legodnn_models.py[28] - INFO: target model size: 35.637MB
2023-06-28 04:30:37,336 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 37368606.4949495B (35.637MB), try to adapt blocks
2023-06-28 04:30:37,338 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:37,352 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010467328071594239
2023-06-28 04:30:37,353 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005469439923763275, 0.0004500799961388111, 0.0003968000002205372, 0.0005436479970812798, 0.0005990079864859582, 0.0006884160116314888, 0.0009997439607977868, 0.0011717119738459587]
2023-06-28 04:30:37,353 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.751
2023-06-28 04:30:37,353 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.795
2023-06-28 04:30:37,353 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.489
2023-06-28 04:30:37,353 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.461
2023-06-28 04:30:37,353 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.238
2023-06-28 04:30:37,353 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.127
2023-06-28 04:30:37,353 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.006
2023-06-28 04:30:37,353 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.950
2023-06-28 04:30:37,354 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:37,354 - optimal_runtime.py[116] - INFO: avg ratio: 1.3287266693349462
2023-06-28 04:30:37,354 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031647964531387653
2023-06-28 04:30:37,354 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00054284 0.00045008 0.0003968  0.00054365 0.00059901 0.00072659
 0.00099974 0.00140956]
2023-06-28 04:30:37,356 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:37,443 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:37,444 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:37,444 - gen_series_legodnn_models.py[28] - INFO: target model size: 36.072MB
2023-06-28 04:30:37,444 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 37823817.36363637B (36.072MB), try to adapt blocks
2023-06-28 04:30:37,446 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:37,461 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011571295738220215
2023-06-28 04:30:37,461 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006564160026609899, 0.0004694079980254174, 0.0003874239958822727, 0.000582047987729311, 0.000615423996001482, 0.0006882240064442157, 0.0010105279982089996, 0.0012236479967832566]
2023-06-28 04:30:37,461 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.459
2023-06-28 04:30:37,461 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.721
2023-06-28 04:30:37,461 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.525
2023-06-28 04:30:37,462 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.364
2023-06-28 04:30:37,462 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.205
2023-06-28 04:30:37,462 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.128
2023-06-28 04:30:37,462 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.995
2023-06-28 04:30:37,462 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.909
2023-06-28 04:30:37,462 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:37,462 - optimal_runtime.py[116] - INFO: avg ratio: 1.3362153919450026
2023-06-28 04:30:37,463 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031470595801033874
2023-06-28 04:30:37,463 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065149 0.00046941 0.00038742 0.00058205 0.00061542 0.00072639
 0.00101053 0.00147203]
2023-06-28 04:30:37,465 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:37,573 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:37,573 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:37,573 - gen_series_legodnn_models.py[28] - INFO: target model size: 36.506MB
2023-06-28 04:30:37,573 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 38279028.23232323B (36.506MB), try to adapt blocks
2023-06-28 04:30:37,575 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:37,589 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010671615600585938
2023-06-28 04:30:37,589 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006032320037484169, 0.000453344002366066, 0.00038719999790191644, 0.0005663679987192153, 0.0006024319902062416, 0.000669824007898569, 0.0010066560171544552, 0.0011579519994556905]
2023-06-28 04:30:37,589 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.588
2023-06-28 04:30:37,590 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.782
2023-06-28 04:30:37,590 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.526
2023-06-28 04:30:37,590 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.402
2023-06-28 04:30:37,590 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.231
2023-06-28 04:30:37,590 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.159
2023-06-28 04:30:37,590 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.999
2023-06-28 04:30:37,590 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.961
2023-06-28 04:30:37,590 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:37,590 - optimal_runtime.py[116] - INFO: avg ratio: 1.3810704260739972
2023-06-28 04:30:37,591 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030448479461371164
2023-06-28 04:30:37,591 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059871 0.00045334 0.0003872  0.00056637 0.00060243 0.00070697
 0.00100666 0.001393  ]
2023-06-28 04:30:37,593 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:37,686 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:37,687 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:37,687 - gen_series_legodnn_models.py[28] - INFO: target model size: 36.940MB
2023-06-28 04:30:37,687 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 38734239.1010101B (36.940MB), try to adapt blocks
2023-06-28 04:30:37,689 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:37,705 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012056575775146485
2023-06-28 04:30:37,705 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006336320042610169, 0.0004921599999070168, 0.0004185599908232689, 0.0005547839850187302, 0.0006261119917035103, 0.0007306239865720272, 0.0010330880135297775, 0.001205664034932852]
2023-06-28 04:30:37,705 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.512
2023-06-28 04:30:37,705 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.642
2023-06-28 04:30:37,705 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.411
2023-06-28 04:30:37,705 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.431
2023-06-28 04:30:37,705 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.184
2023-06-28 04:30:37,706 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.062
2023-06-28 04:30:37,706 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.973
2023-06-28 04:30:37,706 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.923
2023-06-28 04:30:37,706 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:37,706 - optimal_runtime.py[116] - INFO: avg ratio: 1.3202335512228358
2023-06-28 04:30:37,706 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031851557221880935
2023-06-28 04:30:37,707 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062888 0.00049216 0.00041856 0.00055478 0.00062611 0.00077114
 0.00103309 0.0014504 ]
2023-06-28 04:30:37,709 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:37,804 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:37,805 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:37,805 - gen_series_legodnn_models.py[28] - INFO: target model size: 37.374MB
2023-06-28 04:30:37,805 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 39189449.96969697B (37.374MB), try to adapt blocks
2023-06-28 04:30:37,807 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:37,821 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01024614429473877
2023-06-28 04:30:37,821 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005429440028965473, 0.00042108799517154695, 0.00038047999888658524, 0.0005460799895226956, 0.0005886400081217289, 0.0006782719865441323, 0.0009942399635910987, 0.001195808004587889]
2023-06-28 04:30:37,821 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.764
2023-06-28 04:30:37,821 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.919
2023-06-28 04:30:37,821 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.553
2023-06-28 04:30:37,821 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.454
2023-06-28 04:30:37,821 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.260
2023-06-28 04:30:37,821 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.144
2023-06-28 04:30:37,821 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.011
2023-06-28 04:30:37,822 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.931
2023-06-28 04:30:37,822 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:37,822 - optimal_runtime.py[116] - INFO: avg ratio: 1.352730280305694
2023-06-28 04:30:37,822 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003108638515397046
2023-06-28 04:30:37,823 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00053887 0.00042109 0.00038048 0.00054608 0.00058864 0.00071589
 0.00099424 0.00143854]
2023-06-28 04:30:37,828 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:37,920 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:37,921 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:37,921 - gen_series_legodnn_models.py[28] - INFO: target model size: 37.808MB
2023-06-28 04:30:37,921 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 39644660.83838384B (37.808MB), try to adapt blocks
2023-06-28 04:30:37,923 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:37,938 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011492287635803223
2023-06-28 04:30:37,938 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006753280051052571, 0.0004997760020196438, 0.0003997120037674904, 0.0005656320005655289, 0.000607072003185749, 0.0007177279889583587, 0.001007359992712736, 0.0012322559878230096]
2023-06-28 04:30:37,939 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.418
2023-06-28 04:30:37,939 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.617
2023-06-28 04:30:37,939 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.478
2023-06-28 04:30:37,939 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.404
2023-06-28 04:30:37,939 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.222
2023-06-28 04:30:37,939 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.081
2023-06-28 04:30:37,939 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.998
2023-06-28 04:30:37,939 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.903
2023-06-28 04:30:37,940 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:37,940 - optimal_runtime.py[116] - INFO: avg ratio: 1.3206320109379157
2023-06-28 04:30:37,940 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031841947003205056
2023-06-28 04:30:37,940 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067026 0.00049978 0.00039971 0.00056563 0.00060707 0.00075753
 0.00100736 0.00148239]
2023-06-28 04:30:37,942 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:38,043 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:38,043 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:38,044 - gen_series_legodnn_models.py[28] - INFO: target model size: 38.242MB
2023-06-28 04:30:38,044 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 40099871.70707071B (38.242MB), try to adapt blocks
2023-06-28 04:30:38,046 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:38,059 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010420767784118653
2023-06-28 04:30:38,059 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005647680014371872, 0.00043814400210976604, 0.0004038400091230869, 0.0005455680042505263, 0.0005981120094656944, 0.0006616000048816204, 0.0010008639581501485, 0.001162784021347761]
2023-06-28 04:30:38,059 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.696
2023-06-28 04:30:38,060 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.844
2023-06-28 04:30:38,060 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.463
2023-06-28 04:30:38,060 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.456
2023-06-28 04:30:38,060 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.240
2023-06-28 04:30:38,060 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.173
2023-06-28 04:30:38,060 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.005
2023-06-28 04:30:38,060 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.957
2023-06-28 04:30:38,060 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:38,060 - optimal_runtime.py[116] - INFO: avg ratio: 1.3328412733262187
2023-06-28 04:30:38,060 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031550264344739377
2023-06-28 04:30:38,061 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00056053 0.00043814 0.00040384 0.00054557 0.00059811 0.00069829
 0.00100086 0.00139882]
2023-06-28 04:30:38,063 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:38,148 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:38,149 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:38,150 - gen_series_legodnn_models.py[28] - INFO: target model size: 38.676MB
2023-06-28 04:30:38,150 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 40555082.57575758B (38.676MB), try to adapt blocks
2023-06-28 04:30:38,155 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:38,184 - optimal_runtime.py[77] - INFO: infer time of current model: 0.019963584899902343
2023-06-28 04:30:38,184 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0013768000081181525, 0.000985376000404358, 0.0005583679974079131, 0.000841376006603241, 0.0008490879982709884, 0.0009079999998211862, 0.0011120960190892219, 0.0013796160146594047]
2023-06-28 04:30:38,184 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.696
2023-06-28 04:30:38,184 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.820
2023-06-28 04:30:38,184 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.058
2023-06-28 04:30:38,184 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.944
2023-06-28 04:30:38,184 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.873
2023-06-28 04:30:38,184 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.855
2023-06-28 04:30:38,185 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.904
2023-06-28 04:30:38,185 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.807
2023-06-28 04:30:38,185 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4, 5, 6, 7]),)
2023-06-28 04:30:38,185 - optimal_runtime.py[116] - INFO: avg ratio: 0.8670989784189643
2023-06-28 04:30:38,185 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004849676397923608
2023-06-28 04:30:38,186 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00136647 0.00098538 0.00055837 0.00084138 0.00084909 0.00095835
 0.0011121  0.00165966]
2023-06-28 04:30:38,188 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:38,280 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:38,281 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:38,281 - gen_series_legodnn_models.py[28] - INFO: target model size: 39.110MB
2023-06-28 04:30:38,281 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 41010293.44444445B (39.110MB), try to adapt blocks
2023-06-28 04:30:38,283 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:38,297 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010355039596557617
2023-06-28 04:30:38,297 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005819199979305267, 0.0004576639942824841, 0.0003791040033102036, 0.0005330559983849526, 0.0005965120121836662, 0.0006755840070545674, 0.0009975360035896302, 0.0011547520123422145]
2023-06-28 04:30:38,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.646
2023-06-28 04:30:38,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.765
2023-06-28 04:30:38,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.558
2023-06-28 04:30:38,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.490
2023-06-28 04:30:38,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.243
2023-06-28 04:30:38,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.149
2023-06-28 04:30:38,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.008
2023-06-28 04:30:38,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.964
2023-06-28 04:30:38,298 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:38,298 - optimal_runtime.py[116] - INFO: avg ratio: 1.3600040363000547
2023-06-28 04:30:38,298 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003092012477949992
2023-06-28 04:30:38,298 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00057755 0.00045766 0.0003791  0.00053306 0.00059651 0.00071305
 0.00099754 0.00138915]
2023-06-28 04:30:38,300 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:38,389 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:38,389 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:38,390 - gen_series_legodnn_models.py[28] - INFO: target model size: 39.545MB
2023-06-28 04:30:38,390 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 41465504.31313131B (39.545MB), try to adapt blocks
2023-06-28 04:30:38,391 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:38,407 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012207167625427246
2023-06-28 04:30:38,408 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0008659199960529805, 0.0005208639912307262, 0.0004184640049934387, 0.0005860800035297871, 0.0006281600072979927, 0.0007057920098304749, 0.0010199360139667988, 0.0013393280170857906]
2023-06-28 04:30:38,408 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.106
2023-06-28 04:30:38,408 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.551
2023-06-28 04:30:38,408 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.412
2023-06-28 04:30:38,408 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.355
2023-06-28 04:30:38,408 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.181
2023-06-28 04:30:38,408 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.100
2023-06-28 04:30:38,408 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.986
2023-06-28 04:30:38,408 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.831
2023-06-28 04:30:38,409 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5, 6]),)
2023-06-28 04:30:38,409 - optimal_runtime.py[116] - INFO: avg ratio: 1.1897977547133898
2023-06-28 04:30:38,409 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0035343397091172866
2023-06-28 04:30:38,409 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00085942 0.00052086 0.00041846 0.00058608 0.00062816 0.00074493
 0.00101994 0.0016112 ]
2023-06-28 04:30:38,411 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:38,512 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:38,513 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:38,516 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.6) from file
2023-06-28 04:30:38,517 - gen_series_legodnn_models.py[28] - INFO: target model size: 39.979MB
2023-06-28 04:30:38,517 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 41920715.18181818B (39.979MB), try to adapt blocks
2023-06-28 04:30:38,518 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:38,532 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010231807708740234
2023-06-28 04:30:38,532 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005591040067374705, 0.00043455999717116356, 0.000308448001742363, 0.0005490879900753498, 0.0005905599966645241, 0.0006592640131711959, 0.0010089600160717964, 0.0011637440025806425]
2023-06-28 04:30:38,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.713
2023-06-28 04:30:38,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.859
2023-06-28 04:30:38,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.631
2023-06-28 04:30:38,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.446
2023-06-28 04:30:38,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.256
2023-06-28 04:30:38,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.177
2023-06-28 04:30:38,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.996
2023-06-28 04:30:38,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.956
2023-06-28 04:30:38,533 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:38,533 - optimal_runtime.py[116] - INFO: avg ratio: 1.37767705305901
2023-06-28 04:30:38,533 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030523477479464153
2023-06-28 04:30:38,533 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00055491 0.00043456 0.00036209 0.00054909 0.00059056 0.00069582
 0.00100896 0.00139997]
2023-06-28 04:30:38,535 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:38,615 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:38,616 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:38,616 - gen_series_legodnn_models.py[28] - INFO: target model size: 40.413MB
2023-06-28 04:30:38,616 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 42375926.05050505B (40.413MB), try to adapt blocks
2023-06-28 04:30:38,618 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:38,633 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010946687698364257
2023-06-28 04:30:38,633 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006167999990284444, 0.00045372800156474115, 0.000315263994038105, 0.0005578879974782468, 0.0005990400016307831, 0.0007002239935100079, 0.0010302080251276492, 0.0011919039785861971]
2023-06-28 04:30:38,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.553
2023-06-28 04:30:38,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.781
2023-06-28 04:30:38,634 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.596
2023-06-28 04:30:38,634 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.424
2023-06-28 04:30:38,634 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.238
2023-06-28 04:30:38,634 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.108
2023-06-28 04:30:38,634 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.976
2023-06-28 04:30:38,634 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.934
2023-06-28 04:30:38,634 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:38,634 - optimal_runtime.py[116] - INFO: avg ratio: 1.383787002425945
2023-06-28 04:30:38,634 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003038870464117664
2023-06-28 04:30:38,635 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061217 0.00045373 0.00037009 0.00055789 0.00059904 0.00073906
 0.00103021 0.00143385]
2023-06-28 04:30:38,637 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:38,742 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:38,742 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:38,743 - gen_series_legodnn_models.py[28] - INFO: target model size: 40.847MB
2023-06-28 04:30:38,743 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 42831136.91919192B (40.847MB), try to adapt blocks
2023-06-28 04:30:38,744 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:38,758 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01036083221435547
2023-06-28 04:30:38,758 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005583680048584938, 0.00042451200634241107, 0.00030508800223469736, 0.000568800002336502, 0.0005877759903669357, 0.0006654720082879066, 0.0009999999776482583, 0.0012037440054118633]
2023-06-28 04:30:38,758 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.715
2023-06-28 04:30:38,758 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.903
2023-06-28 04:30:38,759 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.649
2023-06-28 04:30:38,759 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.396
2023-06-28 04:30:38,759 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.262
2023-06-28 04:30:38,759 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.166
2023-06-28 04:30:38,759 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.005
2023-06-28 04:30:38,759 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.924
2023-06-28 04:30:38,759 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:38,759 - optimal_runtime.py[116] - INFO: avg ratio: 1.3683791178438052
2023-06-28 04:30:38,759 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030730880027812026
2023-06-28 04:30:38,760 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00055418 0.00042451 0.00035814 0.0005688  0.00058778 0.00070238
 0.001      0.00144809]
2023-06-28 04:30:38,761 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:38,852 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:38,852 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:38,852 - gen_series_legodnn_models.py[28] - INFO: target model size: 41.281MB
2023-06-28 04:30:38,853 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 43286347.78787879B (41.281MB), try to adapt blocks
2023-06-28 04:30:38,855 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:38,871 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012213376045227051
2023-06-28 04:30:38,871 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006549440026283265, 0.00047539199888706207, 0.00031948800012469294, 0.0005771200060844422, 0.0006228800155222416, 0.0007681279964745044, 0.0010520320124924182, 0.00130182396620512]
2023-06-28 04:30:38,871 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.463
2023-06-28 04:30:38,871 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.700
2023-06-28 04:30:38,872 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.575
2023-06-28 04:30:38,872 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.376
2023-06-28 04:30:38,872 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.191
2023-06-28 04:30:38,872 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.010
2023-06-28 04:30:38,872 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.956
2023-06-28 04:30:38,872 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.855
2023-06-28 04:30:38,872 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-28 04:30:38,872 - optimal_runtime.py[116] - INFO: avg ratio: 1.2598967617864916
2023-06-28 04:30:38,873 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003337693672884246
2023-06-28 04:30:38,873 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065003 0.00047539 0.00037505 0.00057712 0.00062288 0.00081073
 0.00105203 0.00156608]
2023-06-28 04:30:38,875 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:38,975 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:38,976 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:38,976 - gen_series_legodnn_models.py[28] - INFO: target model size: 41.715MB
2023-06-28 04:30:38,976 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 43741558.65656566B (41.715MB), try to adapt blocks
2023-06-28 04:30:38,978 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:38,991 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010110912322998046
2023-06-28 04:30:38,991 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005513600036501884, 0.00043910399824380873, 0.0003116160035133362, 0.0005392319932579994, 0.0005857600085437298, 0.0006581759937107563, 0.0009948799610137939, 0.0011607359983026983]
2023-06-28 04:30:38,991 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.737
2023-06-28 04:30:38,991 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.840
2023-06-28 04:30:38,992 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.615
2023-06-28 04:30:38,992 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.473
2023-06-28 04:30:38,992 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.266
2023-06-28 04:30:38,992 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.179
2023-06-28 04:30:38,992 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.011
2023-06-28 04:30:38,992 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.959
2023-06-28 04:30:38,992 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-28 04:30:38,992 - optimal_runtime.py[116] - INFO: avg ratio: 1.3831988378122126
2023-06-28 04:30:38,992 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003040162654382614
2023-06-28 04:30:38,993 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00054722 0.0004391  0.00036581 0.00053923 0.00058576 0.00069468
 0.00099488 0.00139635]
2023-06-28 04:30:38,994 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:39,078 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:39,078 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:39,079 - gen_series_legodnn_models.py[28] - INFO: target model size: 42.149MB
2023-06-28 04:30:39,079 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 44196769.52525253B (42.149MB), try to adapt blocks
2023-06-28 04:30:39,081 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:39,097 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012828960418701171
2023-06-28 04:30:39,097 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006804160028696061, 0.0004817919954657554, 0.0003356480039656162, 0.000577376000583172, 0.0006367999874055386, 0.0006903039962053299, 0.0010496959947049619, 0.0012439359761774538]
2023-06-28 04:30:39,098 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.408
2023-06-28 04:30:39,098 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.677
2023-06-28 04:30:39,098 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.499
2023-06-28 04:30:39,098 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.375
2023-06-28 04:30:39,098 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.165
2023-06-28 04:30:39,098 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.124
2023-06-28 04:30:39,098 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.958
2023-06-28 04:30:39,098 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.895
2023-06-28 04:30:39,098 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:39,099 - optimal_runtime.py[116] - INFO: avg ratio: 1.3142565635089023
2023-06-28 04:30:39,099 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003199641201771817
2023-06-28 04:30:39,099 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067531 0.00048179 0.00039402 0.00057738 0.0006368  0.00072859
 0.0010497  0.00149644]
2023-06-28 04:30:39,101 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:39,203 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:39,203 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:39,204 - gen_series_legodnn_models.py[28] - INFO: target model size: 42.583MB
2023-06-28 04:30:39,204 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 44651980.39393939B (42.583MB), try to adapt blocks
2023-06-28 04:30:39,206 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:39,220 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010859392166137695
2023-06-28 04:30:39,220 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006053439900279045, 0.0004745280034840107, 0.0003260160014033317, 0.0005616639964282511, 0.0005997120104730129, 0.00067772800847888, 0.001016736015677452, 0.0011686080098152161]
2023-06-28 04:30:39,220 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.582
2023-06-28 04:30:39,220 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.703
2023-06-28 04:30:39,220 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.543
2023-06-28 04:30:39,220 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.414
2023-06-28 04:30:39,220 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.237
2023-06-28 04:30:39,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.145
2023-06-28 04:30:39,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.989
2023-06-28 04:30:39,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.952
2023-06-28 04:30:39,221 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:39,221 - optimal_runtime.py[116] - INFO: avg ratio: 1.384303753683852
2023-06-28 04:30:39,221 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00303773607426228
2023-06-28 04:30:39,222 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006008  0.00047453 0.00038271 0.00056166 0.00059971 0.00071531
 0.00101674 0.00140582]
2023-06-28 04:30:39,223 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:39,311 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:39,312 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:39,317 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.8) from file
2023-06-28 04:30:39,321 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2023-06-28 04:30:39,322 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 814045184.0,
  'blocks_sparsity': [0.2, 0.8, 0.0, 0.0, 0.0, 0.6, 0.0, 0.4],
  'esti_latency': 0.002770845089281801,
  'esti_test_accuracy': 0.009966666189332804,
  'is_relaxed': False,
  'model_size': 34331917.0,
  'update_swap_mem_cost': 1663720.0,
  'update_swap_time_cost': 0.009673595428466797}
2023-06-28 04:30:39,365 - gen_series_legodnn_models.py[28] - INFO: target model size: 43.018MB
2023-06-28 04:30:39,365 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 45107191.26262626B (43.018MB), try to adapt blocks
2023-06-28 04:30:39,367 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:39,385 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013066240310668945
2023-06-28 04:30:39,385 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007531520053744317, 0.0005320959910750389, 0.00045414400845766065, 0.0006291519999504089, 0.0006446720100939274, 0.0008267519995570182, 0.0010612799786031246, 0.0013467519879341125]
2023-06-28 04:30:39,385 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.272
2023-06-28 04:30:39,386 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.529
2023-06-28 04:30:39,386 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.301
2023-06-28 04:30:39,386 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.262
2023-06-28 04:30:39,386 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.150
2023-06-28 04:30:39,386 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.939
2023-06-28 04:30:39,386 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.947
2023-06-28 04:30:39,386 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.826
2023-06-28 04:30:39,387 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5, 6]),)
2023-06-28 04:30:39,387 - optimal_runtime.py[116] - INFO: avg ratio: 1.145202620267021
2023-06-28 04:30:39,387 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003671969812050928
2023-06-28 04:30:39,388 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0007475  0.00052835 0.00045414 0.00062915 0.00064467 0.0008726
 0.00106128 0.00162013]
2023-06-28 04:30:39,389 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:39,477 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:39,478 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:39,481 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.6) from file
2023-06-28 04:30:39,482 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 746727424.0,
  'blocks_sparsity': [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4],
  'esti_latency': 0.0032948666606330114,
  'esti_test_accuracy': 0.009966666189332804,
  'is_relaxed': False,
  'model_size': 33805581.0,
  'update_swap_mem_cost': 1272742.0,
  'update_swap_time_cost': 0.003866910934448242}
2023-06-28 04:30:39,512 - gen_series_legodnn_models.py[28] - INFO: target model size: 43.452MB
2023-06-28 04:30:39,513 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 45562402.13131313B (43.452MB), try to adapt blocks
2023-06-28 04:30:39,515 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:39,530 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012020192146301269
2023-06-28 04:30:39,530 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0008434240072965621, 0.0004381759986281395, 0.0003349120020866394, 0.0006114560067653655, 0.0006550080031156539, 0.0007022079862654209, 0.0010277759842574597, 0.0012845440171658992]
2023-06-28 04:30:39,530 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.136
2023-06-28 04:30:39,530 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.857
2023-06-28 04:30:39,530 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.502
2023-06-28 04:30:39,530 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.299
2023-06-28 04:30:39,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.132
2023-06-28 04:30:39,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.105
2023-06-28 04:30:39,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.978
2023-06-28 04:30:39,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.866
2023-06-28 04:30:39,531 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5, 6]),)
2023-06-28 04:30:39,531 - optimal_runtime.py[116] - INFO: avg ratio: 1.1921050752797402
2023-06-28 04:30:39,531 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003527498991072863
2023-06-28 04:30:39,532 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0008371  0.00043509 0.00039315 0.00061146 0.00065501 0.00074115
 0.00102778 0.00154529]
2023-06-28 04:30:39,534 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:39,636 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:39,637 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
2023-06-28 04:30:39,637 - gen_series_legodnn_models.py[28] - INFO: target model size: 43.886MB
2023-06-28 04:30:39,638 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 46017613.0B (43.886MB), try to adapt blocks
2023-06-28 04:30:39,639 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-28 04:30:39,653 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01054099178314209
2023-06-28 04:30:39,653 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006042880043387413, 0.0004684799946844578, 0.00031129600107669827, 0.0005526080019772053, 0.000595904003828764, 0.0006760319955646992, 0.001001472022384405, 0.0011602559983730316]
2023-06-28 04:30:39,653 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.585
2023-06-28 04:30:39,654 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.737
2023-06-28 04:30:39,654 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.616
2023-06-28 04:30:39,654 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.437
2023-06-28 04:30:39,654 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.244
2023-06-28 04:30:39,654 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.148
2023-06-28 04:30:39,654 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.004
2023-06-28 04:30:39,654 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.959
2023-06-28 04:30:39,654 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-28 04:30:39,654 - optimal_runtime.py[116] - INFO: avg ratio: 1.406242993700874
2023-06-28 04:30:39,654 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029903433966524083
2023-06-28 04:30:39,655 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059975 0.00046518 0.00036543 0.00055261 0.0005959  0.00071352
 0.00100147 0.00139577]
2023-06-28 04:30:39,657 - optimal_runtime.py[226] - INFO: solving...
2023-06-28 04:30:39,738 - optimal_runtime.py[228] - INFO: solving finished
2023-06-28 04:30:39,739 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.8, 0.6, 0.0, 0.0, 0.6, 0.0, 0.4]
