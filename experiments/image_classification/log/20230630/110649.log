
2023-06-30 11:06:49,534 - log.py[38] - DEBUG: entry file content: ---------------------------------
2023-06-30 11:06:49,534 - log.py[39] - DEBUG: 
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

from legodnn.utils.dl.common.env import set_random_seed
set_random_seed(0)

import sys
sys.setrecursionlimit(100000) # 最大随机深度（与资源占用有关）
import torch

from legodnn import BlockExtractor, BlockTrainer, ServerBlockProfiler, EdgeBlockProfiler, OptimalRuntime
from legodnn.gen_series_legodnn_models import gen_series_legodnn_models
from legodnn.block_detection.model_topology_extraction import topology_extraction  # 构建模型拓扑结构
from legodnn.presets.auto_block_manager import AutoBlockManager
from legodnn.presets.common_detection_manager_1204_new import CommonDetectionManager
from legodnn.model_manager.common_model_manager import CommonModelManager  # AbstractModelManager的实现
from legodnn.utils.common.file import experiments_model_file_path
from legodnn.utils.dl.common.model import get_module, set_module, get_model_size

from cv_task.datasets.image_classification.cifar_dataloader import CIFAR10Dataloader, CIFAR100Dataloader
from cv_task.image_classification.cifar.models import resnet18
from cv_task.image_classification.cifar.legodnn_configs import get_cifar100_train_config_200e
dataset_root_dir = '/home/marcus/newspace/datasets'

if __name__ == '__main__':
    cv_task = 'image_classification'
    dataset_name = 'cifar100'
    model_name = 'resnet18'
    method = 'legodnn'
    device = 'cuda'
    compress_layer_max_ratio = 0.125  # 最大压缩比？？？
    model_input_size = (1, 3, 32, 32)
    
    block_sparsity = [0.0, 0.2, 0.4, 0.6, 0.8]
    root_path = os.path.join('results/legodnn', cv_task, model_name+'_'+dataset_name + '_' + str(compress_layer_max_ratio).replace('.', '-'))

    compressed_blocks_dir_path = root_path + '/compressed'  # 压缩后的block
    trained_blocks_dir_path = root_path + '/trained'  # 训练过的block
    descendant_models_dir_path = root_path + '/descendant'  # 后代block
    block_training_max_epoch = 65
    test_sample_num = 100
    
    checkpoint = '/home/marcus/newspace/LegoDNN_teacher_model/cifar100/resnet18/2023-06-28/13-03-18/resnet18.pth'
    teacher_model = resnet18(num_classes=100).to(device)
    teacher_model.load_state_dict(torch.load(checkpoint)['net'])  # 权重导入（初次训练没有）

    print('\033[1;36m-------------------------------->    BUILD LEGODNN GRAPH\033[0m')  # 构建拓扑结构
    model_graph = topology_extraction(teacher_model, model_input_size, device=device, mode='unpack')  # pack/unpack
    model_graph.print_ordered_node()  # 按顺序打印节点
    
    print('\033[1;36m-------------------------------->    START BLOCK DETECTION\033[0m')  # 根据拓扑结构探测block
    detection_manager = CommonDetectionManager(model_graph, max_ratio=compress_layer_max_ratio)
    detection_manager.detection_all_blocks()
    detection_manager.print_all_blocks()

    # modelmanager和blockmanager
    model_manager = CommonModelManager()
    block_manager = AutoBlockManager(block_sparsity, detection_manager, model_manager)
    
    print('\033[1;36m-------------------------------->    START BLOCK EXTRACTION\033[0m')  # block导出
    block_extractor = BlockExtractor(teacher_model, block_manager, compressed_blocks_dir_path, model_input_size, device)
    block_extractor.extract_all_blocks()  # 按稀疏度导出blocks

    print('\033[1;36m-------------------------------->    START BLOCK TRAIN\033[0m')
    # num_workers>=1 报错 ValueError: signal number 32 out of range
    train_loader, test_loader = CIFAR100Dataloader(root_dir=dataset_root_dir, num_workers=0, train_batch_size=128, test_batch_size=128)
    print("\033[32mDataloader done\033[0m")
    block_trainer = BlockTrainer(teacher_model, block_manager, model_manager, compressed_blocks_dir_path,
                                 trained_blocks_dir_path, block_training_max_epoch, train_loader, device=device)
    print("\033[32mDatatrainer initialized\033[0m")
    block_trainer.train_all_blocks()
    print("\033[32mBlock trained\033[0m")

    # memory,accuracy profiler (original blocks & compressed blocks)
    server_block_profiler = ServerBlockProfiler(teacher_model, block_manager, model_manager,
                                                trained_blocks_dir_path, test_loader, model_input_size, device)
    server_block_profiler.profile_all_blocks()

    # latency profiler (original blocks & compressed blocks)
    edge_block_profiler = EdgeBlockProfiler(block_manager, model_manager, trained_blocks_dir_path, 
                                            test_sample_num, model_input_size, device)
    edge_block_profiler.profile_all_blocks()

    optimal_runtime = OptimalRuntime(trained_blocks_dir_path, model_input_size,
                                     block_manager, model_manager, device)
    model_size_min = get_model_size(torch.load(os.path.join(compressed_blocks_dir_path, 'model_frame.pt')))/1024**2
    model_size_max = get_model_size(teacher_model)/1024**2 + 1
    gen_series_legodnn_models(deadline=100, model_size_search_range=[model_size_min, model_size_max], target_model_num=100, optimal_runtime=optimal_runtime, descendant_models_save_path=descendant_models_dir_path, device=device)
2023-06-30 11:06:49,534 - log.py[40] - DEBUG: entry file content: ---------------------------------
2023-06-30 11:06:56,258 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-0.pt
2023-06-30 11:06:56,258 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:56,558 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-2.pt
2023-06-30 11:06:56,558 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:56,839 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-4.pt
2023-06-30 11:06:56,839 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:57,142 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-6.pt
2023-06-30 11:06:57,142 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:57,442 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-8.pt
2023-06-30 11:06:57,442 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:57,471 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-0.pt
2023-06-30 11:06:57,471 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:57,752 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-2.pt
2023-06-30 11:06:57,752 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:58,040 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-4.pt
2023-06-30 11:06:58,040 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:58,323 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-6.pt
2023-06-30 11:06:58,323 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:58,623 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-8.pt
2023-06-30 11:06:58,623 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:06:58,654 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-0.pt
2023-06-30 11:06:58,654 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:06:58,898 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-2.pt
2023-06-30 11:06:58,898 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:06:59,145 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-4.pt
2023-06-30 11:06:59,145 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 77, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:06:59,381 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-6.pt
2023-06-30 11:06:59,381 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:06:59,681 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-8.pt
2023-06-30 11:06:59,681 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:06:59,715 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-0.pt
2023-06-30 11:06:59,715 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:00,022 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-2.pt
2023-06-30 11:07:00,022 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:00,352 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-4.pt
2023-06-30 11:07:00,352 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:00,617 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-6.pt
2023-06-30 11:07:00,617 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:00,880 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-8.pt
2023-06-30 11:07:00,880 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:00,915 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-0.pt
2023-06-30 11:07:00,915 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:01,134 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-2.pt
2023-06-30 11:07:01,134 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:01,373 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-4.pt
2023-06-30 11:07:01,373 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 154, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(154, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:01,602 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-6.pt
2023-06-30 11:07:01,602 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:01,910 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-8.pt
2023-06-30 11:07:01,910 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:01,961 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-0.pt
2023-06-30 11:07:01,961 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:02,350 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-2.pt
2023-06-30 11:07:02,350 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:02,836 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-4.pt
2023-06-30 11:07:02,837 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 154, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(154, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:03,240 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-6.pt
2023-06-30 11:07:03,240 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:03,558 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-8.pt
2023-06-30 11:07:03,558 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:03,610 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-0.pt
2023-06-30 11:07:03,610 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:03,924 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-2.pt
2023-06-30 11:07:03,925 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 410, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(410, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(410, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:04,259 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-4.pt
2023-06-30 11:07:04,259 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 308, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(308, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(308, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:04,550 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-6.pt
2023-06-30 11:07:04,550 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:04,885 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-8.pt
2023-06-30 11:07:04,885 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2023-06-30 11:07:04,942 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-0.pt
2023-06-30 11:07:04,942 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:05,358 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-2.pt
2023-06-30 11:07:05,358 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(410, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(410, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:05,768 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-4.pt
2023-06-30 11:07:05,768 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 308, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(308, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(308, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:06,168 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-6.pt
2023-06-30 11:07:06,168 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:06,544 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-8.pt
2023-06-30 11:07:06,544 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2023-06-30 11:07:08,392 - block_trainer.py[183] - INFO: start block training...
2023-06-30 11:13:58,796 - block_trainer.py[357] - INFO: epoch 0 (410.403184s, 40 blocks still need training), blocks loss: 
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-0 | 0.00020395 | 0.00022303 | 0.00040193 | 0.00127541 | 0.00339697 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-1 | 0.00005459 | 0.00009195 | 0.00061713 | 0.00351896 | 0.00687958 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-2 | 0.00006363 | 0.00037030 | 0.00101725 | 0.00276669 | 0.00776248 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-3 | 0.00007191 | 0.00027695 | 0.00096582 | 0.00217745 | 0.00536666 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-4 | 0.00009782 | 0.00045609 | 0.00126790 | 0.00273804 | 0.00652509 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-5 | 0.00008786 | 0.00009631 | 0.00044277 | 0.00128919 | 0.00319744 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-6 | 0.00004630 | 0.00017064 | 0.00037393 | 0.00078100 | 0.00160100 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-7 | 0.01262817 | 0.02815096 | 0.05138824 | 0.08767248 | 0.16017744 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+

2023-06-30 11:20:48,499 - block_trainer.py[357] - INFO: epoch 1 (409.702943s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020354   |   0.00021423   |   0.00028917   |   0.00060244   |   0.00176050   |
|         | (↓ 0.00000042) | (↓ 0.00000881) | (↓ 0.00011276) | (↓ 0.00067297) | (↓ 0.00163647) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004829   |   0.00007392   |   0.00028006   |   0.00115386   |   0.00314584   |
|         | (↓ 0.00000630) | (↓ 0.00001803) | (↓ 0.00033707) | (↓ 0.00236509) | (↓ 0.00373374) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00006335   |   0.00020757   |   0.00049870   |   0.00118012   |   0.00316082   |
|         | (↓ 0.00000028) | (↓ 0.00016272) | (↓ 0.00051855) | (↓ 0.00158657) | (↓ 0.00460166) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006906   |   0.00018559   |   0.00069087   |   0.00167924   |   0.00387889   |
|         | (↓ 0.00000285) | (↓ 0.00009137) | (↓ 0.00027495) | (↓ 0.00049820) | (↓ 0.00148777) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009706   |   0.00035762   |   0.00081432   |   0.00153735   |   0.00319525   |
|         | (↓ 0.00000076) | (↓ 0.00009847) | (↓ 0.00045358) | (↓ 0.00120070) | (↓ 0.00332984) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008503   |   0.00009256   |   0.00038867   |   0.00108452   |   0.00256194   |
|         | (↓ 0.00000283) | (↓ 0.00000375) | (↓ 0.00005410) | (↓ 0.00020468) | (↓ 0.00063550) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004512   |   0.00015325   |   0.00031453   |   0.00059075   |   0.00107167   |
|         | (↓ 0.00000119) | (↓ 0.00001739) | (↓ 0.00005939) | (↓ 0.00019025) | (↓ 0.00052933) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01219337   |   0.02614096   |   0.04599633   |   0.07437870   |   0.12173701   |
|         | (↓ 0.00043480) | (↓ 0.00201000) | (↓ 0.00539191) | (↓ 0.01329378) | (↓ 0.03844043) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 11:27:38,907 - block_trainer.py[357] - INFO: epoch 2 (410.407986s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020219   |   0.00021208   |   0.00028155   |   0.00054062   |   0.00160038   |
|         | (↓ 0.00000135) | (↓ 0.00000215) | (↓ 0.00000762) | (↓ 0.00006181) | (↓ 0.00016012) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-1 |    0.00004925   |   0.00007330   |   0.00025652   |   0.00098805   |   0.00279600   |
|         | (↓ -0.00000096) | (↓ 0.00000062) | (↓ 0.00002354) | (↓ 0.00016582) | (↓ 0.00034984) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005837   |   0.00019017   |   0.00045902   |   0.00106352   |   0.00272947   |
|         | (↓ 0.00000498) | (↓ 0.00001740) | (↓ 0.00003968) | (↓ 0.00011660) | (↓ 0.00043135) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006531   |   0.00017889   |   0.00065372   |   0.00159452   |   0.00371373   |
|         | (↓ 0.00000375) | (↓ 0.00000670) | (↓ 0.00003714) | (↓ 0.00008472) | (↓ 0.00016515) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009530   |   0.00034522   |   0.00077754   |   0.00144211   |   0.00286493   |
|         | (↓ 0.00000176) | (↓ 0.00001240) | (↓ 0.00003678) | (↓ 0.00009523) | (↓ 0.00033032) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008328   |   0.00009060   |   0.00037901   |   0.00105516   |   0.00247226   |
|         | (↓ 0.00000174) | (↓ 0.00000196) | (↓ 0.00000966) | (↓ 0.00002936) | (↓ 0.00008968) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004389   |   0.00015008   |   0.00030768   |   0.00056888   |   0.00099848   |
|         | (↓ 0.00000122) | (↓ 0.00000317) | (↓ 0.00000685) | (↓ 0.00002187) | (↓ 0.00007319) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01185253   |   0.02546388   |   0.04482179   |   0.07186630   |   0.11499763   |
|         | (↓ 0.00034085) | (↓ 0.00067708) | (↓ 0.00117454) | (↓ 0.00251240) | (↓ 0.00673937) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 11:34:29,327 - block_trainer.py[357] - INFO: epoch 3 (410.419412s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-0 |    0.00020566   |    0.00021458   |    0.00028159   |   0.00051437   |   0.00153721   |
|         | (↓ -0.00000347) | (↓ -0.00000250) | (↓ -0.00000004) | (↓ 0.00002625) | (↓ 0.00006317) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00005124   |    0.00007447   |   0.00024899   |   0.00091228   |   0.00262418   |
|         | (↓ -0.00000199) | (↓ -0.00000117) | (↓ 0.00000753) | (↓ 0.00007576) | (↓ 0.00017182) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-2 |    0.00006297   |   0.00018776   |   0.00044646   |   0.00101890   |   0.00255752   |
|         | (↓ -0.00000460) | (↓ 0.00000241) | (↓ 0.00001255) | (↓ 0.00004463) | (↓ 0.00017195) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-3 |    0.00007037   |    0.00018321   |   0.00065249   |   0.00156769   |   0.00367021   |
|         | (↓ -0.00000506) | (↓ -0.00000432) | (↓ 0.00000123) | (↓ 0.00002683) | (↓ 0.00004352) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00009853   |   0.00034392   |   0.00075869   |   0.00139861   |   0.00269996   |
|         | (↓ -0.00000322) | (↓ 0.00000129) | (↓ 0.00001885) | (↓ 0.00004350) | (↓ 0.00016497) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00008502   |    0.00009214   |   0.00037725   |   0.00104143   |   0.00243356   |
|         | (↓ -0.00000174) | (↓ -0.00000154) | (↓ 0.00000177) | (↓ 0.00001373) | (↓ 0.00003870) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004504   |    0.00015009   |   0.00030493   |   0.00055718   |   0.00096074   |
|         | (↓ -0.00000114) | (↓ -0.00000001) | (↓ 0.00000275) | (↓ 0.00001171) | (↓ 0.00003775) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01147115   |   0.02490107   |   0.04397052   |   0.07041497   |   0.11213840   |
|         | (↓ 0.00038138) | (↓ 0.00056281) | (↓ 0.00085128) | (↓ 0.00145133) | (↓ 0.00285923) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 11:41:24,094 - block_trainer.py[357] - INFO: epoch 4 (414.767137s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019404   |   0.00020278   |   0.00026846   |   0.00048635   |   0.00148962   |
|         | (↓ 0.00001162) | (↓ 0.00001180) | (↓ 0.00001313) | (↓ 0.00002802) | (↓ 0.00004759) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004574   |   0.00006864   |   0.00023913   |   0.00085374   |   0.00252651   |
|         | (↓ 0.00000550) | (↓ 0.00000583) | (↓ 0.00000986) | (↓ 0.00005854) | (↓ 0.00009768) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005891   |   0.00017909   |   0.00043282   |   0.00098790   |   0.00245903   |
|         | (↓ 0.00000406) | (↓ 0.00000868) | (↓ 0.00001365) | (↓ 0.00003099) | (↓ 0.00009849) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00007019   |   0.00018294   |   0.00065085   |   0.00155163   |   0.00365012   |
|         | (↓ 0.00000018) | (↓ 0.00000026) | (↓ 0.00000164) | (↓ 0.00001606) | (↓ 0.00002009) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009621   |   0.00033935   |   0.00074043   |   0.00136794   |   0.00259410   |
|         | (↓ 0.00000232) | (↓ 0.00000458) | (↓ 0.00001826) | (↓ 0.00003068) | (↓ 0.00010586) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008297   |   0.00009001   |   0.00037364   |   0.00102600   |   0.00241207   |
|         | (↓ 0.00000205) | (↓ 0.00000213) | (↓ 0.00000360) | (↓ 0.00001543) | (↓ 0.00002149) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004476   |   0.00014895   |   0.00030096   |   0.00054800   |   0.00093716   |
|         | (↓ 0.00000028) | (↓ 0.00000114) | (↓ 0.00000396) | (↓ 0.00000917) | (↓ 0.00002358) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01128742   |   0.02457232   |   0.04332832   |   0.06940376   |   0.11012659   |
|         | (↓ 0.00018373) | (↓ 0.00032875) | (↓ 0.00064219) | (↓ 0.00101121) | (↓ 0.00201182) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 11:48:14,352 - block_trainer.py[357] - INFO: epoch 5 (410.257729s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-0 |    0.00019744   |    0.00020597   |    0.00027005   |   0.00047696   |   0.00147101   |
|         | (↓ -0.00000340) | (↓ -0.00000319) | (↓ -0.00000159) | (↓ 0.00000939) | (↓ 0.00001861) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004929   |    0.00007175   |    0.00023985   |   0.00082230   |   0.00248037   |
|         | (↓ -0.00000355) | (↓ -0.00000311) | (↓ -0.00000072) | (↓ 0.00003144) | (↓ 0.00004614) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-2 |    0.00006058   |   0.00017655   |   0.00042747   |   0.00097212   |   0.00240080   |
|         | (↓ -0.00000168) | (↓ 0.00000254) | (↓ 0.00000534) | (↓ 0.00001578) | (↓ 0.00005823) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006742   |   0.00017995   |   0.00064777   |   0.00153863   |   0.00363734   |
|         | (↓ 0.00000277) | (↓ 0.00000299) | (↓ 0.00000308) | (↓ 0.00001301) | (↓ 0.00001278) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00009681   |   0.00033786   |   0.00072883   |   0.00134557   |   0.00252257   |
|         | (↓ -0.00000060) | (↓ 0.00000149) | (↓ 0.00001160) | (↓ 0.00002236) | (↓ 0.00007153) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00008305   |    0.00009004   |   0.00037248   |   0.00101420   |   0.00240102   |
|         | (↓ -0.00000008) | (↓ -0.00000003) | (↓ 0.00000116) | (↓ 0.00001179) | (↓ 0.00001106) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004358   |   0.00014705   |   0.00029617   |   0.00054033   |   0.00091991   |
|         | (↓ 0.00000118) | (↓ 0.00000189) | (↓ 0.00000479) | (↓ 0.00000768) | (↓ 0.00001725) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01118784   |   0.02437804   |   0.04288521   |   0.06878125   |   0.10907722   |
|         | (↓ 0.00009958) | (↓ 0.00019428) | (↓ 0.00044312) | (↓ 0.00062252) | (↓ 0.00104937) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 11:55:04,879 - block_trainer.py[357] - INFO: epoch 6 (410.526265s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018211   |   0.00019057   |   0.00025332   |   0.00045296   |   0.00143801   |
|         | (↓ 0.00001533) | (↓ 0.00001540) | (↓ 0.00001673) | (↓ 0.00002400) | (↓ 0.00003300) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004452   |   0.00006685   |   0.00023267   |   0.00079624   |   0.00244721   |
|         | (↓ 0.00000477) | (↓ 0.00000489) | (↓ 0.00000718) | (↓ 0.00002605) | (↓ 0.00003316) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005668   |   0.00016929   |   0.00041890   |   0.00095638   |   0.00235846   |
|         | (↓ 0.00000390) | (↓ 0.00000725) | (↓ 0.00000857) | (↓ 0.00001574) | (↓ 0.00004234) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006518   |   0.00017787   |   0.00064522   |   0.00153093   |   0.00362890   |
|         | (↓ 0.00000224) | (↓ 0.00000209) | (↓ 0.00000255) | (↓ 0.00000770) | (↓ 0.00000844) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009641   |   0.00033596   |   0.00071886   |   0.00132816   |   0.00247361   |
|         | (↓ 0.00000040) | (↓ 0.00000190) | (↓ 0.00000997) | (↓ 0.00001741) | (↓ 0.00004895) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008042   |   0.00008736   |   0.00036842   |   0.00100333   |   0.00239112   |
|         | (↓ 0.00000263) | (↓ 0.00000268) | (↓ 0.00000406) | (↓ 0.00001087) | (↓ 0.00000990) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004323   |   0.00014616   |   0.00029289   |   0.00053516   |   0.00090780   |
|         | (↓ 0.00000036) | (↓ 0.00000089) | (↓ 0.00000328) | (↓ 0.00000517) | (↓ 0.00001210) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01110003   |   0.02421191   |   0.04246846   |   0.06833128   |   0.10827166   |
|         | (↓ 0.00008781) | (↓ 0.00016613) | (↓ 0.00041675) | (↓ 0.00044996) | (↓ 0.00080556) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 12:01:55,371 - block_trainer.py[357] - INFO: epoch 7 (410.491946s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-0 |    0.00019235   |    0.00020115   |    0.00026299   |    0.00045714   |   0.00143541   |
|         | (↓ -0.00001023) | (↓ -0.00001059) | (↓ -0.00000967) | (↓ -0.00000418) | (↓ 0.00000260) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00004572   |    0.00006778   |   0.00023244   |   0.00078177   |   0.00242122   |
|         | (↓ -0.00000121) | (↓ -0.00000093) | (↓ 0.00000022) | (↓ 0.00001447) | (↓ 0.00002599) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-2 |    0.00005892   |   0.00016836   |   0.00041699   |   0.00094947   |   0.00233323   |
|         | (↓ -0.00000223) | (↓ 0.00000094) | (↓ 0.00000192) | (↓ 0.00000690) | (↓ 0.00002523) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-3 |    0.00006873   |    0.00018118   |    0.00064690   |   0.00153077   |   0.00362671   |
|         | (↓ -0.00000355) | (↓ -0.00000332) | (↓ -0.00000168) | (↓ 0.00000015) | (↓ 0.00000220) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009240   |   0.00032992   |   0.00070863   |   0.00131006   |   0.00243661   |
|         | (↓ 0.00000401) | (↓ 0.00000604) | (↓ 0.00001023) | (↓ 0.00001811) | (↓ 0.00003700) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007847   |   0.00008495   |   0.00036497   |   0.00099761   |   0.00238258   |
|         | (↓ 0.00000195) | (↓ 0.00000241) | (↓ 0.00000345) | (↓ 0.00000572) | (↓ 0.00000855) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004231   |   0.00014437   |   0.00028977   |   0.00053106   |   0.00090035   |
|         | (↓ 0.00000092) | (↓ 0.00000180) | (↓ 0.00000311) | (↓ 0.00000409) | (↓ 0.00000745) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01107457   |   0.02414395   |   0.04218347   |   0.06798105   |   0.10757871   |
|         | (↓ 0.00002546) | (↓ 0.00006796) | (↓ 0.00028499) | (↓ 0.00035023) | (↓ 0.00069295) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 12:08:45,760 - block_trainer.py[357] - INFO: epoch 8 (410.389399s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-0 |    0.00019305   |    0.00020199   |   0.00026268   |   0.00045261   |   0.00142730   |
|         | (↓ -0.00000070) | (↓ -0.00000083) | (↓ 0.00000031) | (↓ 0.00000453) | (↓ 0.00000811) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004394   |   0.00006602   |   0.00022913   |   0.00076643   |   0.00239004   |
|         | (↓ 0.00000179) | (↓ 0.00000177) | (↓ 0.00000332) | (↓ 0.00001534) | (↓ 0.00003118) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005391   |   0.00016106   |   0.00040898   |   0.00093671   |   0.00230681   |
|         | (↓ 0.00000501) | (↓ 0.00000730) | (↓ 0.00000800) | (↓ 0.00001277) | (↓ 0.00002643) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006586   |   0.00017829   |   0.00064191   |   0.00152593   |   0.00361900   |
|         | (↓ 0.00000287) | (↓ 0.00000289) | (↓ 0.00000499) | (↓ 0.00000485) | (↓ 0.00000771) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00009291   |   0.00032824   |   0.00070341   |   0.00129868   |   0.00241201   |
|         | (↓ -0.00000051) | (↓ 0.00000168) | (↓ 0.00000522) | (↓ 0.00001138) | (↓ 0.00002461) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007769   |   0.00008417   |   0.00036274   |   0.00099446   |   0.00237839   |
|         | (↓ 0.00000077) | (↓ 0.00000078) | (↓ 0.00000223) | (↓ 0.00000315) | (↓ 0.00000419) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00004245   |   0.00014305   |   0.00028766   |   0.00052709   |   0.00089309   |
|         | (↓ -0.00000014) | (↓ 0.00000132) | (↓ 0.00000211) | (↓ 0.00000398) | (↓ 0.00000726) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01093637   |   0.02392624   |   0.04178617   |   0.06741551   |   0.10684254   |
|         | (↓ 0.00013819) | (↓ 0.00021771) | (↓ 0.00039730) | (↓ 0.00056554) | (↓ 0.00073617) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 12:15:36,028 - block_trainer.py[357] - INFO: epoch 9 (410.267602s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019977   |    0.00020879   |    0.00026882   |    0.00045541   |    0.00142852   |
|         | (↓ -0.00000672) | (↓ -0.00000680) | (↓ -0.00000614) | (↓ -0.00000280) | (↓ -0.00000121) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004518   |    0.00006716   |    0.00022955   |   0.00075339   |   0.00236944   |
|         | (↓ -0.00000125) | (↓ -0.00000114) | (↓ -0.00000042) | (↓ 0.00001304) | (↓ 0.00002060) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005969   |    0.00016454   |    0.00041159   |   0.00093580   |   0.00229517   |
|         | (↓ -0.00000579) | (↓ -0.00000348) | (↓ -0.00000260) | (↓ 0.00000091) | (↓ 0.00001163) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006759   |    0.00017971   |    0.00064200   |    0.00152652   |   0.00361611   |
|         | (↓ -0.00000174) | (↓ -0.00000142) | (↓ -0.00000009) | (↓ -0.00000060) | (↓ 0.00000289) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-4 |    0.00009706   |    0.00032948   |   0.00070200   |   0.00128972   |   0.00239417   |
|         | (↓ -0.00000415) | (↓ -0.00000124) | (↓ 0.00000141) | (↓ 0.00000896) | (↓ 0.00001784) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007670   |   0.00008302   |   0.00036098   |   0.00099138   |   0.00237106   |
|         | (↓ 0.00000099) | (↓ 0.00000115) | (↓ 0.00000176) | (↓ 0.00000308) | (↓ 0.00000733) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004449   |    0.00014399   |   0.00028755   |   0.00052508   |   0.00088879   |
|         | (↓ -0.00000204) | (↓ -0.00000094) | (↓ 0.00000011) | (↓ 0.00000200) | (↓ 0.00000430) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01086106   |   0.02377879   |   0.04146151   |   0.06701160   |   0.10632291   |
|         | (↓ 0.00007531) | (↓ 0.00014745) | (↓ 0.00032466) | (↓ 0.00040391) | (↓ 0.00051962) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 12:22:26,531 - block_trainer.py[357] - INFO: epoch 10 (410.502964s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019336   |   0.00020264   |   0.00026165   |   0.00044505   |   0.00141287   |
|         | (↓ 0.00000641) | (↓ 0.00000615) | (↓ 0.00000717) | (↓ 0.00001036) | (↓ 0.00001565) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004568   |    0.00006746   |    0.00022971   |   0.00073845   |   0.00235758   |
|         | (↓ -0.00000049) | (↓ -0.00000031) | (↓ -0.00000016) | (↓ 0.00001495) | (↓ 0.00001185) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-2 |    0.00006139   |   0.00016438   |   0.00041122   |   0.00093248   |   0.00228470   |
|         | (↓ -0.00000170) | (↓ 0.00000016) | (↓ 0.00000037) | (↓ 0.00000332) | (↓ 0.00001048) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006892   |    0.00018003   |    0.00064234   |    0.00152744   |   0.00361368   |
|         | (↓ -0.00000133) | (↓ -0.00000032) | (↓ -0.00000034) | (↓ -0.00000091) | (↓ 0.00000243) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009553   |   0.00032639   |   0.00069782   |   0.00128058   |   0.00237970   |
|         | (↓ 0.00000154) | (↓ 0.00000309) | (↓ 0.00000418) | (↓ 0.00000914) | (↓ 0.00001446) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00008339   |    0.00008938   |    0.00036480   |    0.00099325   |    0.00237173   |
|         | (↓ -0.00000669) | (↓ -0.00000636) | (↓ -0.00000381) | (↓ -0.00000187) | (↓ -0.00000067) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004298   |   0.00014240   |   0.00028512   |   0.00052154   |   0.00088358   |
|         | (↓ 0.00000151) | (↓ 0.00000159) | (↓ 0.00000243) | (↓ 0.00000355) | (↓ 0.00000521) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01080667   |   0.02372506   |   0.04130471   |   0.06682846   |   0.10599058   |
|         | (↓ 0.00005439) | (↓ 0.00005372) | (↓ 0.00015680) | (↓ 0.00018314) | (↓ 0.00033233) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 12:29:17,250 - block_trainer.py[357] - INFO: epoch 11 (410.718599s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019265   |   0.00020179   |   0.00026037   |   0.00044103   |   0.00140529   |
|         | (↓ 0.00000071) | (↓ 0.00000085) | (↓ 0.00000129) | (↓ 0.00000402) | (↓ 0.00000758) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00004645   |    0.00006812   |   0.00022909   |   0.00072117   |   0.00234713   |
|         | (↓ -0.00000077) | (↓ -0.00000066) | (↓ 0.00000062) | (↓ 0.00001728) | (↓ 0.00001045) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00006020   |   0.00016136   |   0.00040718   |   0.00092594   |   0.00227152   |
|         | (↓ 0.00000119) | (↓ 0.00000302) | (↓ 0.00000404) | (↓ 0.00000654) | (↓ 0.00001317) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006609   |   0.00016349   |   0.00063948   |   0.00152433   |   0.00360697   |
|         | (↓ 0.00000283) | (↓ 0.00001654) | (↓ 0.00000286) | (↓ 0.00000311) | (↓ 0.00000671) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009324   |   0.00032158   |   0.00069234   |   0.00126981   |   0.00236659   |
|         | (↓ 0.00000229) | (↓ 0.00000481) | (↓ 0.00000548) | (↓ 0.00001077) | (↓ 0.00001312) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007815   |   0.00008343   |   0.00036056   |   0.00098913   |   0.00236490   |
|         | (↓ 0.00000525) | (↓ 0.00000596) | (↓ 0.00000424) | (↓ 0.00000412) | (↓ 0.00000683) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004221   |   0.00014072   |   0.00028202   |   0.00051748   |   0.00087917   |
|         | (↓ 0.00000077) | (↓ 0.00000168) | (↓ 0.00000311) | (↓ 0.00000406) | (↓ 0.00000441) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01066530   |   0.02350056   |   0.04094521   |   0.06639080   |   0.10543552   |
|         | (↓ 0.00014137) | (↓ 0.00022451) | (↓ 0.00035950) | (↓ 0.00043766) | (↓ 0.00055506) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 12:36:07,372 - block_trainer.py[357] - INFO: epoch 12 (410.122004s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019608   |    0.00020557   |    0.00026352   |    0.00044245   |    0.00140749   |
|         | (↓ -0.00000343) | (↓ -0.00000378) | (↓ -0.00000315) | (↓ -0.00000143) | (↓ -0.00000221) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004590   |   0.00006769   |   0.00022858   |   0.00070865   |   0.00234193   |
|         | (↓ 0.00000054) | (↓ 0.00000043) | (↓ 0.00000051) | (↓ 0.00001252) | (↓ 0.00000521) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005752   |   0.00015786   |   0.00040322   |   0.00092012   |   0.00226256   |
|         | (↓ 0.00000268) | (↓ 0.00000349) | (↓ 0.00000396) | (↓ 0.00000583) | (↓ 0.00000897) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006567   |   0.00016002   |   0.00063885   |   0.00152374   |   0.00360444   |
|         | (↓ 0.00000042) | (↓ 0.00000347) | (↓ 0.00000063) | (↓ 0.00000058) | (↓ 0.00000253) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-4 |    0.00009629   |    0.00032209   |   0.00069219   |   0.00126502   |   0.00236102   |
|         | (↓ -0.00000306) | (↓ -0.00000051) | (↓ 0.00000015) | (↓ 0.00000479) | (↓ 0.00000557) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+-----------------+-----------------+
|         |       0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007821   |   0.00008319   |    0.00036144   |    0.00099022   |    0.00236495   |
|         | (↓ -0.00000007) | (↓ 0.00000024) | (↓ -0.00000089) | (↓ -0.00000109) | (↓ -0.00000005) |
+---------+-----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-6 |   0.00004200   |    0.00014114   |   0.00028201   |   0.00051664   |   0.00087773   |
|         | (↓ 0.00000021) | (↓ -0.00000042) | (↓ 0.00000001) | (↓ 0.00000084) | (↓ 0.00000144) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-7 |    0.01073250   |    0.02352845   |   0.04088285   |   0.06634951   |   0.10536293   |
|         | (↓ -0.00006720) | (↓ -0.00002789) | (↓ 0.00006236) | (↓ 0.00004129) | (↓ 0.00007259) |
+---------+-----------------+-----------------+----------------+----------------+----------------+

2023-06-30 12:42:57,340 - block_trainer.py[357] - INFO: epoch 13 (409.967561s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020887   |    0.00021917   |    0.00027611   |    0.00045280   |    0.00141411   |
|         | (↓ -0.00001279) | (↓ -0.00001361) | (↓ -0.00001260) | (↓ -0.00001035) | (↓ -0.00000661) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004694   |    0.00006874   |    0.00022903   |   0.00070221   |   0.00233170   |
|         | (↓ -0.00000103) | (↓ -0.00000105) | (↓ -0.00000044) | (↓ 0.00000644) | (↓ 0.00001023) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-2 |    0.00006268   |    0.00016185   |    0.00040581   |    0.00092025   |   0.00226003   |
|         | (↓ -0.00000516) | (↓ -0.00000399) | (↓ -0.00000259) | (↓ -0.00000013) | (↓ 0.00000253) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006986   |    0.00016391   |    0.00064240   |    0.00152696   |   0.00360404   |
|         | (↓ -0.00000419) | (↓ -0.00000389) | (↓ -0.00000355) | (↓ -0.00000322) | (↓ 0.00000040) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00009824   |   0.00032172   |   0.00069142   |   0.00126113   |   0.00235586   |
|         | (↓ -0.00000194) | (↓ 0.00000037) | (↓ 0.00000077) | (↓ 0.00000389) | (↓ 0.00000515) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00007965   |    0.00008446   |    0.00036213   |   0.00098988   |   0.00236306   |
|         | (↓ -0.00000144) | (↓ -0.00000127) | (↓ -0.00000068) | (↓ 0.00000034) | (↓ 0.00000189) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004302   |    0.00014153   |   0.00028136   |   0.00051516   |   0.00087608   |
|         | (↓ -0.00000101) | (↓ -0.00000039) | (↓ 0.00000065) | (↓ 0.00000149) | (↓ 0.00000165) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01071119   |   0.02344719   |   0.04071720   |   0.06611673   |   0.10507095   |
|         | (↓ 0.00002131) | (↓ 0.00008126) | (↓ 0.00016565) | (↓ 0.00023278) | (↓ 0.00029198) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 12:49:47,040 - block_trainer.py[357] - INFO: epoch 14 (409.699738s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020579   |   0.00021548   |   0.00027118   |   0.00044773   |   0.00140630   |
|         | (↓ 0.00000307) | (↓ 0.00000370) | (↓ 0.00000493) | (↓ 0.00000507) | (↓ 0.00000781) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004688   |   0.00006842   |   0.00022839   |   0.00069813   |   0.00232018   |
|         | (↓ 0.00000006) | (↓ 0.00000032) | (↓ 0.00000064) | (↓ 0.00000408) | (↓ 0.00001151) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005810   |   0.00015645   |   0.00039987   |   0.00091291   |   0.00225258   |
|         | (↓ 0.00000458) | (↓ 0.00000540) | (↓ 0.00000594) | (↓ 0.00000734) | (↓ 0.00000744) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006560   |   0.00015967   |   0.00063879   |   0.00152392   |   0.00360213   |
|         | (↓ 0.00000426) | (↓ 0.00000424) | (↓ 0.00000361) | (↓ 0.00000304) | (↓ 0.00000190) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009796   |   0.00031995   |   0.00068909   |   0.00125641   |   0.00235193   |
|         | (↓ 0.00000028) | (↓ 0.00000176) | (↓ 0.00000233) | (↓ 0.00000473) | (↓ 0.00000393) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007768   |   0.00008254   |   0.00036073   |   0.00098726   |   0.00235874   |
|         | (↓ 0.00000197) | (↓ 0.00000192) | (↓ 0.00000140) | (↓ 0.00000262) | (↓ 0.00000433) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004102   |   0.00013999   |   0.00027951   |   0.00051237   |   0.00087292   |
|         | (↓ 0.00000200) | (↓ 0.00000155) | (↓ 0.00000185) | (↓ 0.00000279) | (↓ 0.00000316) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01058726   |   0.02328655   |   0.04049841   |   0.06590486   |   0.10484583   |
|         | (↓ 0.00012394) | (↓ 0.00016064) | (↓ 0.00021879) | (↓ 0.00021187) | (↓ 0.00022512) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 12:56:36,940 - block_trainer.py[357] - INFO: epoch 15 (409.900183s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019155   |   0.00020142   |   0.00025420   |   0.00043061   |   0.00138888   |
|         | (↓ 0.00001425) | (↓ 0.00001406) | (↓ 0.00001698) | (↓ 0.00001712) | (↓ 0.00001742) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004239   |   0.00006405   |   0.00022334   |   0.00069006   |   0.00230439   |
|         | (↓ 0.00000449) | (↓ 0.00000437) | (↓ 0.00000504) | (↓ 0.00000807) | (↓ 0.00001580) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005721   |   0.00015499   |   0.00039776   |   0.00090830   |   0.00224651   |
|         | (↓ 0.00000089) | (↓ 0.00000147) | (↓ 0.00000211) | (↓ 0.00000461) | (↓ 0.00000607) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006746   |    0.00016148   |    0.00064025   |    0.00152522   |   0.00359993   |
|         | (↓ -0.00000185) | (↓ -0.00000181) | (↓ -0.00000145) | (↓ -0.00000130) | (↓ 0.00000220) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009413   |   0.00031435   |   0.00068254   |   0.00124631   |   0.00234192   |
|         | (↓ 0.00000383) | (↓ 0.00000560) | (↓ 0.00000655) | (↓ 0.00001009) | (↓ 0.00001002) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+-----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
| block-5 |    0.00007812   |    0.00008279   |   0.00035971   |    0.00098753   |   0.00235851   |
|         | (↓ -0.00000044) | (↓ -0.00000025) | (↓ 0.00000102) | (↓ -0.00000027) | (↓ 0.00000022) |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004199   |    0.00014016   |   0.00027893   |   0.00051102   |   0.00087197   |
|         | (↓ -0.00000097) | (↓ -0.00000017) | (↓ 0.00000057) | (↓ 0.00000134) | (↓ 0.00000095) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01063517   |   0.02327545   |   0.04045851   |   0.06578202   |   0.10466782   |
|         | (↓ -0.00004792) | (↓ 0.00001110) | (↓ 0.00003991) | (↓ 0.00012284) | (↓ 0.00017801) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-30 13:03:26,821 - block_trainer.py[357] - INFO: epoch 16 (409.881079s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-0 |    0.00019328   |    0.00020343   |   0.00025376   |   0.00042918   |   0.00138657   |
|         | (↓ -0.00000174) | (↓ -0.00000201) | (↓ 0.00000043) | (↓ 0.00000143) | (↓ 0.00000231) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00004902   |    0.00007043   |    0.00022985   |    0.00069482   |   0.00230039   |
|         | (↓ -0.00000663) | (↓ -0.00000638) | (↓ -0.00000650) | (↓ -0.00000476) | (↓ 0.00000400) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-2 |    0.00005755   |    0.00015504   |   0.00039750   |   0.00090558   |   0.00224223   |
|         | (↓ -0.00000034) | (↓ -0.00000005) | (↓ 0.00000025) | (↓ 0.00000272) | (↓ 0.00000429) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006635   |   0.00016029   |   0.00063915   |   0.00152389   |   0.00359790   |
|         | (↓ 0.00000111) | (↓ 0.00000119) | (↓ 0.00000110) | (↓ 0.00000133) | (↓ 0.00000203) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009187   |   0.00031118   |   0.00067855   |   0.00123974   |   0.00233571   |
|         | (↓ 0.00000226) | (↓ 0.00000317) | (↓ 0.00000399) | (↓ 0.00000657) | (↓ 0.00000621) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007793   |   0.00008259   |   0.00035952   |   0.00098652   |   0.00235545   |
|         | (↓ 0.00000019) | (↓ 0.00000020) | (↓ 0.00000019) | (↓ 0.00000101) | (↓ 0.00000306) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004074   |   0.00013857   |   0.00027737   |   0.00050870   |   0.00086985   |
|         | (↓ 0.00000125) | (↓ 0.00000159) | (↓ 0.00000156) | (↓ 0.00000232) | (↓ 0.00000212) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01058151   |   0.02315229   |   0.04028705   |   0.06547451   |   0.10423749   |
|         | (↓ 0.00005367) | (↓ 0.00012316) | (↓ 0.00017146) | (↓ 0.00030751) | (↓ 0.00043033) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 13:10:16,729 - block_trainer.py[357] - INFO: epoch 17 (409.907606s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019855   |    0.00020830   |    0.00025724   |    0.00043190   |    0.00138747   |
|         | (↓ -0.00000526) | (↓ -0.00000487) | (↓ -0.00000347) | (↓ -0.00000272) | (↓ -0.00000090) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004648   |   0.00006795   |   0.00022578   |   0.00068933   |   0.00228369   |
|         | (↓ 0.00000254) | (↓ 0.00000248) | (↓ 0.00000406) | (↓ 0.00000549) | (↓ 0.00001670) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00006346   |    0.00016007   |    0.00040180   |    0.00090754   |    0.00224467   |
|         | (↓ -0.00000591) | (↓ -0.00000503) | (↓ -0.00000430) | (↓ -0.00000195) | (↓ -0.00000244) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006494   |   0.00015876   |   0.00063763   |   0.00152211   |   0.00359405   |
|         | (↓ 0.00000141) | (↓ 0.00000153) | (↓ 0.00000151) | (↓ 0.00000178) | (↓ 0.00000385) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00009388   |    0.00031244   |    0.00067988   |   0.00123941   |   0.00233527   |
|         | (↓ -0.00000202) | (↓ -0.00000126) | (↓ -0.00000134) | (↓ 0.00000034) | (↓ 0.00000044) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00007823   |    0.00008297   |    0.00036032   |   0.00098638   |   0.00235327   |
|         | (↓ -0.00000030) | (↓ -0.00000038) | (↓ -0.00000080) | (↓ 0.00000013) | (↓ 0.00000218) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004111   |    0.00013859   |   0.00027718   |   0.00050802   |   0.00086846   |
|         | (↓ -0.00000037) | (↓ -0.00000002) | (↓ 0.00000019) | (↓ 0.00000069) | (↓ 0.00000139) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+-----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+-----------------+----------------+----------------+----------------+-----------------+
| block-7 |    0.01062709   |   0.02315019   |   0.04025155   |   0.06540376   |    0.10425752   |
|         | (↓ -0.00004559) | (↓ 0.00000210) | (↓ 0.00003550) | (↓ 0.00007074) | (↓ -0.00002003) |
+---------+-----------------+----------------+----------------+----------------+-----------------+

2023-06-30 13:17:06,590 - block_trainer.py[357] - INFO: epoch 18 (409.860764s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019259   |   0.00020256   |   0.00025070   |   0.00042454   |   0.00137723   |
|         | (↓ 0.00000595) | (↓ 0.00000574) | (↓ 0.00000654) | (↓ 0.00000736) | (↓ 0.00001024) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004673   |    0.00006800   |    0.00022658   |   0.00068894   |   0.00227535   |
|         | (↓ -0.00000026) | (↓ -0.00000005) | (↓ -0.00000080) | (↓ 0.00000039) | (↓ 0.00000834) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005881   |   0.00015540   |   0.00039714   |   0.00090042   |   0.00223578   |
|         | (↓ 0.00000465) | (↓ 0.00000468) | (↓ 0.00000466) | (↓ 0.00000712) | (↓ 0.00000889) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006381   |   0.00015753   |   0.00063609   |   0.00152068   |   0.00359276   |
|         | (↓ 0.00000113) | (↓ 0.00000123) | (↓ 0.00000154) | (↓ 0.00000143) | (↓ 0.00000129) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009372   |   0.00031125   |   0.00067719   |   0.00123362   |   0.00233006   |
|         | (↓ 0.00000017) | (↓ 0.00000119) | (↓ 0.00000269) | (↓ 0.00000578) | (↓ 0.00000521) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007616   |   0.00008090   |   0.00035811   |   0.00098410   |   0.00234951   |
|         | (↓ 0.00000207) | (↓ 0.00000208) | (↓ 0.00000221) | (↓ 0.00000228) | (↓ 0.00000376) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004100   |   0.00013826   |   0.00027691   |   0.00050680   |   0.00086718   |
|         | (↓ 0.00000011) | (↓ 0.00000032) | (↓ 0.00000028) | (↓ 0.00000121) | (↓ 0.00000128) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01047001   |   0.02292586   |   0.04000179   |   0.06509849   |   0.10382054   |
|         | (↓ 0.00015709) | (↓ 0.00022433) | (↓ 0.00024976) | (↓ 0.00030527) | (↓ 0.00043698) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 13:23:56,524 - block_trainer.py[357] - INFO: epoch 19 (409.933711s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018185   |   0.00019136   |   0.00023886   |   0.00041176   |   0.00136245   |
|         | (↓ 0.00001075) | (↓ 0.00001120) | (↓ 0.00001184) | (↓ 0.00001278) | (↓ 0.00001478) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004191   |   0.00006310   |   0.00022134   |   0.00068257   |   0.00226206   |
|         | (↓ 0.00000483) | (↓ 0.00000489) | (↓ 0.00000524) | (↓ 0.00000638) | (↓ 0.00001329) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005832   |   0.00015498   |   0.00039685   |   0.00089781   |   0.00223448   |
|         | (↓ 0.00000049) | (↓ 0.00000042) | (↓ 0.00000029) | (↓ 0.00000261) | (↓ 0.00000130) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-3 |   0.00006311   |   0.00015706   |    0.00063632   |    0.00152139   |    0.00359410   |
|         | (↓ 0.00000070) | (↓ 0.00000046) | (↓ -0.00000023) | (↓ -0.00000071) | (↓ -0.00000134) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009224   |   0.00030892   |   0.00067506   |   0.00123033   |   0.00232795   |
|         | (↓ 0.00000148) | (↓ 0.00000233) | (↓ 0.00000214) | (↓ 0.00000330) | (↓ 0.00000210) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007410   |   0.00007882   |   0.00035643   |   0.00098213   |   0.00234629   |
|         | (↓ 0.00000207) | (↓ 0.00000207) | (↓ 0.00000168) | (↓ 0.00000197) | (↓ 0.00000322) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+-----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+-----------------+----------------+----------------+----------------+-----------------+
| block-6 |    0.00004105   |   0.00013816   |   0.00027632   |   0.00050599   |    0.00086737   |
|         | (↓ -0.00000005) | (↓ 0.00000010) | (↓ 0.00000059) | (↓ 0.00000081) | (↓ -0.00000019) |
+---------+-----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01046414   |   0.02288391   |   0.03996552   |   0.06502825   |   0.10372717   |
|         | (↓ 0.00000586) | (↓ 0.00004195) | (↓ 0.00003627) | (↓ 0.00007024) | (↓ 0.00009337) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 13:30:46,448 - block_trainer.py[357] - INFO: epoch 20 (409.923418s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019629   |    0.00020627   |    0.00025360   |    0.00042610   |    0.00137422   |
|         | (↓ -0.00001445) | (↓ -0.00001491) | (↓ -0.00001474) | (↓ -0.00001434) | (↓ -0.00001177) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00004435   |    0.00006583   |    0.00022377   |    0.00068304   |   0.00225657   |
|         | (↓ -0.00000244) | (↓ -0.00000272) | (↓ -0.00000244) | (↓ -0.00000047) | (↓ 0.00000549) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-2 |    0.00006077   |    0.00015707   |    0.00039870   |    0.00089825   |   0.00223446   |
|         | (↓ -0.00000245) | (↓ -0.00000209) | (↓ -0.00000185) | (↓ -0.00000044) | (↓ 0.00000002) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006702   |    0.00016095   |    0.00063988   |    0.00152490   |    0.00359718   |
|         | (↓ -0.00000391) | (↓ -0.00000388) | (↓ -0.00000356) | (↓ -0.00000351) | (↓ -0.00000308) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009222   |   0.00030854   |   0.00067427   |   0.00122812   |   0.00232542   |
|         | (↓ 0.00000002) | (↓ 0.00000038) | (↓ 0.00000079) | (↓ 0.00000220) | (↓ 0.00000254) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00008208   |    0.00008679   |    0.00036212   |    0.00098894   |    0.00235333   |
|         | (↓ -0.00000798) | (↓ -0.00000796) | (↓ -0.00000568) | (↓ -0.00000681) | (↓ -0.00000703) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004036   |   0.00013744   |   0.00027585   |   0.00050500   |   0.00086593   |
|         | (↓ 0.00000069) | (↓ 0.00000072) | (↓ 0.00000047) | (↓ 0.00000099) | (↓ 0.00000144) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-7 |    0.01050461   |    0.02290459   |   0.03994033   |   0.06501235   |   0.10371783   |
|         | (↓ -0.00004047) | (↓ -0.00002068) | (↓ 0.00002519) | (↓ 0.00001591) | (↓ 0.00000934) |
+---------+-----------------+-----------------+----------------+----------------+----------------+

2023-06-30 13:37:36,080 - block_trainer.py[357] - INFO: epoch 21 (409.631809s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-0 |    0.00019916   |    0.00020946   |    0.00025615   |    0.00042806   |   0.00137265   |
|         | (↓ -0.00000287) | (↓ -0.00000319) | (↓ -0.00000255) | (↓ -0.00000196) | (↓ 0.00000156) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004583   |    0.00006732   |    0.00022490   |   0.00068275   |   0.00225317   |
|         | (↓ -0.00000148) | (↓ -0.00000149) | (↓ -0.00000112) | (↓ 0.00000028) | (↓ 0.00000340) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005940   |   0.00015558   |   0.00039701   |   0.00089451   |   0.00223034   |
|         | (↓ 0.00000137) | (↓ 0.00000150) | (↓ 0.00000170) | (↓ 0.00000374) | (↓ 0.00000412) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006425   |   0.00015790   |   0.00063636   |   0.00152106   |   0.00359085   |
|         | (↓ 0.00000277) | (↓ 0.00000305) | (↓ 0.00000352) | (↓ 0.00000384) | (↓ 0.00000633) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00009430   |    0.00030983   |    0.00067439   |   0.00122653   |   0.00232444   |
|         | (↓ -0.00000208) | (↓ -0.00000129) | (↓ -0.00000012) | (↓ 0.00000159) | (↓ 0.00000097) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007680   |   0.00008169   |   0.00035855   |   0.00098391   |   0.00234695   |
|         | (↓ 0.00000528) | (↓ 0.00000510) | (↓ 0.00000357) | (↓ 0.00000503) | (↓ 0.00000637) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-6 |    0.00004114   |    0.00013830   |    0.00027613   |   0.00050471   |   0.00086571   |
|         | (↓ -0.00000078) | (↓ -0.00000086) | (↓ -0.00000028) | (↓ 0.00000030) | (↓ 0.00000021) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01040213   |   0.02273304   |   0.03973953   |   0.06468102   |   0.10328162   |
|         | (↓ 0.00010248) | (↓ 0.00017154) | (↓ 0.00020080) | (↓ 0.00033133) | (↓ 0.00043621) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 13:44:25,881 - block_trainer.py[357] - INFO: epoch 22 (409.800987s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019891   |   0.00020891   |   0.00025548   |   0.00042667   |   0.00136921   |
|         | (↓ 0.00000025) | (↓ 0.00000055) | (↓ 0.00000068) | (↓ 0.00000139) | (↓ 0.00000345) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004367   |   0.00006500   |   0.00022210   |   0.00067754   |   0.00224822   |
|         | (↓ 0.00000216) | (↓ 0.00000232) | (↓ 0.00000280) | (↓ 0.00000521) | (↓ 0.00000495) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+----------------+----------------+
| block-2 |    0.00005945   |   0.00015546   |    0.00039702   |   0.00089336   |   0.00222823   |
|         | (↓ -0.00000005) | (↓ 0.00000012) | (↓ -0.00000002) | (↓ 0.00000115) | (↓ 0.00000211) |
+---------+-----------------+----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006852   |    0.00016225   |    0.00064055   |    0.00152462   |    0.00359418   |
|         | (↓ -0.00000427) | (↓ -0.00000436) | (↓ -0.00000419) | (↓ -0.00000356) | (↓ -0.00000333) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-4 |    0.00009664   |    0.00031179   |    0.00067542   |   0.00122640   |    0.00232493   |
|         | (↓ -0.00000234) | (↓ -0.00000196) | (↓ -0.00000103) | (↓ 0.00000013) | (↓ -0.00000049) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007377   |   0.00007854   |   0.00035482   |   0.00098096   |   0.00234179   |
|         | (↓ 0.00000304) | (↓ 0.00000315) | (↓ 0.00000372) | (↓ 0.00000295) | (↓ 0.00000516) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004233   |    0.00013891   |   0.00027612   |   0.00050406   |   0.00086551   |
|         | (↓ -0.00000118) | (↓ -0.00000062) | (↓ 0.00000002) | (↓ 0.00000065) | (↓ 0.00000021) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01041490   |   0.02270480   |   0.03970118   |   0.06457752   |   0.10319145   |
|         | (↓ -0.00001276) | (↓ 0.00002825) | (↓ 0.00003835) | (↓ 0.00010350) | (↓ 0.00009018) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-30 13:51:15,910 - block_trainer.py[357] - INFO: epoch 23 (410.029155s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018262   |   0.00019227   |   0.00023840   |   0.00040889   |   0.00134626   |
|         | (↓ 0.00001629) | (↓ 0.00001664) | (↓ 0.00001708) | (↓ 0.00001777) | (↓ 0.00002294) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004431   |    0.00006568   |    0.00022216   |   0.00067402   |   0.00224483   |
|         | (↓ -0.00000065) | (↓ -0.00000068) | (↓ -0.00000006) | (↓ 0.00000352) | (↓ 0.00000339) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005821   |   0.00015389   |   0.00039484   |   0.00088900   |   0.00222312   |
|         | (↓ 0.00000124) | (↓ 0.00000157) | (↓ 0.00000218) | (↓ 0.00000436) | (↓ 0.00000512) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006524   |   0.00015906   |   0.00063783   |   0.00152250   |   0.00359199   |
|         | (↓ 0.00000328) | (↓ 0.00000319) | (↓ 0.00000271) | (↓ 0.00000212) | (↓ 0.00000219) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008954   |   0.00030514   |   0.00066841   |   0.00121778   |   0.00231635   |
|         | (↓ 0.00000710) | (↓ 0.00000666) | (↓ 0.00000701) | (↓ 0.00000862) | (↓ 0.00000858) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007434   |    0.00007907   |    0.00035521   |    0.00098138   |   0.00233975   |
|         | (↓ -0.00000057) | (↓ -0.00000053) | (↓ -0.00000039) | (↓ -0.00000042) | (↓ 0.00000205) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003972   |   0.00013669   |   0.00027401   |   0.00050225   |   0.00086282   |
|         | (↓ 0.00000261) | (↓ 0.00000223) | (↓ 0.00000211) | (↓ 0.00000181) | (↓ 0.00000268) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01038296   |   0.02261543   |   0.03953054   |   0.06437354   |   0.10288476   |
|         | (↓ 0.00003194) | (↓ 0.00008936) | (↓ 0.00017064) | (↓ 0.00020397) | (↓ 0.00030669) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 13:58:06,151 - block_trainer.py[357] - INFO: epoch 24 (410.241060s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-0 |    0.00018588   |    0.00019528   |    0.00024094   |    0.00041084   |   0.00134572   |
|         | (↓ -0.00000326) | (↓ -0.00000300) | (↓ -0.00000254) | (↓ -0.00000194) | (↓ 0.00000055) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004257   |   0.00006400   |   0.00022068   |   0.00066939   |   0.00224407   |
|         | (↓ 0.00000175) | (↓ 0.00000168) | (↓ 0.00000148) | (↓ 0.00000464) | (↓ 0.00000076) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00006159   |    0.00015702   |    0.00039779   |    0.00089078   |    0.00222348   |
|         | (↓ -0.00000338) | (↓ -0.00000314) | (↓ -0.00000294) | (↓ -0.00000178) | (↓ -0.00000037) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006299   |   0.00015661   |   0.00063511   |   0.00151905   |   0.00358586   |
|         | (↓ 0.00000225) | (↓ 0.00000245) | (↓ 0.00000272) | (↓ 0.00000345) | (↓ 0.00000613) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-4 |    0.00009046   |    0.00030582   |   0.00066792   |   0.00121692   |   0.00231579   |
|         | (↓ -0.00000091) | (↓ -0.00000068) | (↓ 0.00000049) | (↓ 0.00000086) | (↓ 0.00000056) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00007495   |    0.00007969   |    0.00035532   |   0.00098031   |   0.00233828   |
|         | (↓ -0.00000061) | (↓ -0.00000063) | (↓ -0.00000011) | (↓ 0.00000106) | (↓ 0.00000147) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003921   |   0.00013593   |   0.00027291   |   0.00050094   |   0.00086234   |
|         | (↓ 0.00000051) | (↓ 0.00000075) | (↓ 0.00000110) | (↓ 0.00000131) | (↓ 0.00000049) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01033495   |   0.02258161   |   0.03952370   |   0.06435773   |   0.10285787   |
|         | (↓ 0.00004801) | (↓ 0.00003383) | (↓ 0.00000685) | (↓ 0.00001581) | (↓ 0.00002689) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 14:04:56,394 - block_trainer.py[357] - INFO: epoch 25 (410.242913s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019929   |    0.00020950   |    0.00025525   |    0.00042521   |    0.00135621   |
|         | (↓ -0.00001341) | (↓ -0.00001423) | (↓ -0.00001431) | (↓ -0.00001438) | (↓ -0.00001049) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004410   |    0.00006545   |    0.00022151   |   0.00066678   |   0.00224388   |
|         | (↓ -0.00000154) | (↓ -0.00000145) | (↓ -0.00000083) | (↓ 0.00000261) | (↓ 0.00000019) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005742   |   0.00015298   |   0.00039355   |   0.00088528   |   0.00221886   |
|         | (↓ 0.00000417) | (↓ 0.00000404) | (↓ 0.00000423) | (↓ 0.00000550) | (↓ 0.00000462) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006743   |    0.00016097   |    0.00063946   |    0.00152338   |    0.00359072   |
|         | (↓ -0.00000444) | (↓ -0.00000436) | (↓ -0.00000435) | (↓ -0.00000432) | (↓ -0.00000486) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-4 |    0.00009281   |    0.00030776   |    0.00066831   |   0.00121691   |    0.00231588   |
|         | (↓ -0.00000236) | (↓ -0.00000195) | (↓ -0.00000039) | (↓ 0.00000000) | (↓ -0.00000009) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007611   |    0.00008073   |    0.00035599   |    0.00098083   |   0.00233632   |
|         | (↓ -0.00000116) | (↓ -0.00000103) | (↓ -0.00000066) | (↓ -0.00000052) | (↓ 0.00000196) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-6 |    0.00003921   |    0.00013619   |    0.00027302   |   0.00050034   |   0.00086141   |
|         | (↓ -0.00000000) | (↓ -0.00000026) | (↓ -0.00000011) | (↓ 0.00000059) | (↓ 0.00000093) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01034928   |   0.02253603   |   0.03950718   |   0.06427674   |   0.10283621   |
|         | (↓ -0.00001433) | (↓ 0.00004557) | (↓ 0.00001652) | (↓ 0.00008100) | (↓ 0.00002165) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-30 14:11:46,596 - block_trainer.py[357] - INFO: epoch 26 (410.201249s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018657   |   0.00019644   |   0.00024191   |   0.00041127   |   0.00134029   |
|         | (↓ 0.00001272) | (↓ 0.00001307) | (↓ 0.00001334) | (↓ 0.00001394) | (↓ 0.00001592) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004441   |    0.00006564   |    0.00022177   |   0.00066507   |   0.00224385   |
|         | (↓ -0.00000031) | (↓ -0.00000019) | (↓ -0.00000026) | (↓ 0.00000171) | (↓ 0.00000003) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005602   |   0.00015172   |   0.00039283   |   0.00088391   |   0.00221733   |
|         | (↓ 0.00000140) | (↓ 0.00000126) | (↓ 0.00000072) | (↓ 0.00000137) | (↓ 0.00000153) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006346   |   0.00015713   |   0.00063577   |   0.00152042   |   0.00358793   |
|         | (↓ 0.00000397) | (↓ 0.00000385) | (↓ 0.00000369) | (↓ 0.00000295) | (↓ 0.00000279) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009075   |   0.00030576   |   0.00066593   |   0.00121461   |   0.00231487   |
|         | (↓ 0.00000206) | (↓ 0.00000201) | (↓ 0.00000238) | (↓ 0.00000230) | (↓ 0.00000101) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-5 |   0.00007544   |   0.00008024   |    0.00035604   |    0.00098200   |    0.00233651   |
|         | (↓ 0.00000067) | (↓ 0.00000049) | (↓ -0.00000005) | (↓ -0.00000116) | (↓ -0.00000019) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+-----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+----------------+----------------+-----------------+
| block-6 |    0.00004001   |    0.00013665   |   0.00027295   |   0.00050031   |    0.00086145   |
|         | (↓ -0.00000080) | (↓ -0.00000046) | (↓ 0.00000007) | (↓ 0.00000003) | (↓ -0.00000004) |
+---------+-----------------+-----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01033964   |   0.02249179   |   0.03941870   |   0.06417201   |   0.10271386   |
|         | (↓ 0.00000964) | (↓ 0.00004425) | (↓ 0.00008848) | (↓ 0.00010473) | (↓ 0.00012236) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 14:18:36,980 - block_trainer.py[357] - INFO: epoch 27 (410.384322s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00018858   |    0.00019882   |    0.00024452   |    0.00041361   |    0.00134148   |
|         | (↓ -0.00000201) | (↓ -0.00000238) | (↓ -0.00000261) | (↓ -0.00000234) | (↓ -0.00000119) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004282   |   0.00006400   |   0.00021976   |   0.00066213   |   0.00224209   |
|         | (↓ 0.00000160) | (↓ 0.00000164) | (↓ 0.00000200) | (↓ 0.00000295) | (↓ 0.00000176) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005680   |    0.00015249   |    0.00039338   |   0.00088330   |   0.00221675   |
|         | (↓ -0.00000078) | (↓ -0.00000076) | (↓ -0.00000055) | (↓ 0.00000061) | (↓ 0.00000058) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006181   |   0.00015557   |   0.00063399   |   0.00151806   |   0.00358567   |
|         | (↓ 0.00000165) | (↓ 0.00000156) | (↓ 0.00000177) | (↓ 0.00000237) | (↓ 0.00000226) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008901   |   0.00030382   |   0.00066236   |   0.00120939   |   0.00230889   |
|         | (↓ 0.00000174) | (↓ 0.00000194) | (↓ 0.00000357) | (↓ 0.00000522) | (↓ 0.00000598) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007395   |   0.00007871   |   0.00035422   |   0.00097999   |   0.00233355   |
|         | (↓ 0.00000149) | (↓ 0.00000152) | (↓ 0.00000182) | (↓ 0.00000201) | (↓ 0.00000296) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003901   |   0.00013567   |   0.00027195   |   0.00049910   |   0.00086016   |
|         | (↓ 0.00000100) | (↓ 0.00000098) | (↓ 0.00000100) | (↓ 0.00000121) | (↓ 0.00000129) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01025557   |   0.02238704   |   0.03927664   |   0.06400182   |   0.10252359   |
|         | (↓ 0.00008406) | (↓ 0.00010475) | (↓ 0.00014206) | (↓ 0.00017018) | (↓ 0.00019027) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 14:25:27,086 - block_trainer.py[357] - INFO: epoch 28 (410.105094s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019780   |    0.00020837   |    0.00025386   |    0.00042260   |    0.00134770   |
|         | (↓ -0.00000922) | (↓ -0.00000956) | (↓ -0.00000935) | (↓ -0.00000899) | (↓ -0.00000622) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00004357   |    0.00006495   |    0.00022102   |    0.00066236   |    0.00224292   |
|         | (↓ -0.00000075) | (↓ -0.00000095) | (↓ -0.00000125) | (↓ -0.00000023) | (↓ -0.00000082) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005851   |    0.00015415   |    0.00039494   |   0.00088287   |   0.00221569   |
|         | (↓ -0.00000170) | (↓ -0.00000166) | (↓ -0.00000156) | (↓ 0.00000043) | (↓ 0.00000106) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006412   |    0.00015808   |    0.00063675   |    0.00152091   |    0.00358731   |
|         | (↓ -0.00000231) | (↓ -0.00000251) | (↓ -0.00000276) | (↓ -0.00000285) | (↓ -0.00000165) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009206   |    0.00030754   |    0.00066546   |    0.00121281   |    0.00231250   |
|         | (↓ -0.00000305) | (↓ -0.00000373) | (↓ -0.00000310) | (↓ -0.00000342) | (↓ -0.00000361) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007469   |    0.00007945   |    0.00035493   |    0.00098076   |   0.00233158   |
|         | (↓ -0.00000074) | (↓ -0.00000073) | (↓ -0.00000071) | (↓ -0.00000077) | (↓ 0.00000197) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |   0.00003890   |    0.00013589   |    0.00027202   |    0.00049912   |    0.00086047   |
|         | (↓ 0.00000011) | (↓ -0.00000022) | (↓ -0.00000007) | (↓ -0.00000002) | (↓ -0.00000031) |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01022556   |   0.02230964   |   0.03922910   |   0.06392464   |   0.10245962   |
|         | (↓ 0.00003002) | (↓ 0.00007740) | (↓ 0.00004754) | (↓ 0.00007718) | (↓ 0.00006396) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 14:32:16,905 - block_trainer.py[357] - INFO: epoch 29 (409.819095s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018818   |   0.00019801   |   0.00024316   |   0.00041180   |   0.00133468   |
|         | (↓ 0.00000962) | (↓ 0.00001037) | (↓ 0.00001070) | (↓ 0.00001080) | (↓ 0.00001301) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-1 |   0.00004337   |   0.00006484   |   0.00022064   |    0.00066275   |    0.00224317   |
|         | (↓ 0.00000019) | (↓ 0.00000010) | (↓ 0.00000038) | (↓ -0.00000039) | (↓ -0.00000025) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005747   |   0.00015294   |   0.00039314   |   0.00087964   |   0.00221266   |
|         | (↓ 0.00000103) | (↓ 0.00000121) | (↓ 0.00000180) | (↓ 0.00000323) | (↓ 0.00000303) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006430   |    0.00015827   |    0.00063681   |    0.00152143   |   0.00358729   |
|         | (↓ -0.00000018) | (↓ -0.00000019) | (↓ -0.00000006) | (↓ -0.00000052) | (↓ 0.00000002) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008806   |   0.00030268   |   0.00065963   |   0.00120613   |   0.00230642   |
|         | (↓ 0.00000401) | (↓ 0.00000486) | (↓ 0.00000583) | (↓ 0.00000669) | (↓ 0.00000608) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007621   |    0.00008098   |    0.00035629   |    0.00098241   |    0.00233215   |
|         | (↓ -0.00000152) | (↓ -0.00000153) | (↓ -0.00000136) | (↓ -0.00000165) | (↓ -0.00000057) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00003908   |   0.00013571   |   0.00027147   |   0.00049817   |   0.00085909   |
|         | (↓ -0.00000019) | (↓ 0.00000018) | (↓ 0.00000056) | (↓ 0.00000096) | (↓ 0.00000138) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.01036535   |    0.02241616   |    0.03932795   |    0.06394821   |   0.10245540   |
|         | (↓ -0.00013979) | (↓ -0.00010652) | (↓ -0.00009885) | (↓ -0.00002357) | (↓ 0.00000422) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2023-06-30 14:39:06,909 - block_trainer.py[357] - INFO: epoch 30 (410.003513s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019940   |    0.00020952   |    0.00025475   |    0.00042310   |    0.00134369   |
|         | (↓ -0.00001122) | (↓ -0.00001151) | (↓ -0.00001159) | (↓ -0.00001130) | (↓ -0.00000901) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00004700   |    0.00006821   |    0.00022293   |    0.00066368   |    0.00224388   |
|         | (↓ -0.00000362) | (↓ -0.00000337) | (↓ -0.00000229) | (↓ -0.00000092) | (↓ -0.00000071) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00006198   |    0.00015725   |    0.00039745   |    0.00088229   |    0.00221521   |
|         | (↓ -0.00000451) | (↓ -0.00000432) | (↓ -0.00000431) | (↓ -0.00000265) | (↓ -0.00000255) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-3 |    0.00006474   |    0.00015856   |    0.00063714   |   0.00152128   |    0.00358759   |
|         | (↓ -0.00000044) | (↓ -0.00000030) | (↓ -0.00000034) | (↓ 0.00000015) | (↓ -0.00000030) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009126   |    0.00030595   |    0.00066158   |    0.00120697   |    0.00230712   |
|         | (↓ -0.00000320) | (↓ -0.00000326) | (↓ -0.00000196) | (↓ -0.00000084) | (↓ -0.00000070) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007398   |   0.00007881   |   0.00035400   |   0.00097938   |   0.00232780   |
|         | (↓ 0.00000223) | (↓ 0.00000217) | (↓ 0.00000229) | (↓ 0.00000303) | (↓ 0.00000435) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-6 |    0.00003917   |    0.00013580   |    0.00027153   |   0.00049760   |   0.00085898   |
|         | (↓ -0.00000009) | (↓ -0.00000010) | (↓ -0.00000006) | (↓ 0.00000057) | (↓ 0.00000011) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01022126   |   0.02225780   |   0.03914161   |   0.06372084   |   0.10222038   |
|         | (↓ 0.00014408) | (↓ 0.00015836) | (↓ 0.00018634) | (↓ 0.00022737) | (↓ 0.00023502) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 14:45:56,831 - block_trainer.py[357] - INFO: epoch 31 (409.921811s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020289   |    0.00021355   |    0.00025859   |    0.00042723   |    0.00134679   |
|         | (↓ -0.00000349) | (↓ -0.00000403) | (↓ -0.00000384) | (↓ -0.00000413) | (↓ -0.00000310) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-1 |   0.00004475   |   0.00006609   |   0.00022274   |   0.00066335   |    0.00224447   |
|         | (↓ 0.00000224) | (↓ 0.00000212) | (↓ 0.00000019) | (↓ 0.00000032) | (↓ -0.00000059) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00006046   |   0.00015578   |   0.00039587   |   0.00087856   |   0.00221187   |
|         | (↓ 0.00000152) | (↓ 0.00000147) | (↓ 0.00000158) | (↓ 0.00000373) | (↓ 0.00000334) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-3 |    0.00006541   |    0.00015917   |    0.00063770   |   0.00152121   |   0.00358572   |
|         | (↓ -0.00000067) | (↓ -0.00000060) | (↓ -0.00000055) | (↓ 0.00000007) | (↓ 0.00000187) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00009278   |    0.00030713   |    0.00066171   |   0.00120694   |   0.00230614   |
|         | (↓ -0.00000152) | (↓ -0.00000118) | (↓ -0.00000012) | (↓ 0.00000003) | (↓ 0.00000098) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007825   |    0.00008304   |    0.00035795   |    0.00098349   |    0.00232903   |
|         | (↓ -0.00000427) | (↓ -0.00000423) | (↓ -0.00000395) | (↓ -0.00000411) | (↓ -0.00000123) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-6 |    0.00004041   |    0.00013653   |    0.00027162   |   0.00049732   |   0.00085860   |
|         | (↓ -0.00000124) | (↓ -0.00000073) | (↓ -0.00000009) | (↓ 0.00000028) | (↓ 0.00000038) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.01027516   |    0.02227428   |    0.03915091   |    0.06373429   |   0.10216361   |
|         | (↓ -0.00005390) | (↓ -0.00001648) | (↓ -0.00000930) | (↓ -0.00001345) | (↓ 0.00005677) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2023-06-30 14:52:47,201 - block_trainer.py[357] - INFO: epoch 32 (410.369996s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018423   |   0.00019418   |   0.00023934   |   0.00040709   |   0.00132547   |
|         | (↓ 0.00001865) | (↓ 0.00001937) | (↓ 0.00001925) | (↓ 0.00002015) | (↓ 0.00002132) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004409   |   0.00006537   |   0.00022047   |   0.00066137   |   0.00224178   |
|         | (↓ 0.00000066) | (↓ 0.00000072) | (↓ 0.00000227) | (↓ 0.00000198) | (↓ 0.00000269) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005894   |   0.00015428   |   0.00039437   |   0.00087570   |   0.00220989   |
|         | (↓ 0.00000152) | (↓ 0.00000150) | (↓ 0.00000150) | (↓ 0.00000285) | (↓ 0.00000197) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006729   |    0.00016095   |    0.00063951   |    0.00152318   |    0.00358741   |
|         | (↓ -0.00000188) | (↓ -0.00000178) | (↓ -0.00000181) | (↓ -0.00000197) | (↓ -0.00000169) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008831   |   0.00030289   |   0.00065743   |   0.00120210   |   0.00230278   |
|         | (↓ 0.00000447) | (↓ 0.00000424) | (↓ 0.00000428) | (↓ 0.00000483) | (↓ 0.00000336) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007459   |   0.00007936   |   0.00035421   |   0.00098002   |   0.00232556   |
|         | (↓ 0.00000367) | (↓ 0.00000368) | (↓ 0.00000374) | (↓ 0.00000347) | (↓ 0.00000347) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003783   |   0.00013437   |   0.00027022   |   0.00049592   |   0.00085781   |
|         | (↓ 0.00000258) | (↓ 0.00000216) | (↓ 0.00000139) | (↓ 0.00000140) | (↓ 0.00000078) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01009292   |   0.02207597   |   0.03892741   |   0.06344696   |   0.10182219   |
|         | (↓ 0.00018224) | (↓ 0.00019831) | (↓ 0.00022349) | (↓ 0.00028734) | (↓ 0.00034142) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 14:59:37,415 - block_trainer.py[357] - INFO: epoch 33 (410.213495s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019193   |    0.00020253   |    0.00024773   |    0.00041553   |    0.00133261   |
|         | (↓ -0.00000770) | (↓ -0.00000835) | (↓ -0.00000838) | (↓ -0.00000845) | (↓ -0.00000714) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00004543   |    0.00006687   |    0.00022244   |    0.00066307   |    0.00224406   |
|         | (↓ -0.00000134) | (↓ -0.00000149) | (↓ -0.00000196) | (↓ -0.00000170) | (↓ -0.00000227) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005768   |   0.00015304   |   0.00039287   |   0.00087271   |   0.00220733   |
|         | (↓ 0.00000126) | (↓ 0.00000124) | (↓ 0.00000149) | (↓ 0.00000300) | (↓ 0.00000257) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006238   |   0.00015606   |   0.00063472   |   0.00151884   |   0.00358292   |
|         | (↓ 0.00000492) | (↓ 0.00000489) | (↓ 0.00000479) | (↓ 0.00000434) | (↓ 0.00000450) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008524   |   0.00029988   |   0.00065431   |   0.00119877   |   0.00230005   |
|         | (↓ 0.00000307) | (↓ 0.00000301) | (↓ 0.00000312) | (↓ 0.00000333) | (↓ 0.00000273) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007203   |   0.00007676   |   0.00035173   |   0.00097852   |   0.00232502   |
|         | (↓ 0.00000255) | (↓ 0.00000260) | (↓ 0.00000248) | (↓ 0.00000150) | (↓ 0.00000054) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003728   |   0.00013349   |   0.00026906   |   0.00049447   |   0.00085626   |
|         | (↓ 0.00000055) | (↓ 0.00000088) | (↓ 0.00000117) | (↓ 0.00000144) | (↓ 0.00000156) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.01016634   |    0.02213620   |    0.03898170   |    0.06350422   |    0.10189003   |
|         | (↓ -0.00007342) | (↓ -0.00006023) | (↓ -0.00005428) | (↓ -0.00005726) | (↓ -0.00006784) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2023-06-30 15:06:27,300 - block_trainer.py[357] - INFO: epoch 34 (409.885408s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019700   |    0.00020800   |    0.00025304   |    0.00042079   |    0.00133534   |
|         | (↓ -0.00000507) | (↓ -0.00000547) | (↓ -0.00000531) | (↓ -0.00000525) | (↓ -0.00000273) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004301   |   0.00006433   |   0.00021933   |   0.00065942   |   0.00224131   |
|         | (↓ 0.00000241) | (↓ 0.00000254) | (↓ 0.00000311) | (↓ 0.00000365) | (↓ 0.00000274) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005668   |   0.00015203   |   0.00039183   |   0.00087098   |   0.00220585   |
|         | (↓ 0.00000100) | (↓ 0.00000101) | (↓ 0.00000104) | (↓ 0.00000173) | (↓ 0.00000148) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006396   |    0.00015782   |    0.00063636   |    0.00152040   |    0.00358405   |
|         | (↓ -0.00000158) | (↓ -0.00000177) | (↓ -0.00000164) | (↓ -0.00000156) | (↓ -0.00000114) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00008861   |    0.00030330   |    0.00065721   |    0.00120089   |    0.00230086   |
|         | (↓ -0.00000336) | (↓ -0.00000342) | (↓ -0.00000290) | (↓ -0.00000212) | (↓ -0.00000081) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007524   |    0.00008006   |    0.00035501   |    0.00098022   |   0.00232449   |
|         | (↓ -0.00000321) | (↓ -0.00000330) | (↓ -0.00000327) | (↓ -0.00000170) | (↓ 0.00000053) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003823   |    0.00013434   |    0.00026984   |    0.00049503   |    0.00085673   |
|         | (↓ -0.00000095) | (↓ -0.00000085) | (↓ -0.00000078) | (↓ -0.00000056) | (↓ -0.00000047) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.01018282   |    0.02214192   |    0.03899138   |   0.06348636   |   0.10188072   |
|         | (↓ -0.00001647) | (↓ -0.00000571) | (↓ -0.00000968) | (↓ 0.00001786) | (↓ 0.00000932) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2023-06-30 15:13:17,633 - block_trainer.py[357] - INFO: epoch 35 (410.332524s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018554   |   0.00019534   |   0.00024033   |   0.00040800   |   0.00132155   |
|         | (↓ 0.00001146) | (↓ 0.00001266) | (↓ 0.00001271) | (↓ 0.00001278) | (↓ 0.00001378) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+-----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
| block-1 |    0.00004328   |    0.00006447   |   0.00021932   |    0.00065984   |   0.00224057   |
|         | (↓ -0.00000027) | (↓ -0.00000014) | (↓ 0.00000001) | (↓ -0.00000042) | (↓ 0.00000074) |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005835   |    0.00015379   |    0.00039318   |   0.00087066   |   0.00220491   |
|         | (↓ -0.00000167) | (↓ -0.00000176) | (↓ -0.00000135) | (↓ 0.00000032) | (↓ 0.00000094) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006382   |   0.00015754   |   0.00063606   |   0.00152001   |   0.00358389   |
|         | (↓ 0.00000014) | (↓ 0.00000028) | (↓ 0.00000030) | (↓ 0.00000039) | (↓ 0.00000016) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009124   |    0.00030605   |    0.00065925   |    0.00120225   |    0.00230308   |
|         | (↓ -0.00000263) | (↓ -0.00000276) | (↓ -0.00000204) | (↓ -0.00000136) | (↓ -0.00000222) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00006961   |   0.00007440   |   0.00034856   |   0.00097340   |   0.00231667   |
|         | (↓ 0.00000563) | (↓ 0.00000566) | (↓ 0.00000644) | (↓ 0.00000682) | (↓ 0.00000782) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+-----------------+----------------+----------------+
| block-6 |   0.00003820   |    0.00013438   |    0.00026985   |   0.00049464   |   0.00085657   |
|         | (↓ 0.00000003) | (↓ -0.00000005) | (↓ -0.00000001) | (↓ 0.00000039) | (↓ 0.00000016) |
+---------+----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01010900   |   0.02201669   |   0.03885890   |   0.06332870   |   0.10168470   |
|         | (↓ 0.00007382) | (↓ 0.00012522) | (↓ 0.00013248) | (↓ 0.00015767) | (↓ 0.00019602) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 15:20:07,722 - block_trainer.py[357] - INFO: epoch 36 (410.088490s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00018933   |    0.00019990   |    0.00024469   |    0.00041174   |    0.00132452   |
|         | (↓ -0.00000379) | (↓ -0.00000456) | (↓ -0.00000436) | (↓ -0.00000374) | (↓ -0.00000297) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00004354   |    0.00006470   |    0.00021942   |   0.00065910   |   0.00224010   |
|         | (↓ -0.00000026) | (↓ -0.00000023) | (↓ -0.00000010) | (↓ 0.00000074) | (↓ 0.00000047) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005736   |   0.00015270   |   0.00039149   |   0.00086766   |   0.00220340   |
|         | (↓ 0.00000099) | (↓ 0.00000109) | (↓ 0.00000169) | (↓ 0.00000300) | (↓ 0.00000151) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006391   |    0.00015766   |    0.00063627   |    0.00152038   |   0.00358347   |
|         | (↓ -0.00000009) | (↓ -0.00000012) | (↓ -0.00000021) | (↓ -0.00000037) | (↓ 0.00000042) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009100   |   0.00030510   |   0.00065785   |   0.00120104   |   0.00230151   |
|         | (↓ 0.00000023) | (↓ 0.00000095) | (↓ 0.00000140) | (↓ 0.00000121) | (↓ 0.00000157) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007357   |    0.00007827   |    0.00035207   |    0.00097651   |    0.00231890   |
|         | (↓ -0.00000397) | (↓ -0.00000387) | (↓ -0.00000351) | (↓ -0.00000311) | (↓ -0.00000223) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003961   |    0.00013559   |    0.00027071   |    0.00049491   |    0.00085689   |
|         | (↓ -0.00000141) | (↓ -0.00000120) | (↓ -0.00000086) | (↓ -0.00000027) | (↓ -0.00000032) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01012657   |   0.02200027   |   0.03880391   |   0.06327356   |   0.10167645   |
|         | (↓ -0.00001757) | (↓ 0.00001643) | (↓ 0.00005499) | (↓ 0.00005513) | (↓ 0.00000825) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-30 15:26:57,492 - block_trainer.py[357] - INFO: epoch 37 (409.769943s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018445   |   0.00019481   |   0.00023962   |   0.00040653   |   0.00131809   |
|         | (↓ 0.00000488) | (↓ 0.00000509) | (↓ 0.00000507) | (↓ 0.00000521) | (↓ 0.00000643) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004280   |   0.00006393   |   0.00021890   |   0.00065881   |   0.00224007   |
|         | (↓ 0.00000074) | (↓ 0.00000077) | (↓ 0.00000052) | (↓ 0.00000028) | (↓ 0.00000003) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005613   |   0.00015109   |   0.00038943   |   0.00086456   |   0.00220043   |
|         | (↓ 0.00000123) | (↓ 0.00000161) | (↓ 0.00000206) | (↓ 0.00000310) | (↓ 0.00000297) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006492   |    0.00015854   |    0.00063679   |    0.00152092   |    0.00358480   |
|         | (↓ -0.00000101) | (↓ -0.00000088) | (↓ -0.00000052) | (↓ -0.00000054) | (↓ -0.00000134) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-4 |    0.00009116   |    0.00030513   |   0.00065741   |   0.00119909   |   0.00229971   |
|         | (↓ -0.00000015) | (↓ -0.00000002) | (↓ 0.00000044) | (↓ 0.00000195) | (↓ 0.00000181) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-5 |   0.00007303   |   0.00007775   |    0.00035232   |    0.00097718   |    0.00231991   |
|         | (↓ 0.00000055) | (↓ 0.00000052) | (↓ -0.00000025) | (↓ -0.00000068) | (↓ -0.00000100) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003787   |   0.00013378   |   0.00026884   |   0.00049302   |   0.00085497   |
|         | (↓ 0.00000174) | (↓ 0.00000180) | (↓ 0.00000188) | (↓ 0.00000189) | (↓ 0.00000192) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01005480   |   0.02192477   |   0.03871733   |   0.06312985   |   0.10149106   |
|         | (↓ 0.00007178) | (↓ 0.00007550) | (↓ 0.00008658) | (↓ 0.00014372) | (↓ 0.00018539) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 15:33:47,220 - block_trainer.py[357] - INFO: epoch 38 (409.728210s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019101   |    0.00020124   |    0.00024603   |    0.00041336   |    0.00132188   |
|         | (↓ -0.00000656) | (↓ -0.00000643) | (↓ -0.00000641) | (↓ -0.00000682) | (↓ -0.00000380) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004244   |   0.00006364   |   0.00021812   |   0.00065819   |   0.00223942   |
|         | (↓ 0.00000036) | (↓ 0.00000030) | (↓ 0.00000078) | (↓ 0.00000062) | (↓ 0.00000065) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005268   |   0.00014815   |   0.00038653   |   0.00086134   |   0.00219737   |
|         | (↓ 0.00000345) | (↓ 0.00000294) | (↓ 0.00000289) | (↓ 0.00000322) | (↓ 0.00000306) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006311   |   0.00015697   |   0.00063567   |   0.00152012   |   0.00358295   |
|         | (↓ 0.00000181) | (↓ 0.00000157) | (↓ 0.00000112) | (↓ 0.00000080) | (↓ 0.00000186) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008982   |   0.00030426   |   0.00065626   |   0.00119801   |   0.00229856   |
|         | (↓ 0.00000134) | (↓ 0.00000087) | (↓ 0.00000116) | (↓ 0.00000108) | (↓ 0.00000115) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-5 |   0.00007238   |   0.00007714   |    0.00035237   |    0.00097827   |    0.00232086   |
|         | (↓ 0.00000064) | (↓ 0.00000060) | (↓ -0.00000006) | (↓ -0.00000109) | (↓ -0.00000095) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003793   |    0.00013380   |    0.00026906   |    0.00049348   |    0.00085515   |
|         | (↓ -0.00000006) | (↓ -0.00000002) | (↓ -0.00000022) | (↓ -0.00000045) | (↓ -0.00000018) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.01009942   |    0.02194781   |    0.03876287   |    0.06313161   |   0.10137804   |
|         | (↓ -0.00004462) | (↓ -0.00002305) | (↓ -0.00004554) | (↓ -0.00000176) | (↓ 0.00011301) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2023-06-30 15:40:37,118 - block_trainer.py[357] - INFO: epoch 39 (409.897077s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018900   |   0.00019904   |   0.00024377   |   0.00041104   |   0.00131886   |
|         | (↓ 0.00000201) | (↓ 0.00000220) | (↓ 0.00000226) | (↓ 0.00000232) | (↓ 0.00000302) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00004345   |    0.00006454   |    0.00022000   |    0.00065954   |    0.00224122   |
|         | (↓ -0.00000101) | (↓ -0.00000091) | (↓ -0.00000188) | (↓ -0.00000135) | (↓ -0.00000180) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005851   |    0.00015349   |    0.00039050   |    0.00086462   |    0.00220067   |
|         | (↓ -0.00000583) | (↓ -0.00000534) | (↓ -0.00000397) | (↓ -0.00000328) | (↓ -0.00000330) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006727   |    0.00016089   |    0.00063884   |    0.00152241   |    0.00358483   |
|         | (↓ -0.00000416) | (↓ -0.00000392) | (↓ -0.00000317) | (↓ -0.00000229) | (↓ -0.00000188) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-4 |    0.00009034   |    0.00030451   |   0.00065581   |   0.00119650   |   0.00229608   |
|         | (↓ -0.00000052) | (↓ -0.00000025) | (↓ 0.00000044) | (↓ 0.00000151) | (↓ 0.00000247) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00007263   |    0.00007737   |   0.00035160   |   0.00097583   |   0.00231686   |
|         | (↓ -0.00000024) | (↓ -0.00000023) | (↓ 0.00000077) | (↓ 0.00000244) | (↓ 0.00000400) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-6 |    0.00003868   |    0.00013437   |    0.00026926   |   0.00049333   |    0.00085575   |
|         | (↓ -0.00000075) | (↓ -0.00000057) | (↓ -0.00000021) | (↓ 0.00000014) | (↓ -0.00000060) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-7 |   0.00997772   |   0.02183383   |   0.03862184   |   0.06306054   |    0.10139753   |
|         | (↓ 0.00012170) | (↓ 0.00011398) | (↓ 0.00014102) | (↓ 0.00007106) | (↓ -0.00001949) |
+---------+----------------+----------------+----------------+----------------+-----------------+

2023-06-30 15:47:26,865 - block_trainer.py[357] - INFO: epoch 40 (409.747598s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018572   |   0.00019624   |   0.00024102   |   0.00040757   |   0.00131497   |
|         | (↓ 0.00000328) | (↓ 0.00000279) | (↓ 0.00000276) | (↓ 0.00000347) | (↓ 0.00000390) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004292   |   0.00006410   |   0.00021895   |   0.00065900   |   0.00223864   |
|         | (↓ 0.00000053) | (↓ 0.00000044) | (↓ 0.00000105) | (↓ 0.00000054) | (↓ 0.00000258) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005606   |   0.00015136   |   0.00038779   |   0.00086183   |   0.00219804   |
|         | (↓ 0.00000245) | (↓ 0.00000213) | (↓ 0.00000271) | (↓ 0.00000279) | (↓ 0.00000263) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006346   |   0.00015731   |   0.00063581   |   0.00152007   |   0.00358254   |
|         | (↓ 0.00000381) | (↓ 0.00000358) | (↓ 0.00000303) | (↓ 0.00000234) | (↓ 0.00000228) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008619   |   0.00030105   |   0.00065302   |   0.00119426   |   0.00229462   |
|         | (↓ 0.00000415) | (↓ 0.00000346) | (↓ 0.00000280) | (↓ 0.00000224) | (↓ 0.00000146) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-5 |   0.00007196   |   0.00007674   |    0.00035181   |    0.00097620   |    0.00231781   |
|         | (↓ 0.00000067) | (↓ 0.00000064) | (↓ -0.00000020) | (↓ -0.00000037) | (↓ -0.00000094) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003695   |   0.00013291   |   0.00026802   |   0.00049195   |   0.00085407   |
|         | (↓ 0.00000173) | (↓ 0.00000146) | (↓ 0.00000124) | (↓ 0.00000139) | (↓ 0.00000168) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.00998959   |   0.02181035   |   0.03856989   |   0.06291987   |   0.10119465   |
|         | (↓ -0.00001187) | (↓ 0.00002348) | (↓ 0.00005196) | (↓ 0.00014068) | (↓ 0.00020288) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-30 15:54:16,908 - block_trainer.py[357] - INFO: epoch 41 (410.042894s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019312   |    0.00020290   |    0.00024733   |    0.00041362   |    0.00131937   |
|         | (↓ -0.00000739) | (↓ -0.00000666) | (↓ -0.00000632) | (↓ -0.00000605) | (↓ -0.00000440) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00004408   |    0.00006539   |    0.00022085   |    0.00066071   |    0.00224181   |
|         | (↓ -0.00000117) | (↓ -0.00000128) | (↓ -0.00000190) | (↓ -0.00000171) | (↓ -0.00000318) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-2 |    0.00005636   |    0.00015148   |   0.00038725   |   0.00086050   |   0.00219721   |
|         | (↓ -0.00000030) | (↓ -0.00000012) | (↓ 0.00000054) | (↓ 0.00000133) | (↓ 0.00000082) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006427   |    0.00015814   |    0.00063693   |    0.00152134   |    0.00358419   |
|         | (↓ -0.00000081) | (↓ -0.00000083) | (↓ -0.00000112) | (↓ -0.00000126) | (↓ -0.00000165) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-4 |    0.00008795   |    0.00030280   |    0.00065431   |    0.00119493   |   0.00229447   |
|         | (↓ -0.00000176) | (↓ -0.00000176) | (↓ -0.00000130) | (↓ -0.00000067) | (↓ 0.00000015) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00007412   |    0.00007897   |    0.00035294   |   0.00097604   |   0.00231767   |
|         | (↓ -0.00000216) | (↓ -0.00000223) | (↓ -0.00000113) | (↓ 0.00000016) | (↓ 0.00000013) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003789   |    0.00013369   |    0.00026865   |    0.00049207   |    0.00085458   |
|         | (↓ -0.00000094) | (↓ -0.00000078) | (↓ -0.00000063) | (↓ -0.00000012) | (↓ -0.00000051) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.01009392   |    0.02191449   |    0.03864423   |    0.06298687   |   0.10115754   |
|         | (↓ -0.00010433) | (↓ -0.00010414) | (↓ -0.00007434) | (↓ -0.00006701) | (↓ 0.00003712) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2023-06-30 16:01:06,909 - block_trainer.py[357] - INFO: epoch 42 (409.999958s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018931   |   0.00019939   |   0.00024378   |   0.00041045   |   0.00131553   |
|         | (↓ 0.00000380) | (↓ 0.00000351) | (↓ 0.00000355) | (↓ 0.00000317) | (↓ 0.00000384) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004170   |   0.00006285   |   0.00021702   |   0.00065645   |   0.00223724   |
|         | (↓ 0.00000238) | (↓ 0.00000254) | (↓ 0.00000383) | (↓ 0.00000426) | (↓ 0.00000457) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005399   |   0.00014920   |   0.00038415   |   0.00085757   |   0.00219364   |
|         | (↓ 0.00000237) | (↓ 0.00000228) | (↓ 0.00000310) | (↓ 0.00000293) | (↓ 0.00000357) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006579   |    0.00015964   |    0.00063826   |    0.00152281   |   0.00358311   |
|         | (↓ -0.00000151) | (↓ -0.00000149) | (↓ -0.00000133) | (↓ -0.00000147) | (↓ 0.00000108) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00008801   |   0.00030222   |   0.00065329   |   0.00119295   |   0.00229247   |
|         | (↓ -0.00000006) | (↓ 0.00000059) | (↓ 0.00000102) | (↓ 0.00000198) | (↓ 0.00000200) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007132   |   0.00007618   |   0.00035054   |   0.00097182   |   0.00231363   |
|         | (↓ 0.00000280) | (↓ 0.00000279) | (↓ 0.00000240) | (↓ 0.00000423) | (↓ 0.00000405) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003710   |   0.00013278   |   0.00026786   |   0.00049094   |   0.00085250   |
|         | (↓ 0.00000079) | (↓ 0.00000091) | (↓ 0.00000080) | (↓ 0.00000113) | (↓ 0.00000208) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01002100   |   0.02181487   |   0.03854939   |   0.06288491   |   0.10110465   |
|         | (↓ 0.00007292) | (↓ 0.00009962) | (↓ 0.00009484) | (↓ 0.00010197) | (↓ 0.00005288) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 16:07:57,028 - block_trainer.py[357] - INFO: epoch 43 (410.118789s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019229   |    0.00020238   |    0.00024716   |    0.00041308   |    0.00131723   |
|         | (↓ -0.00000298) | (↓ -0.00000298) | (↓ -0.00000337) | (↓ -0.00000263) | (↓ -0.00000171) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00004657   |    0.00006775   |    0.00022226   |    0.00066204   |    0.00224183   |
|         | (↓ -0.00000487) | (↓ -0.00000490) | (↓ -0.00000524) | (↓ -0.00000559) | (↓ -0.00000459) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005983   |    0.00015491   |    0.00038883   |    0.00086176   |    0.00219770   |
|         | (↓ -0.00000584) | (↓ -0.00000570) | (↓ -0.00000468) | (↓ -0.00000419) | (↓ -0.00000406) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006433   |   0.00015807   |   0.00063634   |   0.00152001   |   0.00357993   |
|         | (↓ 0.00000145) | (↓ 0.00000156) | (↓ 0.00000191) | (↓ 0.00000280) | (↓ 0.00000318) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009172   |    0.00030565   |    0.00065606   |    0.00119473   |    0.00229461   |
|         | (↓ -0.00000371) | (↓ -0.00000343) | (↓ -0.00000277) | (↓ -0.00000179) | (↓ -0.00000214) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007388   |    0.00007864   |    0.00035281   |    0.00097349   |    0.00231551   |
|         | (↓ -0.00000256) | (↓ -0.00000246) | (↓ -0.00000227) | (↓ -0.00000167) | (↓ -0.00000189) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+-----------------+----------------+-----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+----------------+-----------------+----------------+-----------------+
| block-6 |    0.00003761   |   0.00013277   |    0.00026795   |   0.00049085   |    0.00085273   |
|         | (↓ -0.00000051) | (↓ 0.00000002) | (↓ -0.00000010) | (↓ 0.00000008) | (↓ -0.00000023) |
+---------+-----------------+----------------+-----------------+----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01002928   |   0.02180723   |   0.03851231   |   0.06277383   |   0.10093108   |
|         | (↓ -0.00000827) | (↓ 0.00000764) | (↓ 0.00003709) | (↓ 0.00011108) | (↓ 0.00017357) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2023-06-30 16:14:46,803 - block_trainer.py[357] - INFO: epoch 44 (409.774845s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018972   |   0.00020027   |   0.00024508   |   0.00041122   |   0.00131514   |
|         | (↓ 0.00000257) | (↓ 0.00000211) | (↓ 0.00000207) | (↓ 0.00000185) | (↓ 0.00000209) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004357   |   0.00006481   |   0.00021929   |   0.00065915   |   0.00223948   |
|         | (↓ 0.00000300) | (↓ 0.00000294) | (↓ 0.00000296) | (↓ 0.00000290) | (↓ 0.00000235) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005788   |   0.00015285   |   0.00038571   |   0.00085858   |   0.00219475   |
|         | (↓ 0.00000195) | (↓ 0.00000206) | (↓ 0.00000313) | (↓ 0.00000318) | (↓ 0.00000295) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-3 |   0.00006401   |   0.00015797   |    0.00063653   |    0.00152065   |    0.00358059   |
|         | (↓ 0.00000033) | (↓ 0.00000011) | (↓ -0.00000019) | (↓ -0.00000064) | (↓ -0.00000066) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008856   |   0.00030309   |   0.00065385   |   0.00119348   |   0.00229291   |
|         | (↓ 0.00000316) | (↓ 0.00000256) | (↓ 0.00000221) | (↓ 0.00000125) | (↓ 0.00000170) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+----------------+-----------------+
| block-5 |   0.00007380   |    0.00007867   |    0.00035289   |   0.00097279   |    0.00231574   |
|         | (↓ 0.00000008) | (↓ -0.00000003) | (↓ -0.00000009) | (↓ 0.00000069) | (↓ -0.00000023) |
+---------+----------------+-----------------+-----------------+----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003854   |    0.00013330   |    0.00026833   |    0.00049120   |    0.00085298   |
|         | (↓ -0.00000094) | (↓ -0.00000053) | (↓ -0.00000038) | (↓ -0.00000034) | (↓ -0.00000025) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.01007013   |    0.02183939   |    0.03855106   |    0.06285239   |    0.10105811   |
|         | (↓ -0.00004085) | (↓ -0.00003217) | (↓ -0.00003875) | (↓ -0.00007857) | (↓ -0.00012703) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2023-06-30 16:21:36,776 - block_trainer.py[357] - INFO: epoch 45 (409.973516s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018770   |   0.00019797   |   0.00024247   |   0.00040817   |   0.00131172   |
|         | (↓ 0.00000203) | (↓ 0.00000230) | (↓ 0.00000261) | (↓ 0.00000305) | (↓ 0.00000342) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004199   |   0.00006312   |   0.00021682   |   0.00065662   |   0.00223584   |
|         | (↓ 0.00000158) | (↓ 0.00000169) | (↓ 0.00000247) | (↓ 0.00000252) | (↓ 0.00000364) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005674   |   0.00015186   |   0.00038469   |   0.00085741   |   0.00219291   |
|         | (↓ 0.00000115) | (↓ 0.00000099) | (↓ 0.00000102) | (↓ 0.00000117) | (↓ 0.00000183) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006357   |   0.00015733   |   0.00063580   |   0.00151958   |   0.00357771   |
|         | (↓ 0.00000043) | (↓ 0.00000063) | (↓ 0.00000073) | (↓ 0.00000107) | (↓ 0.00000288) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008665   |   0.00030073   |   0.00065119   |   0.00118952   |   0.00228784   |
|         | (↓ 0.00000191) | (↓ 0.00000236) | (↓ 0.00000266) | (↓ 0.00000396) | (↓ 0.00000507) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007402   |    0.00007888   |    0.00035308   |    0.00097318   |    0.00231607   |
|         | (↓ -0.00000022) | (↓ -0.00000021) | (↓ -0.00000019) | (↓ -0.00000039) | (↓ -0.00000033) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003681   |   0.00013153   |   0.00026683   |   0.00048955   |   0.00085192   |
|         | (↓ 0.00000173) | (↓ 0.00000177) | (↓ 0.00000150) | (↓ 0.00000165) | (↓ 0.00000106) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00992473   |   0.02170233   |   0.03838232   |   0.06265843   |   0.10080773   |
|         | (↓ 0.00014540) | (↓ 0.00013706) | (↓ 0.00016874) | (↓ 0.00019396) | (↓ 0.00025038) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 16:28:26,696 - block_trainer.py[357] - INFO: epoch 46 (409.920044s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00017959   |   0.00018968   |   0.00023429   |   0.00040032   |   0.00130312   |
|         | (↓ 0.00000811) | (↓ 0.00000829) | (↓ 0.00000818) | (↓ 0.00000785) | (↓ 0.00000860) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003945   |   0.00006071   |   0.00021418   |   0.00065406   |   0.00222954   |
|         | (↓ 0.00000254) | (↓ 0.00000241) | (↓ 0.00000264) | (↓ 0.00000256) | (↓ 0.00000630) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005548   |   0.00015069   |   0.00038297   |   0.00085621   |   0.00219122   |
|         | (↓ 0.00000126) | (↓ 0.00000117) | (↓ 0.00000171) | (↓ 0.00000120) | (↓ 0.00000170) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005747   |   0.00015142   |   0.00063011   |   0.00151372   |   0.00357321   |
|         | (↓ 0.00000611) | (↓ 0.00000591) | (↓ 0.00000569) | (↓ 0.00000586) | (↓ 0.00000450) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008167   |   0.00029648   |   0.00064740   |   0.00118605   |   0.00228494   |
|         | (↓ 0.00000499) | (↓ 0.00000425) | (↓ 0.00000379) | (↓ 0.00000347) | (↓ 0.00000290) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007413   |    0.00007893   |    0.00035373   |    0.00097397   |    0.00231716   |
|         | (↓ -0.00000011) | (↓ -0.00000005) | (↓ -0.00000065) | (↓ -0.00000078) | (↓ -0.00000109) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003517   |   0.00012977   |   0.00026566   |   0.00048850   |   0.00085119   |
|         | (↓ 0.00000164) | (↓ 0.00000176) | (↓ 0.00000117) | (↓ 0.00000105) | (↓ 0.00000073) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.00994004   |    0.02172082   |    0.03839328   |    0.06268279   |    0.10090530   |
|         | (↓ -0.00001532) | (↓ -0.00001849) | (↓ -0.00001097) | (↓ -0.00002436) | (↓ -0.00009757) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2023-06-30 16:35:16,576 - block_trainer.py[357] - INFO: epoch 47 (409.879255s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019435   |    0.00020473   |    0.00024944   |    0.00041493   |    0.00131795   |
|         | (↓ -0.00001477) | (↓ -0.00001505) | (↓ -0.00001516) | (↓ -0.00001461) | (↓ -0.00001483) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00004344   |    0.00006440   |    0.00021838   |    0.00065868   |   0.00222944   |
|         | (↓ -0.00000399) | (↓ -0.00000369) | (↓ -0.00000420) | (↓ -0.00000462) | (↓ 0.00000010) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005755   |    0.00015261   |    0.00038405   |    0.00085715   |    0.00219214   |
|         | (↓ -0.00000208) | (↓ -0.00000192) | (↓ -0.00000108) | (↓ -0.00000094) | (↓ -0.00000093) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006805   |    0.00016186   |    0.00064011   |    0.00152430   |    0.00358365   |
|         | (↓ -0.00001058) | (↓ -0.00001043) | (↓ -0.00001000) | (↓ -0.00001058) | (↓ -0.00001044) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009084   |    0.00030464   |    0.00065441   |    0.00119272   |    0.00229250   |
|         | (↓ -0.00000917) | (↓ -0.00000816) | (↓ -0.00000701) | (↓ -0.00000667) | (↓ -0.00000756) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007386   |   0.00007861   |   0.00035217   |   0.00097141   |   0.00231479   |
|         | (↓ 0.00000027) | (↓ 0.00000032) | (↓ 0.00000156) | (↓ 0.00000255) | (↓ 0.00000237) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003837   |    0.00013238   |    0.00026768   |    0.00049006   |    0.00085307   |
|         | (↓ -0.00000320) | (↓ -0.00000261) | (↓ -0.00000202) | (↓ -0.00000157) | (↓ -0.00000188) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+-----------------+----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+----------------+----------------+
| block-7 |    0.00997762   |   0.02171023   |    0.03841165   |   0.06265877   |   0.10074642   |
|         | (↓ -0.00003757) | (↓ 0.00001060) | (↓ -0.00001837) | (↓ 0.00002402) | (↓ 0.00015888) |
+---------+-----------------+----------------+-----------------+----------------+----------------+

2023-06-30 16:42:06,134 - block_trainer.py[357] - INFO: epoch 48 (409.557854s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018535   |   0.00019596   |   0.00024054   |   0.00040541   |   0.00130631   |
|         | (↓ 0.00000901) | (↓ 0.00000877) | (↓ 0.00000890) | (↓ 0.00000952) | (↓ 0.00001164) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004189   |   0.00006297   |   0.00021569   |   0.00065626   |   0.00221871   |
|         | (↓ 0.00000155) | (↓ 0.00000143) | (↓ 0.00000269) | (↓ 0.00000242) | (↓ 0.00001073) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005586   |   0.00015137   |   0.00038278   |   0.00085613   |   0.00219075   |
|         | (↓ 0.00000170) | (↓ 0.00000123) | (↓ 0.00000127) | (↓ 0.00000102) | (↓ 0.00000139) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006402   |   0.00015776   |   0.00063627   |   0.00152008   |   0.00357832   |
|         | (↓ 0.00000403) | (↓ 0.00000409) | (↓ 0.00000384) | (↓ 0.00000422) | (↓ 0.00000533) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008712   |   0.00030157   |   0.00065183   |   0.00118987   |   0.00228874   |
|         | (↓ 0.00000372) | (↓ 0.00000307) | (↓ 0.00000258) | (↓ 0.00000285) | (↓ 0.00000376) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007177   |   0.00007655   |   0.00035087   |   0.00097007   |   0.00231364   |
|         | (↓ 0.00000209) | (↓ 0.00000205) | (↓ 0.00000129) | (↓ 0.00000134) | (↓ 0.00000115) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003605   |   0.00013015   |   0.00026622   |   0.00048893   |   0.00085107   |
|         | (↓ 0.00000232) | (↓ 0.00000223) | (↓ 0.00000145) | (↓ 0.00000113) | (↓ 0.00000200) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-7 |   0.00996384   |    0.02171295   |   0.03840194   |   0.06260389   |   0.10069678   |
|         | (↓ 0.00001378) | (↓ -0.00000272) | (↓ 0.00000971) | (↓ 0.00005487) | (↓ 0.00004964) |
+---------+----------------+-----------------+----------------+----------------+----------------+

2023-06-30 16:48:55,862 - block_trainer.py[357] - INFO: epoch 49 (409.727922s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019365   |    0.00020331   |    0.00024816   |    0.00041272   |    0.00131372   |
|         | (↓ -0.00000830) | (↓ -0.00000735) | (↓ -0.00000762) | (↓ -0.00000731) | (↓ -0.00000741) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00004648   |    0.00006754   |    0.00022045   |    0.00066108   |   0.00221208   |
|         | (↓ -0.00000459) | (↓ -0.00000457) | (↓ -0.00000476) | (↓ -0.00000482) | (↓ 0.00000663) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00006113   |    0.00015617   |    0.00038661   |    0.00085896   |    0.00219294   |
|         | (↓ -0.00000527) | (↓ -0.00000479) | (↓ -0.00000383) | (↓ -0.00000283) | (↓ -0.00000218) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006233   |   0.00015618   |   0.00063414   |   0.00151746   |   0.00357325   |
|         | (↓ 0.00000169) | (↓ 0.00000158) | (↓ 0.00000214) | (↓ 0.00000261) | (↓ 0.00000507) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00008956   |    0.00030359   |    0.00065263   |    0.00119002   |    0.00228915   |
|         | (↓ -0.00000244) | (↓ -0.00000202) | (↓ -0.00000080) | (↓ -0.00000015) | (↓ -0.00000040) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007047   |   0.00007529   |   0.00034941   |   0.00096822   |   0.00230981   |
|         | (↓ 0.00000130) | (↓ 0.00000126) | (↓ 0.00000146) | (↓ 0.00000186) | (↓ 0.00000382) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003731   |    0.00013120   |    0.00026702   |    0.00048911   |    0.00085150   |
|         | (↓ -0.00000126) | (↓ -0.00000105) | (↓ -0.00000080) | (↓ -0.00000018) | (↓ -0.00000043) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.01006097   |    0.02177919   |    0.03840582   |    0.06262411   |   0.10066767   |
|         | (↓ -0.00009713) | (↓ -0.00006624) | (↓ -0.00000388) | (↓ -0.00002022) | (↓ 0.00002912) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2023-06-30 16:55:45,807 - block_trainer.py[357] - INFO: epoch 50 (409.945174s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018646   |   0.00019691   |   0.00024156   |   0.00040584   |   0.00130915   |
|         | (↓ 0.00000719) | (↓ 0.00000640) | (↓ 0.00000660) | (↓ 0.00000688) | (↓ 0.00000457) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003950   |   0.00006060   |   0.00021251   |   0.00065384   |   0.00219412   |
|         | (↓ 0.00000697) | (↓ 0.00000693) | (↓ 0.00000795) | (↓ 0.00000725) | (↓ 0.00001796) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005456   |   0.00015012   |   0.00038094   |   0.00085439   |   0.00218808   |
|         | (↓ 0.00000657) | (↓ 0.00000605) | (↓ 0.00000567) | (↓ 0.00000457) | (↓ 0.00000485) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006442   |    0.00015814   |    0.00063652   |    0.00152057   |    0.00357650   |
|         | (↓ -0.00000210) | (↓ -0.00000196) | (↓ -0.00000238) | (↓ -0.00000311) | (↓ -0.00000325) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008627   |   0.00030054   |   0.00064975   |   0.00118762   |   0.00228694   |
|         | (↓ 0.00000329) | (↓ 0.00000305) | (↓ 0.00000288) | (↓ 0.00000241) | (↓ 0.00000221) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00006989   |   0.00007467   |   0.00034911   |   0.00096798   |   0.00230929   |
|         | (↓ 0.00000058) | (↓ 0.00000062) | (↓ 0.00000030) | (↓ 0.00000024) | (↓ 0.00000053) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003611   |   0.00013023   |   0.00026622   |   0.00048827   |   0.00085087   |
|         | (↓ 0.00000120) | (↓ 0.00000097) | (↓ 0.00000081) | (↓ 0.00000085) | (↓ 0.00000063) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00993417   |   0.02164087   |   0.03831302   |   0.06250488   |   0.10051205   |
|         | (↓ 0.00012680) | (↓ 0.00013832) | (↓ 0.00009280) | (↓ 0.00011923) | (↓ 0.00015562) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 17:02:35,857 - block_trainer.py[357] - INFO: epoch 51 (410.049123s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019174   |    0.00020251   |    0.00024735   |    0.00041133   |    0.00131295   |
|         | (↓ -0.00000528) | (↓ -0.00000560) | (↓ -0.00000578) | (↓ -0.00000550) | (↓ -0.00000380) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00004163   |    0.00006272   |    0.00021337   |    0.00065571   |   0.00218361   |
|         | (↓ -0.00000213) | (↓ -0.00000211) | (↓ -0.00000086) | (↓ -0.00000188) | (↓ 0.00001051) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005691   |    0.00015217   |    0.00038242   |    0.00085537   |    0.00218889   |
|         | (↓ -0.00000235) | (↓ -0.00000205) | (↓ -0.00000148) | (↓ -0.00000099) | (↓ -0.00000080) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006200   |   0.00015576   |   0.00063413   |   0.00151795   |   0.00357521   |
|         | (↓ 0.00000242) | (↓ 0.00000238) | (↓ 0.00000239) | (↓ 0.00000262) | (↓ 0.00000129) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-4 |    0.00008728   |    0.00030120   |   0.00064946   |   0.00118720   |   0.00228611   |
|         | (↓ -0.00000102) | (↓ -0.00000066) | (↓ 0.00000029) | (↓ 0.00000042) | (↓ 0.00000083) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007207   |    0.00007684   |    0.00035094   |    0.00097017   |    0.00231289   |
|         | (↓ -0.00000218) | (↓ -0.00000217) | (↓ -0.00000182) | (↓ -0.00000219) | (↓ -0.00000361) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-6 |    0.00003748   |    0.00013093   |    0.00026651   |   0.00048823   |    0.00085158   |
|         | (↓ -0.00000137) | (↓ -0.00000070) | (↓ -0.00000030) | (↓ 0.00000004) | (↓ -0.00000071) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00984636   |   0.02156295   |   0.03817703   |   0.06235196   |   0.10041948   |
|         | (↓ 0.00008781) | (↓ 0.00007792) | (↓ 0.00013599) | (↓ 0.00015291) | (↓ 0.00009256) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 17:09:25,488 - block_trainer.py[357] - INFO: epoch 52 (409.631259s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018971   |   0.00019993   |   0.00024451   |   0.00040764   |   0.00131001   |
|         | (↓ 0.00000203) | (↓ 0.00000258) | (↓ 0.00000283) | (↓ 0.00000369) | (↓ 0.00000293) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+-----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
| block-1 |    0.00004281   |    0.00006416   |   0.00021295   |    0.00065696   |   0.00217562   |
|         | (↓ -0.00000118) | (↓ -0.00000144) | (↓ 0.00000042) | (↓ -0.00000125) | (↓ 0.00000800) |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005405   |   0.00014930   |   0.00037933   |   0.00085232   |   0.00218426   |
|         | (↓ 0.00000286) | (↓ 0.00000287) | (↓ 0.00000309) | (↓ 0.00000306) | (↓ 0.00000463) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006315   |    0.00015715   |    0.00063551   |    0.00151960   |    0.00357710   |
|         | (↓ -0.00000114) | (↓ -0.00000138) | (↓ -0.00000138) | (↓ -0.00000165) | (↓ -0.00000189) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008567   |   0.00029898   |   0.00064636   |   0.00118513   |   0.00228444   |
|         | (↓ 0.00000161) | (↓ 0.00000222) | (↓ 0.00000310) | (↓ 0.00000207) | (↓ 0.00000167) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007257   |    0.00007732   |    0.00035163   |    0.00097057   |   0.00231102   |
|         | (↓ -0.00000050) | (↓ -0.00000047) | (↓ -0.00000069) | (↓ -0.00000040) | (↓ 0.00000187) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003623   |   0.00012998   |   0.00026588   |   0.00048763   |   0.00085074   |
|         | (↓ 0.00000125) | (↓ 0.00000095) | (↓ 0.00000063) | (↓ 0.00000060) | (↓ 0.00000084) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.00990708   |    0.02161932   |    0.03824396   |    0.06240725   |    0.10045142   |
|         | (↓ -0.00006072) | (↓ -0.00005637) | (↓ -0.00006693) | (↓ -0.00005529) | (↓ -0.00003193) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2023-06-30 17:16:15,277 - block_trainer.py[357] - INFO: epoch 53 (409.789277s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019206   |    0.00020248   |    0.00024715   |    0.00041034   |    0.00131061   |
|         | (↓ -0.00000235) | (↓ -0.00000255) | (↓ -0.00000264) | (↓ -0.00000270) | (↓ -0.00000059) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+-----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
| block-1 |    0.00004449   |    0.00006562   |   0.00021150   |    0.00065822   |   0.00216899   |
|         | (↓ -0.00000168) | (↓ -0.00000146) | (↓ 0.00000146) | (↓ -0.00000125) | (↓ 0.00000663) |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005755   |    0.00015286   |    0.00038259   |    0.00085562   |    0.00218829   |
|         | (↓ -0.00000350) | (↓ -0.00000356) | (↓ -0.00000326) | (↓ -0.00000331) | (↓ -0.00000403) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006606   |    0.00015999   |    0.00063849   |    0.00152255   |    0.00357902   |
|         | (↓ -0.00000291) | (↓ -0.00000284) | (↓ -0.00000299) | (↓ -0.00000295) | (↓ -0.00000192) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00008793   |    0.00030145   |    0.00064760   |    0.00118696   |    0.00228622   |
|         | (↓ -0.00000225) | (↓ -0.00000247) | (↓ -0.00000123) | (↓ -0.00000183) | (↓ -0.00000178) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007073   |   0.00007552   |   0.00034961   |   0.00096861   |   0.00230895   |
|         | (↓ 0.00000184) | (↓ 0.00000179) | (↓ 0.00000202) | (↓ 0.00000196) | (↓ 0.00000207) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003619   |   0.00012985   |   0.00026555   |   0.00048700   |   0.00084977   |
|         | (↓ 0.00000004) | (↓ 0.00000013) | (↓ 0.00000032) | (↓ 0.00000063) | (↓ 0.00000096) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.00995071   |    0.02165296   |    0.03828663   |    0.06244105   |   0.10043315   |
|         | (↓ -0.00004364) | (↓ -0.00003364) | (↓ -0.00004266) | (↓ -0.00003380) | (↓ 0.00001827) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2023-06-30 17:23:05,275 - block_trainer.py[357] - INFO: epoch 54 (409.997858s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018475   |   0.00019466   |   0.00023925   |   0.00040235   |   0.00130294   |
|         | (↓ 0.00000731) | (↓ 0.00000782) | (↓ 0.00000790) | (↓ 0.00000800) | (↓ 0.00000766) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004308   |   0.00006419   |   0.00020633   |   0.00065650   |   0.00216240   |
|         | (↓ 0.00000142) | (↓ 0.00000143) | (↓ 0.00000516) | (↓ 0.00000172) | (↓ 0.00000659) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005643   |   0.00015146   |   0.00038095   |   0.00085425   |   0.00218664   |
|         | (↓ 0.00000112) | (↓ 0.00000140) | (↓ 0.00000164) | (↓ 0.00000137) | (↓ 0.00000166) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006523   |   0.00015920   |   0.00063748   |   0.00152121   |   0.00357639   |
|         | (↓ 0.00000083) | (↓ 0.00000079) | (↓ 0.00000102) | (↓ 0.00000134) | (↓ 0.00000264) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008568   |   0.00029884   |   0.00064459   |   0.00118491   |   0.00228457   |
|         | (↓ 0.00000225) | (↓ 0.00000261) | (↓ 0.00000301) | (↓ 0.00000205) | (↓ 0.00000165) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007496   |    0.00007970   |    0.00035386   |    0.00097301   |    0.00231300   |
|         | (↓ -0.00000423) | (↓ -0.00000418) | (↓ -0.00000425) | (↓ -0.00000440) | (↓ -0.00000405) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003527   |   0.00012896   |   0.00026476   |   0.00048617   |   0.00084933   |
|         | (↓ 0.00000092) | (↓ 0.00000089) | (↓ 0.00000079) | (↓ 0.00000082) | (↓ 0.00000044) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00988252   |   0.02156285   |   0.03817478   |   0.06233828   |   0.10025170   |
|         | (↓ 0.00006820) | (↓ 0.00009011) | (↓ 0.00011184) | (↓ 0.00010277) | (↓ 0.00018145) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 17:29:55,257 - block_trainer.py[357] - INFO: epoch 55 (409.981570s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019655   |    0.00020712   |    0.00025172   |    0.00041456   |    0.00131484   |
|         | (↓ -0.00001179) | (↓ -0.00001246) | (↓ -0.00001247) | (↓ -0.00001221) | (↓ -0.00001190) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004255   |   0.00006367   |   0.00019970   |   0.00065617   |   0.00215818   |
|         | (↓ 0.00000053) | (↓ 0.00000052) | (↓ 0.00000663) | (↓ 0.00000033) | (↓ 0.00000422) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005372   |   0.00014907   |   0.00037828   |   0.00085147   |   0.00218302   |
|         | (↓ 0.00000271) | (↓ 0.00000239) | (↓ 0.00000267) | (↓ 0.00000278) | (↓ 0.00000362) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006439   |   0.00015825   |   0.00063637   |   0.00151997   |   0.00357395   |
|         | (↓ 0.00000084) | (↓ 0.00000094) | (↓ 0.00000111) | (↓ 0.00000124) | (↓ 0.00000244) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+-----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
| block-4 |    0.00008766   |    0.00030034   |   0.00064446   |    0.00118496   |   0.00228365   |
|         | (↓ -0.00000198) | (↓ -0.00000150) | (↓ 0.00000012) | (↓ -0.00000005) | (↓ 0.00000092) |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00006937   |   0.00007418   |   0.00034822   |   0.00096723   |   0.00230708   |
|         | (↓ 0.00000559) | (↓ 0.00000553) | (↓ 0.00000565) | (↓ 0.00000577) | (↓ 0.00000592) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003646   |    0.00013007   |    0.00026564   |    0.00048682   |    0.00085016   |
|         | (↓ -0.00000119) | (↓ -0.00000111) | (↓ -0.00000088) | (↓ -0.00000064) | (↓ -0.00000083) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00983744   |   0.02150611   |   0.03809213   |   0.06220765   |   0.10008171   |
|         | (↓ 0.00004508) | (↓ 0.00005674) | (↓ 0.00008265) | (↓ 0.00013063) | (↓ 0.00017000) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 17:36:45,062 - block_trainer.py[357] - INFO: epoch 56 (409.804587s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019694   |    0.00020801   |    0.00025245   |    0.00041475   |    0.00131572   |
|         | (↓ -0.00000040) | (↓ -0.00000089) | (↓ -0.00000073) | (↓ -0.00000019) | (↓ -0.00000087) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00004360   |    0.00006485   |   0.00019321   |   0.00065593   |   0.00215320   |
|         | (↓ -0.00000105) | (↓ -0.00000118) | (↓ 0.00000649) | (↓ 0.00000024) | (↓ 0.00000498) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005352   |   0.00014878   |   0.00037779   |   0.00085086   |   0.00218103   |
|         | (↓ 0.00000020) | (↓ 0.00000028) | (↓ 0.00000049) | (↓ 0.00000062) | (↓ 0.00000200) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006083   |   0.00015462   |   0.00063276   |   0.00151632   |   0.00356921   |
|         | (↓ 0.00000356) | (↓ 0.00000364) | (↓ 0.00000360) | (↓ 0.00000366) | (↓ 0.00000474) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008298   |   0.00029607   |   0.00064020   |   0.00118093   |   0.00227915   |
|         | (↓ 0.00000467) | (↓ 0.00000426) | (↓ 0.00000426) | (↓ 0.00000403) | (↓ 0.00000450) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007081   |    0.00007565   |    0.00035013   |    0.00096836   |    0.00230814   |
|         | (↓ -0.00000144) | (↓ -0.00000148) | (↓ -0.00000192) | (↓ -0.00000113) | (↓ -0.00000106) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003574   |   0.00012934   |   0.00026475   |   0.00048566   |   0.00084873   |
|         | (↓ 0.00000073) | (↓ 0.00000073) | (↓ 0.00000089) | (↓ 0.00000116) | (↓ 0.00000143) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.00989662   |    0.02157827   |    0.03815900   |    0.06226925   |    0.10017588   |
|         | (↓ -0.00005918) | (↓ -0.00007216) | (↓ -0.00006687) | (↓ -0.00006161) | (↓ -0.00009417) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2023-06-30 17:43:34,647 - block_trainer.py[357] - INFO: epoch 57 (409.585356s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019069   |   0.00020087   |   0.00024558   |   0.00040796   |   0.00130820   |
|         | (↓ 0.00000626) | (↓ 0.00000714) | (↓ 0.00000687) | (↓ 0.00000679) | (↓ 0.00000752) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004146   |   0.00006275   |   0.00018805   |   0.00065437   |   0.00215053   |
|         | (↓ 0.00000214) | (↓ 0.00000209) | (↓ 0.00000516) | (↓ 0.00000156) | (↓ 0.00000267) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005177   |   0.00014714   |   0.00037649   |   0.00084999   |   0.00218053   |
|         | (↓ 0.00000175) | (↓ 0.00000164) | (↓ 0.00000131) | (↓ 0.00000086) | (↓ 0.00000050) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006200   |    0.00015589   |    0.00063430   |    0.00151775   |    0.00357021   |
|         | (↓ -0.00000117) | (↓ -0.00000128) | (↓ -0.00000154) | (↓ -0.00000143) | (↓ -0.00000100) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
| block-4 |    0.00008505   |    0.00029739   |   0.00063999   |    0.00118153   |    0.00228049   |
|         | (↓ -0.00000206) | (↓ -0.00000132) | (↓ 0.00000021) | (↓ -0.00000060) | (↓ -0.00000133) |
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007409   |    0.00007893   |    0.00035310   |    0.00097150   |    0.00231184   |
|         | (↓ -0.00000328) | (↓ -0.00000328) | (↓ -0.00000297) | (↓ -0.00000314) | (↓ -0.00000370) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003577   |    0.00012947   |    0.00026505   |    0.00048569   |    0.00084879   |
|         | (↓ -0.00000003) | (↓ -0.00000013) | (↓ -0.00000030) | (↓ -0.00000003) | (↓ -0.00000006) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.00997178   |    0.02164077   |    0.03825685   |    0.06234189   |    0.10030902   |
|         | (↓ -0.00007516) | (↓ -0.00006251) | (↓ -0.00009785) | (↓ -0.00007264) | (↓ -0.00013314) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2023-06-30 17:50:24,625 - block_trainer.py[357] - INFO: epoch 58 (409.977485s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018725   |   0.00019769   |   0.00024233   |   0.00040469   |   0.00130507   |
|         | (↓ 0.00000344) | (↓ 0.00000318) | (↓ 0.00000326) | (↓ 0.00000327) | (↓ 0.00000313) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00004174   |    0.00006279   |   0.00018613   |   0.00065241   |   0.00214676   |
|         | (↓ -0.00000028) | (↓ -0.00000003) | (↓ 0.00000192) | (↓ 0.00000196) | (↓ 0.00000377) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005518   |    0.00015041   |    0.00037926   |    0.00085226   |    0.00218163   |
|         | (↓ -0.00000341) | (↓ -0.00000327) | (↓ -0.00000278) | (↓ -0.00000227) | (↓ -0.00000110) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006543   |    0.00015948   |    0.00063792   |    0.00152201   |    0.00357492   |
|         | (↓ -0.00000342) | (↓ -0.00000359) | (↓ -0.00000362) | (↓ -0.00000426) | (↓ -0.00000471) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008355   |   0.00029579   |   0.00063871   |   0.00118095   |   0.00227841   |
|         | (↓ 0.00000150) | (↓ 0.00000160) | (↓ 0.00000128) | (↓ 0.00000058) | (↓ 0.00000208) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007491   |    0.00007972   |    0.00035416   |    0.00097269   |    0.00231234   |
|         | (↓ -0.00000082) | (↓ -0.00000079) | (↓ -0.00000106) | (↓ -0.00000120) | (↓ -0.00000050) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003471   |   0.00012842   |   0.00026389   |   0.00048474   |   0.00084728   |
|         | (↓ 0.00000105) | (↓ 0.00000106) | (↓ 0.00000116) | (↓ 0.00000094) | (↓ 0.00000151) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00993555   |   0.02160226   |   0.03817514   |   0.06224447   |   0.10007200   |
|         | (↓ 0.00003624) | (↓ 0.00003852) | (↓ 0.00008171) | (↓ 0.00009743) | (↓ 0.00023702) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 17:57:14,652 - block_trainer.py[357] - INFO: epoch 59 (410.027091s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00017442   |   0.00018442   |   0.00022867   |   0.00039015   |   0.00128930   |
|         | (↓ 0.00001282) | (↓ 0.00001327) | (↓ 0.00001366) | (↓ 0.00001454) | (↓ 0.00001576) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004135   |   0.00006272   |   0.00018571   |   0.00065240   |   0.00214423   |
|         | (↓ 0.00000039) | (↓ 0.00000007) | (↓ 0.00000042) | (↓ 0.00000001) | (↓ 0.00000253) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005255   |   0.00014789   |   0.00037645   |   0.00084954   |   0.00217883   |
|         | (↓ 0.00000263) | (↓ 0.00000253) | (↓ 0.00000282) | (↓ 0.00000272) | (↓ 0.00000279) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005967   |   0.00015346   |   0.00063192   |   0.00151593   |   0.00356695   |
|         | (↓ 0.00000576) | (↓ 0.00000603) | (↓ 0.00000600) | (↓ 0.00000608) | (↓ 0.00000797) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008173   |   0.00029358   |   0.00063626   |   0.00117881   |   0.00227686   |
|         | (↓ 0.00000182) | (↓ 0.00000221) | (↓ 0.00000245) | (↓ 0.00000214) | (↓ 0.00000154) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00006943   |   0.00007433   |   0.00034858   |   0.00096725   |   0.00230691   |
|         | (↓ 0.00000548) | (↓ 0.00000539) | (↓ 0.00000558) | (↓ 0.00000544) | (↓ 0.00000543) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003500   |    0.00012900   |    0.00026469   |    0.00048543   |    0.00084859   |
|         | (↓ -0.00000029) | (↓ -0.00000059) | (↓ -0.00000080) | (↓ -0.00000069) | (↓ -0.00000130) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-7 |   0.00993166   |   0.02157801   |   0.03814907   |   0.06220290   |    0.10011999   |
|         | (↓ 0.00000388) | (↓ 0.00002425) | (↓ 0.00002608) | (↓ 0.00004156) | (↓ -0.00004800) |
+---------+----------------+----------------+----------------+----------------+-----------------+

2023-06-30 18:04:04,690 - block_trainer.py[357] - INFO: epoch 60 (410.037006s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019019   |    0.00020091   |    0.00024558   |    0.00040758   |    0.00130685   |
|         | (↓ -0.00001577) | (↓ -0.00001649) | (↓ -0.00001691) | (↓ -0.00001743) | (↓ -0.00001754) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004104   |   0.00006194   |   0.00018472   |   0.00065161   |   0.00214399   |
|         | (↓ 0.00000031) | (↓ 0.00000078) | (↓ 0.00000099) | (↓ 0.00000080) | (↓ 0.00000024) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005521   |    0.00015060   |    0.00037916   |    0.00085272   |    0.00218197   |
|         | (↓ -0.00000265) | (↓ -0.00000271) | (↓ -0.00000271) | (↓ -0.00000319) | (↓ -0.00000314) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006320   |    0.00015685   |    0.00063498   |    0.00151874   |    0.00356876   |
|         | (↓ -0.00000353) | (↓ -0.00000339) | (↓ -0.00000306) | (↓ -0.00000281) | (↓ -0.00000181) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00008629   |    0.00029724   |    0.00063905   |    0.00118163   |    0.00228056   |
|         | (↓ -0.00000455) | (↓ -0.00000366) | (↓ -0.00000280) | (↓ -0.00000282) | (↓ -0.00000370) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007375   |    0.00007861   |    0.00035245   |    0.00097104   |    0.00231036   |
|         | (↓ -0.00000432) | (↓ -0.00000428) | (↓ -0.00000387) | (↓ -0.00000379) | (↓ -0.00000345) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-6 |    0.00003567   |    0.00012930   |    0.00026471   |   0.00048488   |    0.00084859   |
|         | (↓ -0.00000067) | (↓ -0.00000029) | (↓ -0.00000002) | (↓ 0.00000056) | (↓ -0.00000000) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-7 |   0.00988229   |   0.02152263   |   0.03812036   |    0.06220787   |    0.10012439   |
|         | (↓ 0.00004937) | (↓ 0.00005538) | (↓ 0.00002870) | (↓ -0.00000496) | (↓ -0.00000439) |
+---------+----------------+----------------+----------------+-----------------+-----------------+

2023-06-30 18:10:54,783 - block_trainer.py[357] - INFO: epoch 61 (410.093760s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019325   |    0.00020356   |    0.00024790   |    0.00040962   |    0.00130876   |
|         | (↓ -0.00000306) | (↓ -0.00000265) | (↓ -0.00000233) | (↓ -0.00000204) | (↓ -0.00000191) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004045   |   0.00006136   |   0.00018383   |   0.00065018   |   0.00214094   |
|         | (↓ 0.00000059) | (↓ 0.00000058) | (↓ 0.00000090) | (↓ 0.00000143) | (↓ 0.00000305) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-2 |    0.00005694   |    0.00015192   |    0.00037996   |    0.00085300   |   0.00218170   |
|         | (↓ -0.00000173) | (↓ -0.00000131) | (↓ -0.00000080) | (↓ -0.00000028) | (↓ 0.00000027) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-3 |   0.00006268   |   0.00015653   |   0.00063458   |   0.00151822   |    0.00356915   |
|         | (↓ 0.00000051) | (↓ 0.00000032) | (↓ 0.00000040) | (↓ 0.00000052) | (↓ -0.00000039) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008560   |   0.00029574   |   0.00063699   |   0.00117997   |   0.00227900   |
|         | (↓ 0.00000069) | (↓ 0.00000150) | (↓ 0.00000207) | (↓ 0.00000165) | (↓ 0.00000157) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007052   |   0.00007530   |   0.00034917   |   0.00096747   |   0.00230646   |
|         | (↓ 0.00000324) | (↓ 0.00000330) | (↓ 0.00000328) | (↓ 0.00000357) | (↓ 0.00000390) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003541   |   0.00012903   |   0.00026434   |   0.00048441   |   0.00084773   |
|         | (↓ 0.00000026) | (↓ 0.00000026) | (↓ 0.00000037) | (↓ 0.00000046) | (↓ 0.00000086) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.00981584   |   0.02146731   |   0.03804127   |   0.06203774   |   0.09991339   |
|         | (↓ 0.00006645) | (↓ 0.00005532) | (↓ 0.00007910) | (↓ 0.00017012) | (↓ 0.00021100) |
+---------+----------------+----------------+----------------+----------------+----------------+

2023-06-30 18:17:44,815 - block_trainer.py[357] - INFO: epoch 62 (410.031313s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018160   |   0.00019184   |   0.00023631   |   0.00039790   |   0.00129680   |
|         | (↓ 0.00001166) | (↓ 0.00001172) | (↓ 0.00001159) | (↓ 0.00001173) | (↓ 0.00001195) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003980   |   0.00006082   |   0.00018371   |   0.00065010   |   0.00213930   |
|         | (↓ 0.00000065) | (↓ 0.00000054) | (↓ 0.00000012) | (↓ 0.00000008) | (↓ 0.00000164) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005540   |   0.00015054   |   0.00037852   |   0.00085172   |   0.00218004   |
|         | (↓ 0.00000154) | (↓ 0.00000138) | (↓ 0.00000144) | (↓ 0.00000128) | (↓ 0.00000166) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006220   |   0.00015596   |   0.00063416   |   0.00151767   |   0.00356712   |
|         | (↓ 0.00000048) | (↓ 0.00000057) | (↓ 0.00000042) | (↓ 0.00000055) | (↓ 0.00000203) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008387   |   0.00029382   |   0.00063549   |   0.00117857   |   0.00227776   |
|         | (↓ 0.00000173) | (↓ 0.00000192) | (↓ 0.00000149) | (↓ 0.00000140) | (↓ 0.00000124) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-5 |   0.00006995   |   0.00007486   |    0.00034928   |    0.00096788   |    0.00230646   |
|         | (↓ 0.00000057) | (↓ 0.00000044) | (↓ -0.00000010) | (↓ -0.00000040) | (↓ -0.00000001) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+-----------------+-----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+-----------------+-----------------+----------------+
| block-6 |   0.00003526   |   0.00012897   |    0.00026447   |    0.00048443   |   0.00084752   |
|         | (↓ 0.00000015) | (↓ 0.00000007) | (↓ -0.00000013) | (↓ -0.00000002) | (↓ 0.00000021) |
+---------+----------------+----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+----------------+-----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
| block-7 |    0.00982718   |    0.02146960   |   0.03801407   |    0.06208092   |   0.09990013   |
|         | (↓ -0.00001134) | (↓ -0.00000230) | (↓ 0.00002720) | (↓ -0.00004318) | (↓ 0.00001325) |
+---------+-----------------+-----------------+----------------+-----------------+----------------+

2023-06-30 18:24:34,520 - block_trainer.py[357] - INFO: epoch 63 (409.705246s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019427   |    0.00020504   |    0.00024944   |    0.00041152   |    0.00130968   |
|         | (↓ -0.00001268) | (↓ -0.00001319) | (↓ -0.00001313) | (↓ -0.00001362) | (↓ -0.00001288) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00004391   |    0.00006497   |    0.00018724   |    0.00065314   |    0.00213981   |
|         | (↓ -0.00000411) | (↓ -0.00000415) | (↓ -0.00000353) | (↓ -0.00000304) | (↓ -0.00000052) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005690   |    0.00015197   |    0.00037994   |    0.00085357   |    0.00218199   |
|         | (↓ -0.00000150) | (↓ -0.00000143) | (↓ -0.00000142) | (↓ -0.00000185) | (↓ -0.00000194) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006395   |    0.00015770   |    0.00063569   |    0.00151875   |    0.00356757   |
|         | (↓ -0.00000175) | (↓ -0.00000173) | (↓ -0.00000152) | (↓ -0.00000108) | (↓ -0.00000045) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-4 |    0.00008560   |    0.00029519   |    0.00063680   |    0.00118019   |   0.00227750   |
|         | (↓ -0.00000174) | (↓ -0.00000137) | (↓ -0.00000130) | (↓ -0.00000161) | (↓ 0.00000026) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007122   |    0.00007604   |    0.00034978   |    0.00096789   |    0.00230666   |
|         | (↓ -0.00000127) | (↓ -0.00000118) | (↓ -0.00000050) | (↓ -0.00000001) | (↓ -0.00000020) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-6 |    0.00003567   |    0.00012930   |    0.00026452   |   0.00048427   |    0.00084777   |
|         | (↓ -0.00000040) | (↓ -0.00000033) | (↓ -0.00000005) | (↓ 0.00000016) | (↓ -0.00000025) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.00989335   |    0.02151182   |    0.03802233   |   0.06206467   |   0.09986866   |
|         | (↓ -0.00006616) | (↓ -0.00004221) | (↓ -0.00000826) | (↓ 0.00001625) | (↓ 0.00003148) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2023-06-30 18:31:24,400 - block_trainer.py[357] - INFO: epoch 64 (409.879310s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00018509   |   0.00019523   |   0.00023963   |   0.00040120   |   0.00129906   |
|         | (↓ 0.00000918) | (↓ 0.00000981) | (↓ 0.00000981) | (↓ 0.00001032) | (↓ 0.00001062) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00004216   |   0.00006337   |   0.00018635   |   0.00065188   |   0.00213845   |
|         | (↓ 0.00000175) | (↓ 0.00000160) | (↓ 0.00000088) | (↓ 0.00000126) | (↓ 0.00000137) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005677   |   0.00015187   |   0.00037959   |   0.00085291   |   0.00218099   |
|         | (↓ 0.00000012) | (↓ 0.00000010) | (↓ 0.00000035) | (↓ 0.00000066) | (↓ 0.00000100) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-3 |   0.00006365   |   0.00015762   |    0.00063608   |    0.00152034   |    0.00356992   |
|         | (↓ 0.00000030) | (↓ 0.00000008) | (↓ -0.00000039) | (↓ -0.00000159) | (↓ -0.00000235) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+-----------------+-----------------+-----------------+
|         |       0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00008575   |   0.00029488   |    0.00063687   |    0.00118086   |    0.00227927   |
|         | (↓ -0.00000015) | (↓ 0.00000031) | (↓ -0.00000007) | (↓ -0.00000067) | (↓ -0.00000177) |
+---------+-----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00006849   |   0.00007340   |   0.00034759   |   0.00096647   |   0.00230428   |
|         | (↓ 0.00000272) | (↓ 0.00000264) | (↓ 0.00000218) | (↓ 0.00000142) | (↓ 0.00000238) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003442   |   0.00012800   |   0.00026342   |   0.00048312   |   0.00084669   |
|         | (↓ 0.00000124) | (↓ 0.00000130) | (↓ 0.00000109) | (↓ 0.00000115) | (↓ 0.00000108) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-7 |   0.00981056   |   0.02143527   |   0.03797540   |   0.06203811   |    0.09987823   |
|         | (↓ 0.00008279) | (↓ 0.00007655) | (↓ 0.00004692) | (↓ 0.00002656) | (↓ -0.00000957) |
+---------+----------------+----------------+----------------+----------------+-----------------+

2023-06-30 18:31:24,438 - server_block_profiler.py[193] - INFO: raw block info: {"index": 0, "id": "block-0", "size": 315890, "FLOPs": 151781376.0, "param": 74112.0, "input_size": [64, 32, 32], "output_size": [64, 32, 32]}
2023-06-30 18:31:24,456 - server_block_profiler.py[193] - INFO: raw block info: {"index": 1, "id": "block-1", "size": 313409, "FLOPs": 151519232.0, "param": 73984.0, "input_size": [64, 32, 32], "output_size": [64, 32, 32]}
2023-06-30 18:31:24,473 - server_block_profiler.py[193] - INFO: raw block info: {"index": 2, "id": "block-2", "size": 899539, "FLOPs": 113377280.0, "param": 221440.0, "input_size": [64, 32, 32], "output_size": [128, 16, 16]}
2023-06-30 18:31:24,492 - server_block_profiler.py[193] - INFO: raw block info: {"index": 3, "id": "block-3", "size": 1200193, "FLOPs": 151257088.0, "param": 295424.0, "input_size": [128, 16, 16], "output_size": [128, 16, 16]}
2023-06-30 18:31:24,512 - server_block_profiler.py[193] - INFO: raw block info: {"index": 4, "id": "block-4", "size": 3555795, "FLOPs": 113311744.0, "param": 885248.0, "input_size": [128, 16, 16], "output_size": [256, 8, 8]}
2023-06-30 18:31:24,535 - server_block_profiler.py[193] - INFO: raw block info: {"index": 5, "id": "block-5", "size": 4743297, "FLOPs": 151126016.0, "param": 1180672.0, "input_size": [256, 8, 8], "output_size": [256, 8, 8]}
2023-06-30 18:31:24,573 - server_block_profiler.py[193] - INFO: raw block info: {"index": 6, "id": "block-6", "size": 14176723, "FLOPs": 113278976.0, "param": 3539968.0, "input_size": [256, 8, 8], "output_size": [512, 4, 4]}
2023-06-30 18:31:24,616 - server_block_profiler.py[193] - INFO: raw block info: {"index": 7, "id": "block-7", "size": 18907265, "FLOPs": 151060480.0, "param": 4720640.0, "input_size": [512, 4, 4], "output_size": [512, 4, 4]}
2023-06-30 18:31:30,131 - server_block_profiler.py[265] - INFO: profile blocks acc drop
2023-06-30 18:31:56,152 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:32:01,520 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:32:06,402 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:32:08,957 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:32:14,276 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:32:19,109 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:32:21,620 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:32:26,717 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:32:31,326 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:32:33,638 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:32:38,652 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:32:43,179 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:32:45,472 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:33:06,066 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:33:11,435 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2023-06-30 18:33:11,435 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:33:11,435 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2023-06-30 18:33:13,992 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:33:19,309 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2023-06-30 18:33:24,141 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2023-06-30 18:33:26,654 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:33:31,750 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2023-06-30 18:33:36,358 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2023-06-30 18:33:38,675 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:33:43,690 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2023-06-30 18:33:48,217 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2023-06-30 18:33:48,218 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:33:48,218 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:34:08,673 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:34:14,045 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2023-06-30 18:34:14,046 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:34:14,046 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2023-06-30 18:34:16,541 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:34:21,847 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2023-06-30 18:34:26,658 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2023-06-30 18:34:29,084 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:34:34,264 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2023-06-30 18:34:38,950 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2023-06-30 18:34:41,275 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:34:46,364 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2023-06-30 18:34:50,958 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2023-06-30 18:34:50,958 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:34:50,958 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:35:11,624 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:35:16,990 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2023-06-30 18:35:16,991 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:35:16,991 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2023-06-30 18:35:19,579 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:35:24,877 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2023-06-30 18:35:29,692 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2023-06-30 18:35:32,211 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:35:37,320 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2023-06-30 18:35:41,943 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2023-06-30 18:35:44,292 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:35:49,276 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2023-06-30 18:35:53,774 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2023-06-30 18:35:53,774 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:35:53,774 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:36:14,153 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:36:19,542 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2023-06-30 18:36:19,542 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:36:19,542 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2023-06-30 18:36:22,040 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:36:27,346 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2023-06-30 18:36:32,146 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2023-06-30 18:36:34,556 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:36:39,749 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2023-06-30 18:36:44,435 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2023-06-30 18:36:46,768 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:36:51,870 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2023-06-30 18:36:56,466 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2023-06-30 18:36:56,467 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:36:56,467 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:37:17,094 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:37:22,470 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2023-06-30 18:37:22,471 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:37:22,471 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2023-06-30 18:37:25,078 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:37:30,314 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2023-06-30 18:37:35,060 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2023-06-30 18:37:37,529 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:37:42,645 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2023-06-30 18:37:47,262 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2023-06-30 18:37:49,608 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:37:54,602 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2023-06-30 18:37:59,098 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2023-06-30 18:37:59,098 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:37:59,098 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:38:19,655 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:38:25,002 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2023-06-30 18:38:25,002 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:38:25,003 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2023-06-30 18:38:27,492 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:38:32,754 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2023-06-30 18:38:37,547 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2023-06-30 18:38:39,946 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:38:45,127 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2023-06-30 18:38:49,840 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2023-06-30 18:38:52,173 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:38:57,252 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2023-06-30 18:39:01,861 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2023-06-30 18:39:01,862 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:39:01,862 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:39:22,661 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:39:27,993 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2023-06-30 18:39:27,993 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2023-06-30 18:39:27,994 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2023-06-30 18:39:30,552 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:39:35,767 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2023-06-30 18:39:40,531 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2023-06-30 18:39:42,968 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:39:48,088 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2023-06-30 18:39:52,753 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2023-06-30 18:39:55,111 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2023-06-30 18:40:00,093 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2023-06-30 18:40:04,629 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2023-06-30 18:40:04,629 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2023-06-30 18:40:04,630 - server_block_profiler.py[308] - INFO: block block-0 (sparsity 0.0) acc drop: 0.00036664803822835285
2023-06-30 18:40:04,638 - server_block_profiler.py[336] - INFO: block block-0 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-30 18:40:04,639 - server_block_profiler.py[308] - INFO: block block-0 (sparsity 0.2) acc drop: 0.0008999903996785482
2023-06-30 18:40:04,646 - server_block_profiler.py[336] - INFO: block block-0 (sparsity 0.2) size drop: 55360B (0.053MB), FLOPs drop: 28.361M, param drop: 0.014M
2023-06-30 18:40:04,647 - server_block_profiler.py[308] - INFO: block block-0 (sparsity 0.4) acc drop: 0.00036664803822835285
2023-06-30 18:40:04,655 - server_block_profiler.py[336] - INFO: block block-0 (sparsity 0.4) size drop: 115520B (0.110MB), FLOPs drop: 59.085M, param drop: 0.029M
2023-06-30 18:40:04,655 - server_block_profiler.py[308] - INFO: block block-0 (sparsity 0.6) acc drop: 0.0011999805768330891
2023-06-30 18:40:04,663 - server_block_profiler.py[336] - INFO: block block-0 (sparsity 0.6) size drop: 175680B (0.168MB), FLOPs drop: 89.809M, param drop: 0.044M
2023-06-30 18:40:04,663 - server_block_profiler.py[308] - INFO: block block-0 (sparsity 0.8) acc drop: 0.004766643047332764
2023-06-30 18:40:04,672 - server_block_profiler.py[336] - INFO: block block-0 (sparsity 0.8) size drop: 235840B (0.225MB), FLOPs drop: 120.533M, param drop: 0.059M
2023-06-30 18:40:04,673 - server_block_profiler.py[308] - INFO: block block-1 (sparsity 0.0) acc drop: 0.0001333157221476237
2023-06-30 18:40:04,681 - server_block_profiler.py[336] - INFO: block block-1 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-30 18:40:04,681 - server_block_profiler.py[308] - INFO: block block-1 (sparsity 0.2) acc drop: 0.00023331244786580405
2023-06-30 18:40:04,690 - server_block_profiler.py[336] - INFO: block block-1 (sparsity 0.2) size drop: 55360B (0.053MB), FLOPs drop: 28.361M, param drop: 0.014M
2023-06-30 18:40:04,690 - server_block_profiler.py[308] - INFO: block block-1 (sparsity 0.4) acc drop: 0.0006000002225240072
2023-06-30 18:40:04,698 - server_block_profiler.py[336] - INFO: block block-1 (sparsity 0.4) size drop: 115520B (0.110MB), FLOPs drop: 59.085M, param drop: 0.029M
2023-06-30 18:40:04,698 - server_block_profiler.py[308] - INFO: block block-1 (sparsity 0.6) acc drop: 0.0021999875704447427
2023-06-30 18:40:04,707 - server_block_profiler.py[336] - INFO: block block-1 (sparsity 0.6) size drop: 175680B (0.168MB), FLOPs drop: 89.809M, param drop: 0.044M
2023-06-30 18:40:04,707 - server_block_profiler.py[308] - INFO: block block-1 (sparsity 0.8) acc drop: 0.005966663360595703
2023-06-30 18:40:04,716 - server_block_profiler.py[336] - INFO: block block-1 (sparsity 0.8) size drop: 235840B (0.225MB), FLOPs drop: 120.533M, param drop: 0.059M
2023-06-30 18:40:04,717 - server_block_profiler.py[308] - INFO: block block-2 (sparsity 0.0) acc drop: -0.00026667118072509766
2023-06-30 18:40:04,727 - server_block_profiler.py[336] - INFO: block block-2 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-30 18:40:04,727 - server_block_profiler.py[308] - INFO: block block-2 (sparsity 0.2) acc drop: -0.00033334891001383465
2023-06-30 18:40:04,738 - server_block_profiler.py[336] - INFO: block block-2 (sparsity 0.2) size drop: 173056B (0.165MB), FLOPs drop: 22.144M, param drop: 0.043M
2023-06-30 18:40:04,738 - server_block_profiler.py[308] - INFO: block block-2 (sparsity 0.4) acc drop: 0.0020333329836527505
2023-06-30 18:40:04,746 - server_block_profiler.py[336] - INFO: block block-2 (sparsity 0.4) size drop: 353280B (0.337MB), FLOPs drop: 45.174M, param drop: 0.088M
2023-06-30 18:40:04,746 - server_block_profiler.py[308] - INFO: block block-2 (sparsity 0.6) acc drop: 0.003533343474070231
2023-06-30 18:40:04,754 - server_block_profiler.py[336] - INFO: block block-2 (sparsity 0.6) size drop: 526336B (0.502MB), FLOPs drop: 67.318M, param drop: 0.131M
2023-06-30 18:40:04,754 - server_block_profiler.py[308] - INFO: block block-2 (sparsity 0.8) acc drop: 0.009766678015391031
2023-06-30 18:40:04,761 - server_block_profiler.py[336] - INFO: block block-2 (sparsity 0.8) size drop: 706560B (0.674MB), FLOPs drop: 90.348M, param drop: 0.176M
2023-06-30 18:40:04,761 - server_block_profiler.py[308] - INFO: block block-3 (sparsity 0.0) acc drop: 9.999672571818034e-05
2023-06-30 18:40:04,772 - server_block_profiler.py[336] - INFO: block block-3 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-30 18:40:04,772 - server_block_profiler.py[308] - INFO: block block-3 (sparsity 0.2) acc drop: 0.0003333290417989095
2023-06-30 18:40:04,781 - server_block_profiler.py[336] - INFO: block block-3 (sparsity 0.2) size drop: 230720B (0.220MB), FLOPs drop: 29.517M, param drop: 0.058M
2023-06-30 18:40:04,781 - server_block_profiler.py[308] - INFO: block block-3 (sparsity 0.4) acc drop: 0.0016333460807800293
2023-06-30 18:40:04,790 - server_block_profiler.py[336] - INFO: block block-3 (sparsity 0.4) size drop: 470848B (0.449MB), FLOPs drop: 60.214M, param drop: 0.118M
2023-06-30 18:40:04,790 - server_block_profiler.py[308] - INFO: block block-3 (sparsity 0.6) acc drop: 0.004433333873748779
2023-06-30 18:40:04,797 - server_block_profiler.py[336] - INFO: block block-3 (sparsity 0.6) size drop: 701504B (0.669MB), FLOPs drop: 89.731M, param drop: 0.175M
2023-06-30 18:40:04,798 - server_block_profiler.py[308] - INFO: block block-3 (sparsity 0.8) acc drop: 0.010033349196116129
2023-06-30 18:40:04,805 - server_block_profiler.py[336] - INFO: block block-3 (sparsity 0.8) size drop: 941632B (0.898MB), FLOPs drop: 120.429M, param drop: 0.235M
2023-06-30 18:40:04,805 - server_block_profiler.py[308] - INFO: block block-4 (sparsity 0.0) acc drop: 0.001466671625773112
2023-06-30 18:40:04,817 - server_block_profiler.py[336] - INFO: block block-4 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-30 18:40:04,817 - server_block_profiler.py[308] - INFO: block block-4 (sparsity 0.2) acc drop: 0.002866665522257487
2023-06-30 18:40:04,827 - server_block_profiler.py[336] - INFO: block block-4 (sparsity 0.2) size drop: 705792B (0.673MB), FLOPs drop: 22.574M, param drop: 0.176M
2023-06-30 18:40:04,828 - server_block_profiler.py[308] - INFO: block block-4 (sparsity 0.4) acc drop: 0.00593334436416626
2023-06-30 18:40:04,837 - server_block_profiler.py[336] - INFO: block block-4 (sparsity 0.4) size drop: 1411584B (1.346MB), FLOPs drop: 45.148M, param drop: 0.353M
2023-06-30 18:40:04,837 - server_block_profiler.py[308] - INFO: block block-4 (sparsity 0.6) acc drop: 0.009366671244303385
2023-06-30 18:40:04,845 - server_block_profiler.py[336] - INFO: block block-4 (sparsity 0.6) size drop: 2117376B (2.019MB), FLOPs drop: 67.721M, param drop: 0.529M
2023-06-30 18:40:04,845 - server_block_profiler.py[308] - INFO: block block-4 (sparsity 0.8) acc drop: 0.016933321952819824
2023-06-30 18:40:04,852 - server_block_profiler.py[336] - INFO: block block-4 (sparsity 0.8) size drop: 2823168B (2.692MB), FLOPs drop: 90.295M, param drop: 0.705M
2023-06-30 18:40:04,852 - server_block_profiler.py[308] - INFO: block block-5 (sparsity 0.0) acc drop: 0.0005666414896647135
2023-06-30 18:40:04,869 - server_block_profiler.py[336] - INFO: block block-5 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-30 18:40:04,870 - server_block_profiler.py[308] - INFO: block block-5 (sparsity 0.2) acc drop: 0.0006333192189534506
2023-06-30 18:40:04,886 - server_block_profiler.py[336] - INFO: block block-5 (sparsity 0.2) size drop: 940928B (0.897MB), FLOPs drop: 30.094M, param drop: 0.235M
2023-06-30 18:40:04,887 - server_block_profiler.py[308] - INFO: block block-5 (sparsity 0.4) acc drop: 0.0011666615804036458
2023-06-30 18:40:04,901 - server_block_profiler.py[336] - INFO: block block-5 (sparsity 0.4) size drop: 1881728B (1.795MB), FLOPs drop: 60.188M, param drop: 0.470M
2023-06-30 18:40:04,901 - server_block_profiler.py[308] - INFO: block block-5 (sparsity 0.6) acc drop: 0.00473332405090332
2023-06-30 18:40:04,915 - server_block_profiler.py[336] - INFO: block block-5 (sparsity 0.6) size drop: 2822528B (2.692MB), FLOPs drop: 90.282M, param drop: 0.705M
2023-06-30 18:40:04,915 - server_block_profiler.py[308] - INFO: block block-5 (sparsity 0.8) acc drop: 0.008966664473215738
2023-06-30 18:40:04,927 - server_block_profiler.py[336] - INFO: block block-5 (sparsity 0.8) size drop: 3763328B (3.589MB), FLOPs drop: 120.376M, param drop: 0.940M
2023-06-30 18:40:04,928 - server_block_profiler.py[308] - INFO: block block-6 (sparsity 0.0) acc drop: 9.999672571818034e-05
2023-06-30 18:40:04,974 - server_block_profiler.py[336] - INFO: block block-6 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-30 18:40:04,974 - server_block_profiler.py[308] - INFO: block block-6 (sparsity 0.2) acc drop: 0.00289998451868693
2023-06-30 18:40:05,003 - server_block_profiler.py[336] - INFO: block block-6 (sparsity 0.2) size drop: 2821632B (2.691MB), FLOPs drop: 22.567M, param drop: 0.705M
2023-06-30 18:40:05,003 - server_block_profiler.py[308] - INFO: block block-6 (sparsity 0.4) acc drop: 0.0042999982833862305
2023-06-30 18:40:05,025 - server_block_profiler.py[336] - INFO: block block-6 (sparsity 0.4) size drop: 5643264B (5.382MB), FLOPs drop: 45.135M, param drop: 1.410M
2023-06-30 18:40:05,025 - server_block_profiler.py[308] - INFO: block block-6 (sparsity 0.6) acc drop: 0.010933339595794678
2023-06-30 18:40:05,042 - server_block_profiler.py[336] - INFO: block block-6 (sparsity 0.6) size drop: 8492800B (8.099MB), FLOPs drop: 67.923M, param drop: 2.123M
2023-06-30 18:40:05,042 - server_block_profiler.py[308] - INFO: block block-6 (sparsity 0.8) acc drop: 0.018766661485036213
2023-06-30 18:40:05,053 - server_block_profiler.py[336] - INFO: block block-6 (sparsity 0.8) size drop: 11314432B (10.790MB), FLOPs drop: 90.490M, param drop: 2.828M
2023-06-30 18:40:05,054 - server_block_profiler.py[308] - INFO: block block-7 (sparsity 0.0) acc drop: 0.00036662817001342773
2023-06-30 18:40:05,096 - server_block_profiler.py[336] - INFO: block block-7 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2023-06-30 18:40:05,097 - server_block_profiler.py[308] - INFO: block block-7 (sparsity 0.2) acc drop: 0.0020999709765116372
2023-06-30 18:40:05,144 - server_block_profiler.py[336] - INFO: block block-7 (sparsity 0.2) size drop: 3761728B (3.587MB), FLOPs drop: 30.088M, param drop: 0.940M
2023-06-30 18:40:05,144 - server_block_profiler.py[308] - INFO: block block-7 (sparsity 0.4) acc drop: 0.003833293914794922
2023-06-30 18:40:05,184 - server_block_profiler.py[336] - INFO: block block-7 (sparsity 0.4) size drop: 7523392B (7.175MB), FLOPs drop: 60.175M, param drop: 1.880M
2023-06-30 18:40:05,185 - server_block_profiler.py[308] - INFO: block block-7 (sparsity 0.6) acc drop: 0.003999988238016765
2023-06-30 18:40:05,209 - server_block_profiler.py[336] - INFO: block block-7 (sparsity 0.6) size drop: 11322240B (10.798MB), FLOPs drop: 90.558M, param drop: 2.830M
2023-06-30 18:40:05,209 - server_block_profiler.py[308] - INFO: block block-7 (sparsity 0.8) acc drop: 0.014399965604146322
2023-06-30 18:40:05,223 - server_block_profiler.py[336] - INFO: block block-7 (sparsity 0.8) size drop: 15083904B (14.385MB), FLOPs drop: 120.645M, param drop: 3.770M
2023-06-30 18:40:05,493 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 0, "id": "block-0", "latency": 0.001051959999203682}
2023-06-30 18:40:05,651 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 1, "id": "block-1", "latency": 0.000771414720416069}
2023-06-30 18:40:05,758 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 2, "id": "block-2", "latency": 0.0005757785555720329}
2023-06-30 18:40:05,916 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 3, "id": "block-3", "latency": 0.0007744371181726457}
2023-06-30 18:40:06,039 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 4, "id": "block-4", "latency": 0.0007247222393751147}
2023-06-30 18:40:06,201 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 5, "id": "block-5", "latency": 0.0008076880019903185}
2023-06-30 18:40:06,395 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 6, "id": "block-6", "latency": 0.000993927678465843}
2023-06-30 18:40:06,653 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 7, "id": "block-7", "latency": 0.0013309273540973664}
2023-06-30 18:40:06,657 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2023-06-30 18:40:06,662 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.0) from file
2023-06-30 18:40:06,665 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:06,668 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2023-06-30 18:40:06,673 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:06,677 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2023-06-30 18:40:06,682 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.0) from file
2023-06-30 18:40:06,691 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.0) from file
2023-06-30 18:40:06,701 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.0) from file
2023-06-30 18:40:07,689 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-30 18:40:07,864 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.2) latency rel drop: -0.209% (0.001s -> 0.001s)
2023-06-30 18:40:08,043 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.4) latency rel drop: -1.778% (0.001s -> 0.001s)
2023-06-30 18:40:08,218 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.6) latency rel drop: 0.058% (0.001s -> 0.001s)
2023-06-30 18:40:08,395 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.8) latency rel drop: -0.560% (0.001s -> 0.001s)
2023-06-30 18:40:08,706 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-30 18:40:08,859 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.2) latency rel drop: 1.210% (0.001s -> 0.001s)
2023-06-30 18:40:09,015 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.4) latency rel drop: -0.346% (0.001s -> 0.001s)
2023-06-30 18:40:09,169 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.6) latency rel drop: 1.513% (0.001s -> 0.001s)
2023-06-30 18:40:09,324 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.8) latency rel drop: -0.046% (0.001s -> 0.001s)
2023-06-30 18:40:09,533 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-30 18:40:09,635 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.2) latency rel drop: 3.810% (0.001s -> 0.001s)
2023-06-30 18:40:09,733 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.4) latency rel drop: 9.144% (0.001s -> 0.001s)
2023-06-30 18:40:09,830 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.6) latency rel drop: 14.121% (0.001s -> 0.000s)
2023-06-30 18:40:09,937 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.8) latency rel drop: -1.144% (0.001s -> 0.001s)
2023-06-30 18:40:10,264 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-30 18:40:10,424 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.2) latency rel drop: 2.964% (0.001s -> 0.001s)
2023-06-30 18:40:10,590 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.4) latency rel drop: 0.450% (0.001s -> 0.001s)
2023-06-30 18:40:10,753 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.6) latency rel drop: 1.571% (0.001s -> 0.001s)
2023-06-30 18:40:10,915 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.8) latency rel drop: 2.580% (0.001s -> 0.001s)
2023-06-30 18:40:11,175 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-30 18:40:11,294 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.2) latency rel drop: 7.849% (0.001s -> 0.001s)
2023-06-30 18:40:11,406 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.4) latency rel drop: 16.352% (0.001s -> 0.001s)
2023-06-30 18:40:11,513 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.6) latency rel drop: 23.016% (0.001s -> 0.001s)
2023-06-30 18:40:11,614 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.8) latency rel drop: 32.313% (0.001s -> 0.000s)
2023-06-30 18:40:11,953 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-30 18:40:12,116 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.2) latency rel drop: 3.799% (0.001s -> 0.001s)
2023-06-30 18:40:12,277 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.4) latency rel drop: 3.787% (0.001s -> 0.001s)
2023-06-30 18:40:12,437 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.6) latency rel drop: 4.122% (0.001s -> 0.001s)
2023-06-30 18:40:12,600 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.8) latency rel drop: 3.144% (0.001s -> 0.001s)
2023-06-30 18:40:12,993 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-30 18:40:13,165 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.2) latency rel drop: 11.007% (0.001s -> 0.001s)
2023-06-30 18:40:13,314 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.4) latency rel drop: 21.041% (0.001s -> 0.001s)
2023-06-30 18:40:13,438 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.6) latency rel drop: 33.950% (0.001s -> 0.001s)
2023-06-30 18:40:13,545 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.8) latency rel drop: 42.767% (0.001s -> 0.001s)
2023-06-30 18:40:14,070 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2023-06-30 18:40:14,304 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.2) latency rel drop: 8.365% (0.001s -> 0.001s)
2023-06-30 18:40:14,515 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.4) latency rel drop: 16.915% (0.001s -> 0.001s)
2023-06-30 18:40:14,703 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.6) latency rel drop: 26.000% (0.001s -> 0.001s)
2023-06-30 18:40:14,871 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.8) latency rel drop: 35.100% (0.001s -> 0.001s)
2023-06-30 18:40:14,871 - optimal_runtime.py[21] - INFO: init adaptive model runtime
2023-06-30 18:40:14,925 - optimal_runtime.py[147] - INFO: load blocks metrics
2023-06-30 18:40:14,942 - optimal_runtime.py[176] - INFO: load model metrics
2023-06-30 18:40:14,947 - optimal_runtime.py[187] - INFO: load sparest blocks for initializing model
2023-06-30 18:40:14,947 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:14,951 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.8) from file
2023-06-30 18:40:14,954 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.8) from file
2023-06-30 18:40:14,957 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.8) from file
2023-06-30 18:40:14,960 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.8) from file
2023-06-30 18:40:14,963 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.8) from file
2023-06-30 18:40:14,967 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.8) from file
2023-06-30 18:40:14,970 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.8) from file
2023-06-30 18:40:14,975 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.8) from file
2023-06-30 18:40:15,104 - gen_series_legodnn_models.py[17] - INFO: min model size: 0.908MB, max model size: 43.886MB
2023-06-30 18:40:15,105 - gen_series_legodnn_models.py[28] - INFO: target model size: 0.908MB
2023-06-30 18:40:15,105 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 951737.0B (0.908MB), try to adapt blocks
2023-06-30 18:40:15,108 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:15,122 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009881600379943848
2023-06-30 18:40:15,122 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005925760082900525, 0.0004487039931118489, 0.0003466879948973656, 0.0004767999947071076, 0.000398912001401186, 0.0006416959911584854, 0.0005789760015904903, 0.0009789759777486325]
2023-06-30 18:40:15,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.785
2023-06-30 18:40:15,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.720
2023-06-30 18:40:15,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.680
2023-06-30 18:40:15,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.582
2023-06-30 18:40:15,122 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.230
2023-06-30 18:40:15,123 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.219
2023-06-30 18:40:15,123 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.983
2023-06-30 18:40:15,123 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.882
2023-06-30 18:40:15,124 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:15,124 - optimal_runtime.py[116] - INFO: avg ratio: 1.427733276262689
2023-06-30 18:40:15,124 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002932852548726262
2023-06-30 18:40:15,125 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058927 0.0004485  0.00034277 0.00048943 0.00058935 0.00066253
 0.00101161 0.00150843]
2023-06-30 18:40:15,128 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:15,237 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:15,237 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:15,239 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058927 0.0004485  0.00034277 0.00048943 0.00058935 0.00066253
 0.00101161 0.00150843]
2023-06-30 18:40:15,241 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:15,335 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:15,336 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:15,338 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058927 0.0004485  0.00034277 0.00048943 0.00058935 0.00066253
 0.00101161 0.00150843]
2023-06-30 18:40:15,340 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:15,467 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:15,468 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:15,473 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.6) from file
2023-06-30 18:40:15,473 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 270471040.0,
  'blocks_sparsity': [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.0017473118626040083,
  'esti_test_accuracy': 0.6833666960398356,
  'is_relaxed': True,
  'model_size': 9924493.0,
  'update_swap_mem_cost': 0,
  'update_swap_time_cost': 0.0050733089447021484}
2023-06-30 18:40:15,493 - gen_series_legodnn_models.py[28] - INFO: target model size: 1.342MB
2023-06-30 18:40:15,493 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 1406947.8686868688B (1.342MB), try to adapt blocks
2023-06-30 18:40:15,495 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:15,508 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009689087867736817
2023-06-30 18:40:15,508 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00062889601662755, 0.0004915839955210687, 0.00032707200199365614, 0.00046678399667143816, 0.0003992319963872433, 0.0006202559880912304, 0.0005942399874329567, 0.0009425280131399632]
2023-06-30 18:40:15,509 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.682
2023-06-30 18:40:15,509 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.546
2023-06-30 18:40:15,509 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.781
2023-06-30 18:40:15,509 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.616
2023-06-30 18:40:15,509 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.229
2023-06-30 18:40:15,509 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.261
2023-06-30 18:40:15,509 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.957
2023-06-30 18:40:15,509 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.916
2023-06-30 18:40:15,509 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5]),)
2023-06-30 18:40:15,510 - optimal_runtime.py[116] - INFO: avg ratio: 1.4667664861542342
2023-06-30 18:40:15,510 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028548042361993373
2023-06-30 18:40:15,510 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062539 0.00049913 0.00032337 0.00047914 0.00058982 0.00064039
 0.00103828 0.00145227]
2023-06-30 18:40:15,512 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:15,629 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:15,630 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:15,632 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062539 0.00049913 0.00032337 0.00047914 0.00058982 0.00064039
 0.00103828 0.00145227]
2023-06-30 18:40:15,634 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:15,740 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:15,740 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:15,742 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062539 0.00049913 0.00032337 0.00047914 0.00058982 0.00064039
 0.00103828 0.00145227]
2023-06-30 18:40:15,744 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:15,843 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:15,844 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:15,844 - gen_series_legodnn_models.py[28] - INFO: target model size: 1.776MB
2023-06-30 18:40:15,844 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 1862158.7373737374B (1.776MB), try to adapt blocks
2023-06-30 18:40:15,846 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:15,861 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01021132755279541
2023-06-30 18:40:15,861 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006430400013923646, 0.0005208000019192695, 0.0003272320032119752, 0.00044902399554848675, 0.0003846720010042191, 0.0006034559905529022, 0.0005573440007865429, 0.0009186239838600158]
2023-06-30 18:40:15,861 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.645
2023-06-30 18:40:15,861 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.459
2023-06-30 18:40:15,861 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.780
2023-06-30 18:40:15,861 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.680
2023-06-30 18:40:15,861 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.275
2023-06-30 18:40:15,861 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.296
2023-06-30 18:40:15,861 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.021
2023-06-30 18:40:15,862 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.940
2023-06-30 18:40:15,862 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5]),)
2023-06-30 18:40:15,862 - optimal_runtime.py[116] - INFO: avg ratio: 1.4188657111690888
2023-06-30 18:40:15,862 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029511821627841934
2023-06-30 18:40:15,863 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063946 0.0005288  0.00032353 0.00046091 0.00056831 0.00062305
 0.00097381 0.00141544]
2023-06-30 18:40:15,864 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:15,984 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:15,984 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:15,987 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063946 0.0005288  0.00032353 0.00046091 0.00056831 0.00062305
 0.00097381 0.00141544]
2023-06-30 18:40:15,988 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:16,101 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:16,102 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:16,104 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063946 0.0005288  0.00032353 0.00046091 0.00056831 0.00062305
 0.00097381 0.00141544]
2023-06-30 18:40:16,106 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:16,231 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:16,231 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:16,232 - gen_series_legodnn_models.py[28] - INFO: target model size: 2.210MB
2023-06-30 18:40:16,232 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 2317369.606060606B (2.210MB), try to adapt blocks
2023-06-30 18:40:16,233 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:16,246 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009339712142944335
2023-06-30 18:40:16,246 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005862400047481061, 0.0004538239985704422, 0.0003084479980170726, 0.00044278400763869284, 0.0003729279972612858, 0.0005886720083653927, 0.0005574720203876495, 0.0009187520109117031]
2023-06-30 18:40:16,246 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.804
2023-06-30 18:40:16,246 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.674
2023-06-30 18:40:16,246 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.888
2023-06-30 18:40:16,246 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.704
2023-06-30 18:40:16,246 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.315
2023-06-30 18:40:16,247 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.329
2023-06-30 18:40:16,247 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.020
2023-06-30 18:40:16,247 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.940
2023-06-30 18:40:16,247 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4, 5]),)
2023-06-30 18:40:16,247 - optimal_runtime.py[116] - INFO: avg ratio: 1.5055707621844485
2023-06-30 18:40:16,247 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0027812250897545866
2023-06-30 18:40:16,248 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058297 0.00046079 0.00030496 0.00045451 0.00055096 0.00060778
 0.00097404 0.00141563]
2023-06-30 18:40:16,249 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:16,362 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:16,363 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:16,365 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058297 0.00046079 0.00030496 0.00045451 0.00055096 0.00060778
 0.00097404 0.00141563]
2023-06-30 18:40:16,367 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:16,483 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:16,484 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:16,490 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058297 0.00046079 0.00030496 0.00045451 0.00055096 0.00060778
 0.00097404 0.00141563]
2023-06-30 18:40:16,494 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:16,614 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:16,615 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:16,615 - gen_series_legodnn_models.py[28] - INFO: target model size: 2.644MB
2023-06-30 18:40:16,615 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 2772580.474747475B (2.644MB), try to adapt blocks
2023-06-30 18:40:16,617 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:16,632 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011030400276184082
2023-06-30 18:40:16,632 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006572479978203773, 0.0004492800012230873, 0.00042150399833917624, 0.0004716159999370575, 0.00037686400860548024, 0.0006496000178158282, 0.0006160640008747578, 0.0009877760075032711]
2023-06-30 18:40:16,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.610
2023-06-30 18:40:16,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.691
2023-06-30 18:40:16,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.382
2023-06-30 18:40:16,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.600
2023-06-30 18:40:16,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.302
2023-06-30 18:40:16,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.204
2023-06-30 18:40:16,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.923
2023-06-30 18:40:16,633 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.874
2023-06-30 18:40:16,634 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-30 18:40:16,634 - optimal_runtime.py[116] - INFO: avg ratio: 1.4193595319731505
2023-06-30 18:40:16,634 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029501553932337523
2023-06-30 18:40:16,634 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065359 0.00045618 0.00041674 0.0004841  0.00055678 0.00067069
 0.00107641 0.00152199]
2023-06-30 18:40:16,636 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:16,749 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:16,749 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:16,751 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065359 0.00045618 0.00041674 0.0004841  0.00055678 0.00067069
 0.00107641 0.00152199]
2023-06-30 18:40:16,752 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:16,854 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:16,855 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:16,864 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065359 0.00045618 0.00041674 0.0004841  0.00055678 0.00067069
 0.00107641 0.00152199]
2023-06-30 18:40:16,869 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:16,998 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:16,998 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:16,999 - gen_series_legodnn_models.py[28] - INFO: target model size: 3.078MB
2023-06-30 18:40:16,999 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 3227791.3434343436B (3.078MB), try to adapt blocks
2023-06-30 18:40:17,000 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:17,013 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009393024444580077
2023-06-30 18:40:17,013 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005960320085287095, 0.00043497600406408306, 0.0003090879954397678, 0.00043977600336074827, 0.0003715200014412403, 0.00059340800344944, 0.0005546239949762821, 0.0009859840273857116]
2023-06-30 18:40:17,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.775
2023-06-30 18:40:17,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.747
2023-06-30 18:40:17,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.884
2023-06-30 18:40:17,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.716
2023-06-30 18:40:17,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.320
2023-06-30 18:40:17,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.318
2023-06-30 18:40:17,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.026
2023-06-30 18:40:17,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.876
2023-06-30 18:40:17,014 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5]),)
2023-06-30 18:40:17,015 - optimal_runtime.py[116] - INFO: avg ratio: 1.575137435189043
2023-06-30 18:40:17,015 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0026583909979168096
2023-06-30 18:40:17,015 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059271 0.00044166 0.00030559 0.00045142 0.00054888 0.00061267
 0.00096906 0.00151923]
2023-06-30 18:40:17,017 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:17,139 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:17,139 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:17,142 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059271 0.00044166 0.00030559 0.00045142 0.00054888 0.00061267
 0.00096906 0.00151923]
2023-06-30 18:40:17,145 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:17,256 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:17,257 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:17,259 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059271 0.00044166 0.00030559 0.00045142 0.00054888 0.00061267
 0.00096906 0.00151923]
2023-06-30 18:40:17,260 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:17,362 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:17,362 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:17,363 - gen_series_legodnn_models.py[28] - INFO: target model size: 3.512MB
2023-06-30 18:40:17,363 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 3683002.212121212B (3.512MB), try to adapt blocks
2023-06-30 18:40:17,365 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:17,379 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010217472076416016
2023-06-30 18:40:17,379 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006526080220937728, 0.000472704004496336, 0.000325472004711628, 0.00047904000058770173, 0.00038684800267219544, 0.0006383360065519809, 0.000569504003971815, 0.0009324160069227219]
2023-06-30 18:40:17,379 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.621
2023-06-30 18:40:17,379 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.607
2023-06-30 18:40:17,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.789
2023-06-30 18:40:17,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.575
2023-06-30 18:40:17,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.268
2023-06-30 18:40:17,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.226
2023-06-30 18:40:17,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.999
2023-06-30 18:40:17,380 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.926
2023-06-30 18:40:17,380 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5]),)
2023-06-30 18:40:17,380 - optimal_runtime.py[116] - INFO: avg ratio: 1.4593405125441423
2023-06-30 18:40:17,380 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028693311411524766
2023-06-30 18:40:17,381 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064897 0.00047996 0.00032179 0.00049173 0.00057153 0.00065906
 0.00099506 0.00143669]
2023-06-30 18:40:17,383 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:17,500 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:17,500 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:17,502 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064897 0.00047996 0.00032179 0.00049173 0.00057153 0.00065906
 0.00099506 0.00143669]
2023-06-30 18:40:17,504 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:17,605 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:17,605 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:17,608 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064897 0.00047996 0.00032179 0.00049173 0.00057153 0.00065906
 0.00099506 0.00143669]
2023-06-30 18:40:17,609 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:17,737 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:17,738 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:17,738 - gen_series_legodnn_models.py[28] - INFO: target model size: 3.947MB
2023-06-30 18:40:17,738 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 4138213.0808080807B (3.947MB), try to adapt blocks
2023-06-30 18:40:17,740 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:17,753 - optimal_runtime.py[77] - INFO: infer time of current model: 0.00975814437866211
2023-06-30 18:40:17,753 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006016960106790067, 0.0004654080085456371, 0.00032198400795459747, 0.00046515199914574625, 0.00038211200386285783, 0.0006107200011610985, 0.0005656320042908192, 0.0009372159726917742]
2023-06-30 18:40:17,753 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.758
2023-06-30 18:40:17,753 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.632
2023-06-30 18:40:17,754 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.809
2023-06-30 18:40:17,754 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.622
2023-06-30 18:40:17,754 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.284
2023-06-30 18:40:17,754 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.281
2023-06-30 18:40:17,754 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.006
2023-06-30 18:40:17,754 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.922
2023-06-30 18:40:17,754 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4, 5]),)
2023-06-30 18:40:17,754 - optimal_runtime.py[116] - INFO: avg ratio: 1.454771958611112
2023-06-30 18:40:17,754 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028783419651462203
2023-06-30 18:40:17,755 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059834 0.00047256 0.00031834 0.00047747 0.00056453 0.00063055
 0.00098829 0.00144408]
2023-06-30 18:40:17,756 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:17,865 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:17,865 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:17,868 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059834 0.00047256 0.00031834 0.00047747 0.00056453 0.00063055
 0.00098829 0.00144408]
2023-06-30 18:40:17,869 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:17,989 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:17,989 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:17,995 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059834 0.00047256 0.00031834 0.00047747 0.00056453 0.00063055
 0.00098829 0.00144408]
2023-06-30 18:40:17,999 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:18,118 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:18,119 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:18,119 - gen_series_legodnn_models.py[28] - INFO: target model size: 4.381MB
2023-06-30 18:40:18,119 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 4593423.94949495B (4.381MB), try to adapt blocks
2023-06-30 18:40:18,121 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:18,137 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011124159812927246
2023-06-30 18:40:18,137 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007004160024225712, 0.00048707200586795804, 0.0003541439995169639, 0.0004463999904692174, 0.0004187200032174587, 0.0006553599946200848, 0.0006466560028493405, 0.0009840640127658845]
2023-06-30 18:40:18,137 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.510
2023-06-30 18:40:18,137 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.560
2023-06-30 18:40:18,137 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.644
2023-06-30 18:40:18,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.690
2023-06-30 18:40:18,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.172
2023-06-30 18:40:18,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.194
2023-06-30 18:40:18,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.880
2023-06-30 18:40:18,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.878
2023-06-30 18:40:18,138 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5]),)
2023-06-30 18:40:18,139 - optimal_runtime.py[116] - INFO: avg ratio: 1.3588388118268167
2023-06-30 18:40:18,139 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030815510579646275
2023-06-30 18:40:18,139 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00069651 0.00049455 0.00035014 0.00045822 0.00061861 0.00067664
 0.00112986 0.00151627]
2023-06-30 18:40:18,141 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:18,251 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:18,252 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:18,254 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00069651 0.00049455 0.00035014 0.00045822 0.00061861 0.00067664
 0.00112986 0.00151627]
2023-06-30 18:40:18,255 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:18,358 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:18,359 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:18,365 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00069651 0.00049455 0.00035014 0.00045822 0.00061861 0.00067664
 0.00112986 0.00151627]
2023-06-30 18:40:18,369 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:18,502 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:18,502 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:18,502 - gen_series_legodnn_models.py[28] - INFO: target model size: 4.815MB
2023-06-30 18:40:18,503 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 5048634.818181818B (4.815MB), try to adapt blocks
2023-06-30 18:40:18,504 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:18,518 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009759807586669922
2023-06-30 18:40:18,518 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005928319990634919, 0.0004544959887862205, 0.00031612800806760794, 0.0004514879994094372, 0.00038697599619627, 0.000614783998578787, 0.0005761919990181923, 0.0009325120374560356]
2023-06-30 18:40:18,518 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.784
2023-06-30 18:40:18,518 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.672
2023-06-30 18:40:18,518 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.842
2023-06-30 18:40:18,518 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.671
2023-06-30 18:40:18,518 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.268
2023-06-30 18:40:18,518 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.272
2023-06-30 18:40:18,518 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-30 18:40:18,518 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.926
2023-06-30 18:40:18,519 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4, 5]),)
2023-06-30 18:40:18,519 - optimal_runtime.py[116] - INFO: avg ratio: 1.4706912664939682
2023-06-30 18:40:18,519 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028471857238743575
2023-06-30 18:40:18,519 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058953 0.00046148 0.00031255 0.00046344 0.00057172 0.00063474
 0.00100674 0.00143684]
2023-06-30 18:40:18,521 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:18,628 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:18,628 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:18,630 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058953 0.00046148 0.00031255 0.00046344 0.00057172 0.00063474
 0.00100674 0.00143684]
2023-06-30 18:40:18,632 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:18,754 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:18,755 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:18,760 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058953 0.00046148 0.00031255 0.00046344 0.00057172 0.00063474
 0.00100674 0.00143684]
2023-06-30 18:40:18,764 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:18,889 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:18,890 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:18,890 - gen_series_legodnn_models.py[28] - INFO: target model size: 5.249MB
2023-06-30 18:40:18,890 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 5503845.686868687B (5.249MB), try to adapt blocks
2023-06-30 18:40:18,892 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:18,908 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011883872032165527
2023-06-30 18:40:18,908 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000801120012998581, 0.00048793599382042883, 0.000327808003872633, 0.0006468160003423691, 0.0003890880011022091, 0.0006596799902617931, 0.0005819200016558171, 0.0010005119852721691]
2023-06-30 18:40:18,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.320
2023-06-30 18:40:18,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.557
2023-06-30 18:40:18,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.777
2023-06-30 18:40:18,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.166
2023-06-30 18:40:18,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.261
2023-06-30 18:40:18,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.186
2023-06-30 18:40:18,909 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.978
2023-06-30 18:40:18,909 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.863
2023-06-30 18:40:18,909 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-30 18:40:18,909 - optimal_runtime.py[116] - INFO: avg ratio: 1.2333758497237548
2023-06-30 18:40:18,909 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003395016352173736
2023-06-30 18:40:18,910 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00079666 0.00049543 0.0003241  0.00066394 0.00057484 0.0006811
 0.00101675 0.00154161]
2023-06-30 18:40:18,911 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:19,020 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:19,020 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:19,022 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00079666 0.00049543 0.0003241  0.00066394 0.00057484 0.0006811
 0.00101675 0.00154161]
2023-06-30 18:40:19,024 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:19,125 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:19,125 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:19,127 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00079666 0.00049543 0.0003241  0.00066394 0.00057484 0.0006811
 0.00101675 0.00154161]
2023-06-30 18:40:19,129 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:19,262 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:19,263 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:19,264 - gen_series_legodnn_models.py[28] - INFO: target model size: 5.683MB
2023-06-30 18:40:19,264 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 5959056.555555556B (5.683MB), try to adapt blocks
2023-06-30 18:40:19,268 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:19,295 - optimal_runtime.py[77] - INFO: infer time of current model: 0.018509632110595704
2023-06-30 18:40:19,295 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0011957439929246904, 0.0008941119983792306, 0.0005913920029997825, 0.0008400319963693618, 0.0006180480122566223, 0.0010570240020751952, 0.0008027839809656144, 0.001143712006509304]
2023-06-30 18:40:19,295 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.885
2023-06-30 18:40:19,295 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.850
2023-06-30 18:40:19,295 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.985
2023-06-30 18:40:19,296 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.898
2023-06-30 18:40:19,296 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.794
2023-06-30 18:40:19,296 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.740
2023-06-30 18:40:19,296 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.709
2023-06-30 18:40:19,296 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.755
2023-06-30 18:40:19,297 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5, 7]),)
2023-06-30 18:40:19,297 - optimal_runtime.py[116] - INFO: avg ratio: 0.8202599342079596
2023-06-30 18:40:19,297 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.005104883224890898
2023-06-30 18:40:19,298 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00118908 0.00090785 0.0005847  0.00086228 0.0009131  0.00109134
 0.00140265 0.00176226]
2023-06-30 18:40:19,300 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:19,419 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:19,419 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:19,422 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00118908 0.00090785 0.0005847  0.00086228 0.0009131  0.00109134
 0.00140265 0.00176226]
2023-06-30 18:40:19,423 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:19,532 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:19,533 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:19,535 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00118908 0.00090785 0.0005847  0.00086228 0.0009131  0.00109134
 0.00140265 0.00176226]
2023-06-30 18:40:19,536 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:19,641 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:19,642 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:19,642 - gen_series_legodnn_models.py[28] - INFO: target model size: 6.117MB
2023-06-30 18:40:19,642 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 6414267.424242424B (6.117MB), try to adapt blocks
2023-06-30 18:40:19,644 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:19,659 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01098419189453125
2023-06-30 18:40:19,659 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000630336008965969, 0.0004794880114495755, 0.000331712007522583, 0.0004831680059432984, 0.00040108800306916235, 0.0006383679956197739, 0.0005743039920926094, 0.0009849279895424842]
2023-06-30 18:40:19,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.678
2023-06-30 18:40:19,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.584
2023-06-30 18:40:19,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.756
2023-06-30 18:40:19,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.561
2023-06-30 18:40:19,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.223
2023-06-30 18:40:19,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.225
2023-06-30 18:40:19,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.991
2023-06-30 18:40:19,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.877
2023-06-30 18:40:19,660 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4, 5]),)
2023-06-30 18:40:19,660 - optimal_runtime.py[116] - INFO: avg ratio: 1.3986148199441075
2023-06-30 18:40:19,660 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029939130620363808
2023-06-30 18:40:19,661 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062682 0.00048685 0.00032796 0.00049596 0.00059256 0.00065909
 0.00100345 0.0015176 ]
2023-06-30 18:40:19,662 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:19,782 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:19,783 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:19,785 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062682 0.00048685 0.00032796 0.00049596 0.00059256 0.00065909
 0.00100345 0.0015176 ]
2023-06-30 18:40:19,786 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:19,890 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:19,890 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:19,892 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062682 0.00048685 0.00032796 0.00049596 0.00059256 0.00065909
 0.00100345 0.0015176 ]
2023-06-30 18:40:19,894 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:20,021 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:20,023 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:20,023 - gen_series_legodnn_models.py[28] - INFO: target model size: 6.551MB
2023-06-30 18:40:20,023 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 6869478.292929293B (6.551MB), try to adapt blocks
2023-06-30 18:40:20,028 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:20,054 - optimal_runtime.py[77] - INFO: infer time of current model: 0.018089536666870118
2023-06-30 18:40:20,054 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0012167680114507674, 0.0008961280062794685, 0.0005922560021281243, 0.0008977600038051607, 0.0005265920087695121, 0.0010511999949812888, 0.0007191039994359017, 0.0010928639844059943]
2023-06-30 18:40:20,054 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.869
2023-06-30 18:40:20,054 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.848
2023-06-30 18:40:20,054 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.983
2023-06-30 18:40:20,054 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.840
2023-06-30 18:40:20,055 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.932
2023-06-30 18:40:20,055 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.744
2023-06-30 18:40:20,055 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.791
2023-06-30 18:40:20,055 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.790
2023-06-30 18:40:20,055 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 6, 7]),)
2023-06-30 18:40:20,055 - optimal_runtime.py[116] - INFO: avg ratio: 0.82780569596984
2023-06-30 18:40:20,056 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.005058350285066031
2023-06-30 18:40:20,056 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00120999 0.00090989 0.00058556 0.00092153 0.00077798 0.00108533
 0.00125645 0.00168391]
2023-06-30 18:40:20,058 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:20,163 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:20,163 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:20,166 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00120999 0.00090989 0.00058556 0.00092153 0.00077798 0.00108533
 0.00125645 0.00168391]
2023-06-30 18:40:20,168 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:20,285 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:20,285 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:20,287 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00120999 0.00090989 0.00058556 0.00092153 0.00077798 0.00108533
 0.00125645 0.00168391]
2023-06-30 18:40:20,289 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:20,394 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:20,395 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:20,395 - gen_series_legodnn_models.py[28] - INFO: target model size: 6.985MB
2023-06-30 18:40:20,395 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 7324689.161616161B (6.985MB), try to adapt blocks
2023-06-30 18:40:20,397 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:20,413 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010971199989318848
2023-06-30 18:40:20,414 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006655359901487827, 0.0005225279964506626, 0.00031932799890637396, 0.00045689600706100465, 0.0004033279940485955, 0.0006142080053687096, 0.0005732159912586213, 0.0010150080136954785]
2023-06-30 18:40:20,414 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.589
2023-06-30 18:40:20,414 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.454
2023-06-30 18:40:20,414 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.824
2023-06-30 18:40:20,414 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.651
2023-06-30 18:40:20,414 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.216
2023-06-30 18:40:20,414 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.274
2023-06-30 18:40:20,414 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.992
2023-06-30 18:40:20,415 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.851
2023-06-30 18:40:20,415 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5]),)
2023-06-30 18:40:20,415 - optimal_runtime.py[116] - INFO: avg ratio: 1.4369247799728453
2023-06-30 18:40:20,415 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00291409211988637
2023-06-30 18:40:20,416 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00066183 0.00053055 0.00031572 0.00046899 0.00059587 0.00063415
 0.00100154 0.00156395]
2023-06-30 18:40:20,418 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:20,536 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:20,536 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:20,539 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00066183 0.00053055 0.00031572 0.00046899 0.00059587 0.00063415
 0.00100154 0.00156395]
2023-06-30 18:40:20,540 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:20,644 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:20,644 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:20,647 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00066183 0.00053055 0.00031572 0.00046899 0.00059587 0.00063415
 0.00100154 0.00156395]
2023-06-30 18:40:20,649 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:20,772 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:20,772 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:20,773 - gen_series_legodnn_models.py[28] - INFO: target model size: 7.419MB
2023-06-30 18:40:20,773 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 7779900.03030303B (7.419MB), try to adapt blocks
2023-06-30 18:40:20,775 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:20,788 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009813119888305664
2023-06-30 18:40:20,788 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006279040053486824, 0.0004851519949734211, 0.00032972799614071845, 0.00046003199368715287, 0.0003893439993262291, 0.000619039986282587, 0.00056623999401927, 0.0009407359771430493]
2023-06-30 18:40:20,788 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.685
2023-06-30 18:40:20,788 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.566
2023-06-30 18:40:20,789 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.766
2023-06-30 18:40:20,789 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.640
2023-06-30 18:40:20,789 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.260
2023-06-30 18:40:20,789 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.264
2023-06-30 18:40:20,789 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.005
2023-06-30 18:40:20,789 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.918
2023-06-30 18:40:20,789 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5]),)
2023-06-30 18:40:20,789 - optimal_runtime.py[116] - INFO: avg ratio: 1.4828770055654665
2023-06-30 18:40:20,789 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028237885964059214
2023-06-30 18:40:20,790 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006244  0.0004926  0.000326   0.00047221 0.00057521 0.00063914
 0.00098936 0.00144951]
2023-06-30 18:40:20,791 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:20,901 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:20,902 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:20,904 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006244  0.0004926  0.000326   0.00047221 0.00057521 0.00063914
 0.00098936 0.00144951]
2023-06-30 18:40:20,906 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:21,023 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:21,023 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:21,025 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006244  0.0004926  0.000326   0.00047221 0.00057521 0.00063914
 0.00098936 0.00144951]
2023-06-30 18:40:21,027 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:21,132 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:21,133 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:21,133 - gen_series_legodnn_models.py[28] - INFO: target model size: 7.854MB
2023-06-30 18:40:21,133 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 8235110.898989899B (7.854MB), try to adapt blocks
2023-06-30 18:40:21,135 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:21,150 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011093952178955079
2023-06-30 18:40:21,150 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006889280043542385, 0.0004919680021703243, 0.0003383359983563423, 0.00046918399259448043, 0.0004461119994521141, 0.0006403200067579746, 0.0005683520175516606, 0.0010200320146977902]
2023-06-30 18:40:21,150 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.536
2023-06-30 18:40:21,151 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.544
2023-06-30 18:40:21,151 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.721
2023-06-30 18:40:21,151 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.608
2023-06-30 18:40:21,151 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.100
2023-06-30 18:40:21,151 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.222
2023-06-30 18:40:21,151 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.001
2023-06-30 18:40:21,151 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.847
2023-06-30 18:40:21,151 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5]),)
2023-06-30 18:40:21,151 - optimal_runtime.py[116] - INFO: avg ratio: 1.4018288290723488
2023-06-30 18:40:21,152 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002987048840306176
2023-06-30 18:40:21,152 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00068509 0.00049952 0.00033451 0.00048161 0.00065908 0.00066111
 0.00099305 0.00157169]
2023-06-30 18:40:21,154 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:21,274 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:21,274 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:21,276 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00068509 0.00049952 0.00033451 0.00048161 0.00065908 0.00066111
 0.00099305 0.00157169]
2023-06-30 18:40:21,278 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:21,387 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:21,387 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:21,390 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00068509 0.00049952 0.00033451 0.00048161 0.00065908 0.00066111
 0.00099305 0.00157169]
2023-06-30 18:40:21,391 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:21,518 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:21,518 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:21,519 - gen_series_legodnn_models.py[28] - INFO: target model size: 8.288MB
2023-06-30 18:40:21,519 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 8690321.767676767B (8.288MB), try to adapt blocks
2023-06-30 18:40:21,521 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:21,534 - optimal_runtime.py[77] - INFO: infer time of current model: 0.00963276767730713
2023-06-30 18:40:21,534 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005995520055294037, 0.0004570559971034527, 0.00031334399804472927, 0.000450048003345728, 0.00038076799362897875, 0.0006075520142912864, 0.0005574399940669536, 0.0009337279796600343]
2023-06-30 18:40:21,534 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.764
2023-06-30 18:40:21,534 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.662
2023-06-30 18:40:21,534 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.859
2023-06-30 18:40:21,534 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.676
2023-06-30 18:40:21,534 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.288
2023-06-30 18:40:21,534 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.288
2023-06-30 18:40:21,534 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.020
2023-06-30 18:40:21,534 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.925
2023-06-30 18:40:21,535 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5]),)
2023-06-30 18:40:21,535 - optimal_runtime.py[116] - INFO: avg ratio: 1.5357946280193358
2023-06-30 18:40:21,535 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0027264916166483723
2023-06-30 18:40:21,535 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059621 0.00046408 0.0003098  0.00046197 0.00056254 0.00062728
 0.00097398 0.00143871]
2023-06-30 18:40:21,537 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:21,641 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:21,642 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:21,644 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059621 0.00046408 0.0003098  0.00046197 0.00056254 0.00062728
 0.00097398 0.00143871]
2023-06-30 18:40:21,646 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:21,767 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:21,768 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:21,770 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059621 0.00046408 0.0003098  0.00046197 0.00056254 0.00062728
 0.00097398 0.00143871]
2023-06-30 18:40:21,771 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:21,878 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:21,879 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:21,879 - gen_series_legodnn_models.py[28] - INFO: target model size: 8.722MB
2023-06-30 18:40:21,879 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 9145532.636363637B (8.722MB), try to adapt blocks
2023-06-30 18:40:21,881 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:21,895 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010489055633544922
2023-06-30 18:40:21,896 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007341760098934173, 0.0004742720015347004, 0.0003437439948320389, 0.0004920320026576519, 0.0003778879977762699, 0.0006309759914875031, 0.0005775039941072464, 0.0009418879896402358]
2023-06-30 18:40:21,896 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.441
2023-06-30 18:40:21,896 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.602
2023-06-30 18:40:21,896 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.694
2023-06-30 18:40:21,896 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.533
2023-06-30 18:40:21,896 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.298
2023-06-30 18:40:21,896 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.240
2023-06-30 18:40:21,896 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.985
2023-06-30 18:40:21,896 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.917
2023-06-30 18:40:21,897 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5]),)
2023-06-30 18:40:21,897 - optimal_runtime.py[116] - INFO: avg ratio: 1.4228145363835623
2023-06-30 18:40:21,897 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029429915643337957
2023-06-30 18:40:21,898 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00073008 0.00048156 0.00033986 0.00050506 0.00055829 0.00065146
 0.00100904 0.00145128]
2023-06-30 18:40:21,900 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:22,024 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:22,024 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:22,026 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00073008 0.00048156 0.00033986 0.00050506 0.00055829 0.00065146
 0.00100904 0.00145128]
2023-06-30 18:40:22,028 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:22,131 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:22,132 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:22,134 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00073008 0.00048156 0.00033986 0.00050506 0.00055829 0.00065146
 0.00100904 0.00145128]
2023-06-30 18:40:22,136 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:22,264 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:22,265 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:22,265 - gen_series_legodnn_models.py[28] - INFO: target model size: 9.156MB
2023-06-30 18:40:22,265 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 9600743.505050505B (9.156MB), try to adapt blocks
2023-06-30 18:40:22,267 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:22,280 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009605567932128906
2023-06-30 18:40:22,280 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005906880013644695, 0.00045238399878144264, 0.00031535999849438665, 0.0004450880028307438, 0.00037987200915813444, 0.0006426240094006062, 0.0005680640116333961, 0.0009383359998464584]
2023-06-30 18:40:22,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.791
2023-06-30 18:40:22,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.679
2023-06-30 18:40:22,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.847
2023-06-30 18:40:22,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.695
2023-06-30 18:40:22,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.291
2023-06-30 18:40:22,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.217
2023-06-30 18:40:22,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.001
2023-06-30 18:40:22,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.921
2023-06-30 18:40:22,281 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4, 5]),)
2023-06-30 18:40:22,281 - optimal_runtime.py[116] - INFO: avg ratio: 1.47079426686693
2023-06-30 18:40:22,281 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028469863341989573
2023-06-30 18:40:22,281 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005874  0.00045933 0.00031179 0.00045687 0.00056122 0.00066349
 0.00099254 0.00144581]
2023-06-30 18:40:22,283 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:22,396 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:22,396 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2023-06-30 18:40:22,399 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005874  0.00045933 0.00031179 0.00045687 0.00056122 0.00066349
 0.00099254 0.00144581]
2023-06-30 18:40:22,400 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:22,514 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:22,514 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2023-06-30 18:40:22,516 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005874  0.00045933 0.00031179 0.00045687 0.00056122 0.00066349
 0.00099254 0.00144581]
2023-06-30 18:40:22,518 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:22,624 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:22,626 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:22,627 - gen_series_legodnn_models.py[28] - INFO: target model size: 9.590MB
2023-06-30 18:40:22,627 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 10055954.373737374B (9.590MB), try to adapt blocks
2023-06-30 18:40:22,631 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:22,659 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01920204734802246
2023-06-30 18:40:22,659 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0013164160028100013, 0.0009266879931092262, 0.0007164799943566322, 0.0008992639854550361, 0.0005737600028514862, 0.0008387839794158935, 0.0007674880027770997, 0.001187296025454998]
2023-06-30 18:40:22,660 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.804
2023-06-30 18:40:22,660 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.820
2023-06-30 18:40:22,660 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.813
2023-06-30 18:40:22,660 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.839
2023-06-30 18:40:22,660 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.855
2023-06-30 18:40:22,660 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.933
2023-06-30 18:40:22,660 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.741
2023-06-30 18:40:22,660 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.728
2023-06-30 18:40:22,661 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 3, 4]),)
2023-06-30 18:40:22,661 - optimal_runtime.py[116] - INFO: avg ratio: 0.8260369277010684
2023-06-30 18:40:22,661 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.005069181579862326
2023-06-30 18:40:22,662 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00130908 0.00094092 0.00070838 0.00092308 0.00084767 0.00086601
 0.00134098 0.00182941]
2023-06-30 18:40:22,665 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:22,790 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:22,790 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:22,796 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2023-06-30 18:40:22,800 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-30 18:40:22,800 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 331919232.0,
  'blocks_sparsity': [0.6, 0.4, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.0035392203733134427,
  'esti_test_accuracy': 0.688533345858256,
  'is_relaxed': False,
  'model_size': 10044813.0,
  'update_swap_mem_cost': 555878.0,
  'update_swap_time_cost': 0.009466886520385742}
2023-06-30 18:40:22,822 - gen_series_legodnn_models.py[28] - INFO: target model size: 10.024MB
2023-06-30 18:40:22,822 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 10511165.242424242B (10.024MB), try to adapt blocks
2023-06-30 18:40:22,824 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:22,837 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010148159980773926
2023-06-30 18:40:22,838 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006403840109705924, 0.0004608959965407848, 0.000341024000197649, 0.000513215996325016, 0.0004323200024664402, 0.000639488011598587, 0.0005762879922986031, 0.0009631359651684761]
2023-06-30 18:40:22,838 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.642
2023-06-30 18:40:22,838 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.680
2023-06-30 18:40:22,838 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.708
2023-06-30 18:40:22,838 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.470
2023-06-30 18:40:22,838 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.135
2023-06-30 18:40:22,838 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.223
2023-06-30 18:40:22,838 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-30 18:40:22,839 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.897
2023-06-30 18:40:22,839 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5]),)
2023-06-30 18:40:22,839 - optimal_runtime.py[116] - INFO: avg ratio: 1.3674476449793818
2023-06-30 18:40:22,839 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030621510034129756
2023-06-30 18:40:22,840 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064076 0.0004593  0.00033717 0.00052681 0.00063871 0.00066025
 0.00100691 0.00148402]
2023-06-30 18:40:22,841 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:22,975 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:22,975 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:22,979 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.6) from file
2023-06-30 18:40:22,984 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.6) from file
2023-06-30 18:40:22,984 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 385646464.0,
  'blocks_sparsity': [0.6, 0.4, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.0018288269168487002,
  'esti_test_accuracy': 0.7003666957219442,
  'is_relaxed': False,
  'model_size': 10465165.0,
  'update_swap_mem_cost': 1323432.0,
  'update_swap_time_cost': 0.008577585220336914}
2023-06-30 18:40:23,009 - gen_series_legodnn_models.py[28] - INFO: target model size: 10.458MB
2023-06-30 18:40:23,009 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 10966376.111111112B (10.458MB), try to adapt blocks
2023-06-30 18:40:23,011 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:23,024 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009766207695007325
2023-06-30 18:40:23,025 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006371519975364208, 0.00046662399545311923, 0.0003362559974193573, 0.0004949760064482688, 0.0003848319984972477, 0.0006180800087749957, 0.0005699199959635734, 0.0009400959871709348]
2023-06-30 18:40:23,025 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.650
2023-06-30 18:40:23,025 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.659
2023-06-30 18:40:23,025 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.471
2023-06-30 18:40:23,025 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.540
2023-06-30 18:40:23,025 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.275
2023-06-30 18:40:23,025 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.266
2023-06-30 18:40:23,025 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.998
2023-06-30 18:40:23,025 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.919
2023-06-30 18:40:23,026 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:23,026 - optimal_runtime.py[116] - INFO: avg ratio: 1.3877288282886715
2023-06-30 18:40:23,026 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00301739871135493
2023-06-30 18:40:23,026 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063752 0.00046501 0.00039154 0.00050288 0.00056855 0.00063814
 0.00099579 0.00144852]
2023-06-30 18:40:23,028 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:23,168 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:23,169 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.4, 0.4, 0.4, 0.8, 0.8, 0.8, 0.8]
2023-06-30 18:40:23,181 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.4) from file
2023-06-30 18:40:23,185 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.4) from file
2023-06-30 18:40:23,190 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2023-06-30 18:40:23,190 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 468031360.0,
  'blocks_sparsity': [0.4, 0.4, 0.4, 0.4, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.0018542094077205916,
  'esti_test_accuracy': 0.7055000265439352,
  'is_relaxed': False,
  'model_size': 10929037.0,
  'update_swap_mem_cost': 2488076.0,
  'update_swap_time_cost': 0.020850658416748047}
2023-06-30 18:40:23,214 - gen_series_legodnn_models.py[28] - INFO: target model size: 10.892MB
2023-06-30 18:40:23,214 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 11421586.97979798B (10.892MB), try to adapt blocks
2023-06-30 18:40:23,216 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:23,229 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010057727813720703
2023-06-30 18:40:23,230 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006724160090088845, 0.00047820800542831425, 0.00035513600707054135, 0.0005376000069081784, 0.00039875200018286706, 0.0006529919989407063, 0.0005964160040020942, 0.000951136026531458]
2023-06-30 18:40:23,230 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.592
2023-06-30 18:40:23,230 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.619
2023-06-30 18:40:23,230 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.473
2023-06-30 18:40:23,230 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.434
2023-06-30 18:40:23,230 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.230
2023-06-30 18:40:23,230 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.198
2023-06-30 18:40:23,230 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.954
2023-06-30 18:40:23,230 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.908
2023-06-30 18:40:23,231 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:23,231 - optimal_runtime.py[116] - INFO: avg ratio: 1.3338273641101424
2023-06-30 18:40:23,231 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031393351874902382
2023-06-30 18:40:23,231 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00066067 0.00047656 0.00039088 0.00054003 0.00058911 0.00067419
 0.00104208 0.00146553]
2023-06-30 18:40:23,233 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:23,339 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:23,340 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.6, 0.4, 0.6, 0.8, 0.8, 0.8]
2023-06-30 18:40:23,345 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2023-06-30 18:40:23,348 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.6) from file
2023-06-30 18:40:23,352 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.6) from file
2023-06-30 18:40:23,352 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 437737088.0,
  'blocks_sparsity': [0.6, 0.4, 0.6, 0.4, 0.6, 0.8, 0.8, 0.8],
  'esti_latency': 0.001966132604448864,
  'esti_test_accuracy': 0.7107333342234293,
  'is_relaxed': False,
  'model_size': 11401613.0,
  'update_swap_mem_cost': 3431088.0,
  'update_swap_time_cost': 0.011951208114624023}
2023-06-30 18:40:23,375 - gen_series_legodnn_models.py[28] - INFO: target model size: 11.327MB
2023-06-30 18:40:23,375 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 11876797.848484848B (11.327MB), try to adapt blocks
2023-06-30 18:40:23,377 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:23,392 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010609151840209961
2023-06-30 18:40:23,392 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000647424004971981, 0.0004767039977014065, 0.0003332480005919933, 0.0005414399988949299, 0.00045337600260972983, 0.0006338240094482899, 0.0005840960033237934, 0.0009621120169758797]
2023-06-30 18:40:23,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.624
2023-06-30 18:40:23,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.624
2023-06-30 18:40:23,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.484
2023-06-30 18:40:23,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.424
2023-06-30 18:40:23,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.231
2023-06-30 18:40:23,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.234
2023-06-30 18:40:23,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.974
2023-06-30 18:40:23,393 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.898
2023-06-30 18:40:23,393 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:23,393 - optimal_runtime.py[116] - INFO: avg ratio: 1.3431349027987374
2023-06-30 18:40:23,393 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031175804972851462
2023-06-30 18:40:23,394 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006478  0.00047506 0.00038804 0.00054388 0.00058892 0.0006544
 0.00102055 0.00148244]
2023-06-30 18:40:23,395 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:23,528 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:23,528 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.2, 0.2, 0.4, 0.6, 0.8, 0.8, 0.8]
2023-06-30 18:40:23,533 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.4) from file
2023-06-30 18:40:23,537 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2023-06-30 18:40:23,540 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2023-06-30 18:40:23,540 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 544359040.0,
  'blocks_sparsity': [0.4, 0.2, 0.2, 0.4, 0.6, 0.8, 0.8, 0.8],
  'esti_latency': 0.0019932100115781248,
  'esti_test_accuracy': 0.7158000469207764,
  'is_relaxed': False,
  'model_size': 11875213.0,
  'update_swap_mem_cost': 1896204.0,
  'update_swap_time_cost': 0.011993646621704102}
2023-06-30 18:40:23,563 - gen_series_legodnn_models.py[28] - INFO: target model size: 11.761MB
2023-06-30 18:40:23,563 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 12332008.717171717B (11.761MB), try to adapt blocks
2023-06-30 18:40:23,565 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:23,579 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010059776306152344
2023-06-30 18:40:23,579 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000650016013532877, 0.000466048002243042, 0.0003858240060508251, 0.0005349119976162911, 0.0004653120040893555, 0.0006480960063636302, 0.0005838720090687276, 0.0009532159641385077]
2023-06-30 18:40:23,579 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.647
2023-06-30 18:40:23,579 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.635
2023-06-30 18:40:23,579 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.435
2023-06-30 18:40:23,579 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.441
2023-06-30 18:40:23,579 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.199
2023-06-30 18:40:23,580 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.207
2023-06-30 18:40:23,580 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.974
2023-06-30 18:40:23,580 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.906
2023-06-30 18:40:23,580 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:23,580 - optimal_runtime.py[116] - INFO: avg ratio: 1.3207103994259026
2023-06-30 18:40:23,580 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003170514277776951
2023-06-30 18:40:23,581 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063866 0.00047176 0.00040111 0.00053733 0.00060443 0.00066914
 0.00102016 0.00146874]
2023-06-30 18:40:23,583 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:23,722 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:23,722 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.2, 0.2, 0.6, 0.8, 0.8, 0.8]
2023-06-30 18:40:23,728 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.0) from file
2023-06-30 18:40:23,732 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:23,737 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:23,737 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 662502016.0,
  'blocks_sparsity': [0.0, 0.0, 0.2, 0.2, 0.6, 0.8, 0.8, 0.8],
  'esti_latency': 0.0020273406477810474,
  'esti_test_accuracy': 0.7172000606854757,
  'is_relaxed': False,
  'model_size': 12286221.0,
  'update_swap_mem_cost': 2786536.0,
  'update_swap_time_cost': 0.014188051223754883}
2023-06-30 18:40:23,760 - gen_series_legodnn_models.py[28] - INFO: target model size: 12.195MB
2023-06-30 18:40:23,760 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 12787219.585858585B (12.195MB), try to adapt blocks
2023-06-30 18:40:23,763 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:23,776 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010192895889282226
2023-06-30 18:40:23,776 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006399359926581383, 0.0004917440004646778, 0.00039334401115775105, 0.0005792640075087547, 0.00045827199891209595, 0.0006428160071372986, 0.0005863999910652637, 0.0009778240099549294]
2023-06-30 18:40:23,776 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.644
2023-06-30 18:40:23,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.569
2023-06-30 18:40:23,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.408
2023-06-30 18:40:23,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.297
2023-06-30 18:40:23,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.217
2023-06-30 18:40:23,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.217
2023-06-30 18:40:23,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.970
2023-06-30 18:40:23,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.883
2023-06-30 18:40:23,777 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:23,777 - optimal_runtime.py[116] - INFO: avg ratio: 1.2849401425476321
2023-06-30 18:40:23,778 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032587752841826264
2023-06-30 18:40:23,778 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063994 0.00049174 0.00040892 0.00059696 0.00059528 0.00066368
 0.00102458 0.00150665]
2023-06-30 18:40:23,780 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:23,913 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:23,913 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.4, 0.2, 0.2, 0.4, 0.8, 0.8, 0.8]
2023-06-30 18:40:23,920 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.4) from file
2023-06-30 18:40:23,924 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-30 18:40:23,928 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2023-06-30 18:40:23,928 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 566906240.0,
  'blocks_sparsity': [0.4, 0.4, 0.2, 0.2, 0.4, 0.8, 0.8, 0.8],
  'esti_latency': 0.002153367245549861,
  'esti_test_accuracy': 0.7201667030652364,
  'is_relaxed': False,
  'model_size': 12760973.0,
  'update_swap_mem_cost': 4610188.0,
  'update_swap_time_cost': 0.014566659927368164}
2023-06-30 18:40:23,952 - gen_series_legodnn_models.py[28] - INFO: target model size: 12.629MB
2023-06-30 18:40:23,952 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 13242430.454545455B (12.629MB), try to adapt blocks
2023-06-30 18:40:23,954 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:23,967 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010032383918762208
2023-06-30 18:40:23,967 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006239360086619855, 0.00046528000384569166, 0.0004014399908483029, 0.0005675200149416923, 0.0005116160027682781, 0.0006279039978981018, 0.0005753280222415924, 0.0009696640074253083]
2023-06-30 18:40:23,967 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.716
2023-06-30 18:40:23,967 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.664
2023-06-30 18:40:23,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.380
2023-06-30 18:40:23,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.324
2023-06-30 18:40:23,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.185
2023-06-30 18:40:23,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.246
2023-06-30 18:40:23,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.989
2023-06-30 18:40:23,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.891
2023-06-30 18:40:23,968 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:23,968 - optimal_runtime.py[116] - INFO: avg ratio: 1.2836437596491075
2023-06-30 18:40:23,969 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032620664002082312
2023-06-30 18:40:23,969 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061304 0.00046367 0.00041734 0.00058486 0.00061163 0.00064829
 0.00100523 0.00149408]
2023-06-30 18:40:23,971 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:24,100 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:24,101 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.4, 0.2, 0.4, 0.2, 0.8, 0.8, 0.8]
2023-06-30 18:40:24,108 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2023-06-30 18:40:24,115 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2023-06-30 18:40:24,115 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 558782592.0,
  'blocks_sparsity': [0.4, 0.4, 0.2, 0.4, 0.2, 0.8, 0.8, 0.8],
  'esti_latency': 0.0022333278338695518,
  'esti_test_accuracy': 0.7219333648681641,
  'is_relaxed': False,
  'model_size': 13226637.0,
  'update_swap_mem_cost': 6693032.0,
  'update_swap_time_cost': 0.014053583145141602}
2023-06-30 18:40:24,139 - gen_series_legodnn_models.py[28] - INFO: target model size: 13.063MB
2023-06-30 18:40:24,139 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 13697641.323232323B (13.063MB), try to adapt blocks
2023-06-30 18:40:24,141 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:24,155 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010199135780334472
2023-06-30 18:40:24,155 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006476159989833831, 0.0004752959981560707, 0.0003842559903860092, 0.0005739840008318424, 0.0005786560028791428, 0.0006310400031507016, 0.0005760959945619106, 0.000954655971378088]
2023-06-30 18:40:24,155 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.653
2023-06-30 18:40:24,155 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.629
2023-06-30 18:40:24,156 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.441
2023-06-30 18:40:24,156 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.343
2023-06-30 18:40:24,156 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.154
2023-06-30 18:40:24,156 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.240
2023-06-30 18:40:24,156 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-30 18:40:24,156 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.905
2023-06-30 18:40:24,156 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:24,156 - optimal_runtime.py[116] - INFO: avg ratio: 1.2945761265093592
2023-06-30 18:40:24,156 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032345190772819737
2023-06-30 18:40:24,157 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006363  0.00047366 0.00039948 0.00057658 0.00062795 0.00065153
 0.00100658 0.00147096]
2023-06-30 18:40:24,159 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:24,265 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:24,266 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.2, 0.2, 0.8, 0.8, 0.8]
2023-06-30 18:40:24,276 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:24,286 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:24,288 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 648564864.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.2, 0.2, 0.8, 0.8, 0.8],
  'esti_latency': 0.002196967393292566,
  'esti_test_accuracy': 0.7237000664075216,
  'is_relaxed': False,
  'model_size': 13582285.0,
  'update_swap_mem_cost': 2210116.0,
  'update_swap_time_cost': 0.020838022232055664}
2023-06-30 18:40:24,320 - gen_series_legodnn_models.py[28] - INFO: target model size: 13.497MB
2023-06-30 18:40:24,320 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 14152852.191919193B (13.497MB), try to adapt blocks
2023-06-30 18:40:24,322 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:24,334 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009468735694885254
2023-06-30 18:40:24,334 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005932479985058308, 0.0004350720010697842, 0.000380575992166996, 0.0005289920009672642, 0.000543328009545803, 0.0006117759943008423, 0.0005596159920096398, 0.0009425279907882214]
2023-06-30 18:40:24,334 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.805
2023-06-30 18:40:24,334 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.773
2023-06-30 18:40:24,334 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.455
2023-06-30 18:40:24,335 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.421
2023-06-30 18:40:24,335 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.229
2023-06-30 18:40:24,335 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.279
2023-06-30 18:40:24,335 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.017
2023-06-30 18:40:24,335 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.916
2023-06-30 18:40:24,335 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:24,335 - optimal_runtime.py[116] - INFO: avg ratio: 1.3459364849452276
2023-06-30 18:40:24,335 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031110912179178546
2023-06-30 18:40:24,336 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058288 0.00043507 0.00039565 0.00054515 0.00058961 0.00063164
 0.00097778 0.00145227]
2023-06-30 18:40:24,337 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:24,468 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:24,468 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.2, 0.4, 0.2, 0.6, 0.8, 0.8]
2023-06-30 18:40:24,473 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2023-06-30 18:40:24,477 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-30 18:40:24,481 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2023-06-30 18:40:24,486 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.6) from file
2023-06-30 18:40:24,487 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 558152576.0,
  'blocks_sparsity': [0.6, 0.4, 0.2, 0.4, 0.2, 0.6, 0.8, 0.8],
  'esti_latency': 0.0020945113789032853,
  'esti_test_accuracy': 0.7253333727518717,
  'is_relaxed': False,
  'model_size': 14107277.0,
  'update_swap_mem_cost': 5451434.0,
  'update_swap_time_cost': 0.01820850372314453}
2023-06-30 18:40:24,517 - gen_series_legodnn_models.py[28] - INFO: target model size: 13.931MB
2023-06-30 18:40:24,517 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 14608063.06060606B (13.931MB), try to adapt blocks
2023-06-30 18:40:24,519 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:24,534 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011012096405029297
2023-06-30 18:40:24,535 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006436480022966862, 0.0004984960034489632, 0.00045126399397850034, 0.0005621440038084983, 0.0005627520084381104, 0.0007522239908576012, 0.0006140160076320171, 0.0010143360048532487]
2023-06-30 18:40:24,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.633
2023-06-30 18:40:24,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.553
2023-06-30 18:40:24,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.227
2023-06-30 18:40:24,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.371
2023-06-30 18:40:24,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.187
2023-06-30 18:40:24,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.029
2023-06-30 18:40:24,535 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.926
2023-06-30 18:40:24,536 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.852
2023-06-30 18:40:24,536 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:24,536 - optimal_runtime.py[116] - INFO: avg ratio: 1.2037433158234705
2023-06-30 18:40:24,536 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003478591426548281
2023-06-30 18:40:24,537 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00064402 0.00049678 0.00046914 0.00056468 0.00061069 0.00078456
 0.00107283 0.00156291]
2023-06-30 18:40:24,539 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:24,672 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:24,674 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.2, 0.2, 0.6, 0.8, 0.8]
2023-06-30 18:40:24,687 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.4) from file
2023-06-30 18:40:24,696 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:24,705 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:24,706 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 678658944.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.2, 0.2, 0.6, 0.8, 0.8],
  'esti_latency': 0.0023677632834251186,
  'esti_test_accuracy': 0.727933406829834,
  'is_relaxed': False,
  'model_size': 14523085.0,
  'update_swap_mem_cost': 2550696.0,
  'update_swap_time_cost': 0.032167673110961914}
2023-06-30 18:40:24,733 - gen_series_legodnn_models.py[28] - INFO: target model size: 14.365MB
2023-06-30 18:40:24,733 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 15063273.92929293B (14.365MB), try to adapt blocks
2023-06-30 18:40:24,734 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:24,747 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009649503707885742
2023-06-30 18:40:24,747 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005997759960591793, 0.0004207359999418259, 0.00036700800061225893, 0.0005240640118718147, 0.0005420799963176251, 0.0006645119898021221, 0.000556127991527319, 0.0009265599846839904]
2023-06-30 18:40:24,747 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.785
2023-06-30 18:40:24,747 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.833
2023-06-30 18:40:24,747 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.509
2023-06-30 18:40:24,747 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.434
2023-06-30 18:40:24,747 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.232
2023-06-30 18:40:24,748 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.165
2023-06-30 18:40:24,748 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.023
2023-06-30 18:40:24,748 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.932
2023-06-30 18:40:24,748 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:24,748 - optimal_runtime.py[116] - INFO: avg ratio: 1.3350921147950878
2023-06-30 18:40:24,748 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00313636125311923
2023-06-30 18:40:24,749 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005893  0.00042074 0.00038154 0.00054007 0.00058825 0.00069308
 0.00097169 0.00142766]
2023-06-30 18:40:24,750 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:24,890 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:24,890 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.2, 0.4, 0.2, 0.4, 0.8, 0.8]
2023-06-30 18:40:24,896 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2023-06-30 18:40:24,900 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-30 18:40:24,904 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2023-06-30 18:40:24,909 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2023-06-30 18:40:24,910 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 588246656.0,
  'blocks_sparsity': [0.6, 0.4, 0.2, 0.4, 0.2, 0.4, 0.8, 0.8],
  'esti_latency': 0.002131429504802227,
  'esti_test_accuracy': 0.7289000352223715,
  'is_relaxed': False,
  'model_size': 15048077.0,
  'update_swap_mem_cost': 7333034.0,
  'update_swap_time_cost': 0.019202709197998047}
2023-06-30 18:40:24,934 - gen_series_legodnn_models.py[28] - INFO: target model size: 14.800MB
2023-06-30 18:40:24,934 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 15518484.797979798B (14.800MB), try to adapt blocks
2023-06-30 18:40:24,937 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:24,950 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0104017915725708
2023-06-30 18:40:24,951 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006266560032963752, 0.00046012799069285393, 0.00038988800346851347, 0.0005322239957749844, 0.0005623679943382741, 0.0007569920085370542, 0.0006344319954514504, 0.000986784029752016]
2023-06-30 18:40:24,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.678
2023-06-30 18:40:24,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.682
2023-06-30 18:40:24,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.421
2023-06-30 18:40:24,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.449
2023-06-30 18:40:24,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.188
2023-06-30 18:40:24,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.027
2023-06-30 18:40:24,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.897
2023-06-30 18:40:24,951 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.875
2023-06-30 18:40:24,952 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:24,952 - optimal_runtime.py[116] - INFO: avg ratio: 1.2707953510500145
2023-06-30 18:40:24,952 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032950476052091915
2023-06-30 18:40:24,952 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062702 0.00045854 0.00040533 0.00053463 0.00061027 0.00078678
 0.0011085  0.00152046]
2023-06-30 18:40:24,954 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:25,089 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:25,089 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.2, 0.2, 0.4, 0.8, 0.8]
2023-06-30 18:40:25,095 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.4) from file
2023-06-30 18:40:25,098 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:25,103 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:25,103 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 708753024.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.2, 0.2, 0.4, 0.8, 0.8],
  'esti_latency': 0.0021894654357759425,
  'esti_test_accuracy': 0.7315000693003336,
  'is_relaxed': False,
  'model_size': 15463885.0,
  'update_swap_mem_cost': 2550696.0,
  'update_swap_time_cost': 0.013708114624023438}
2023-06-30 18:40:25,129 - gen_series_legodnn_models.py[28] - INFO: target model size: 15.234MB
2023-06-30 18:40:25,129 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 15973695.666666666B (15.234MB), try to adapt blocks
2023-06-30 18:40:25,131 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:25,145 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010196864128112793
2023-06-30 18:40:25,145 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006352640017867088, 0.00048374400287866593, 0.0003834880031645298, 0.0005618240013718606, 0.0005596479997038842, 0.0007452799938619137, 0.000585216011852026, 0.0009453760161995887]
2023-06-30 18:40:25,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.685
2023-06-30 18:40:25,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.595
2023-06-30 18:40:25,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.444
2023-06-30 18:40:25,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.338
2023-06-30 18:40:25,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.193
2023-06-30 18:40:25,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.043
2023-06-30 18:40:25,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.972
2023-06-30 18:40:25,145 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.914
2023-06-30 18:40:25,146 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:25,146 - optimal_runtime.py[116] - INFO: avg ratio: 1.2544530699768295
2023-06-30 18:40:25,146 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033379735586805703
2023-06-30 18:40:25,146 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062417 0.00048374 0.00039868 0.00057899 0.00060732 0.00077461
 0.00102251 0.00145666]
2023-06-30 18:40:25,148 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:25,268 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:25,269 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.8, 0.8]
2023-06-30 18:40:25,276 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:25,276 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 738269824.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.8, 0.8],
  'esti_latency': 0.002308304182955414,
  'esti_test_accuracy': 0.7317334016164144,
  'is_relaxed': False,
  'model_size': 15694605.0,
  'update_swap_mem_cost': 2169666.0,
  'update_swap_time_cost': 0.0072553157806396484}
2023-06-30 18:40:25,302 - gen_series_legodnn_models.py[28] - INFO: target model size: 15.668MB
2023-06-30 18:40:25,302 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 16428906.535353536B (15.668MB), try to adapt blocks
2023-06-30 18:40:25,304 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:25,318 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010514431953430176
2023-06-30 18:40:25,318 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007311679869890213, 0.00047590400651097294, 0.00038249599933624267, 0.0005955520085990429, 0.0005718399919569493, 0.0007511359862983227, 0.0005855040103197099, 0.0009516160003840925]
2023-06-30 18:40:25,318 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.464
2023-06-30 18:40:25,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.621
2023-06-30 18:40:25,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.448
2023-06-30 18:40:25,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.300
2023-06-30 18:40:25,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.168
2023-06-30 18:40:25,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.035
2023-06-30 18:40:25,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.972
2023-06-30 18:40:25,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.908
2023-06-30 18:40:25,319 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-30 18:40:25,320 - optimal_runtime.py[116] - INFO: avg ratio: 1.2830200461583885
2023-06-30 18:40:25,320 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032636521858921907
2023-06-30 18:40:25,320 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00071839 0.0004759  0.00039765 0.00059555 0.00062055 0.0007807
 0.00102301 0.00146627]
2023-06-30 18:40:25,322 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:25,425 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:25,425 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.8, 0.8]
2023-06-30 18:40:25,430 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2023-06-30 18:40:25,431 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 760843648.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.8, 0.8],
  'esti_latency': 0.0022795475321133307,
  'esti_test_accuracy': 0.7331333955128988,
  'is_relaxed': False,
  'model_size': 16400397.0,
  'update_swap_mem_cost': 6405798.0,
  'update_swap_time_cost': 0.00511932373046875}
2023-06-30 18:40:25,454 - gen_series_legodnn_models.py[28] - INFO: target model size: 16.102MB
2023-06-30 18:40:25,454 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 16884117.404040404B (16.102MB), try to adapt blocks
2023-06-30 18:40:25,457 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:25,470 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010212703704833985
2023-06-30 18:40:25,470 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006909760087728499, 0.00047177599743008613, 0.0003854080103337765, 0.000587360005825758, 0.0006160320043563843, 0.0007426880039274693, 0.0005696959942579269, 0.0009380159899592399]
2023-06-30 18:40:25,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.549
2023-06-30 18:40:25,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.635
2023-06-30 18:40:25,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.437
2023-06-30 18:40:25,471 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.319
2023-06-30 18:40:25,471 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.176
2023-06-30 18:40:25,471 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.046
2023-06-30 18:40:25,471 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.999
2023-06-30 18:40:25,471 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.921
2023-06-30 18:40:25,471 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:25,471 - optimal_runtime.py[116] - INFO: avg ratio: 1.2445768352460427
2023-06-30 18:40:25,471 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033644617669270076
2023-06-30 18:40:25,472 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006789  0.00047178 0.00040067 0.00058736 0.00061603 0.00077192
 0.00099539 0.00144532]
2023-06-30 18:40:25,474 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:25,620 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:25,621 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.8, 0.8]
2023-06-30 18:40:25,621 - gen_series_legodnn_models.py[28] - INFO: target model size: 16.536MB
2023-06-30 18:40:25,621 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 17339328.272727273B (16.536MB), try to adapt blocks
2023-06-30 18:40:25,623 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:25,638 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012333056449890138
2023-06-30 18:40:25,639 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000613727994263172, 0.0004853120073676109, 0.0003685760051012039, 0.0005719040036201477, 0.000606720007956028, 0.0007455039843916894, 0.0005683199912309647, 0.000929119974374771]
2023-06-30 18:40:25,639 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.745
2023-06-30 18:40:25,639 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.590
2023-06-30 18:40:25,639 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.503
2023-06-30 18:40:25,639 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.354
2023-06-30 18:40:25,639 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.194
2023-06-30 18:40:25,639 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.042
2023-06-30 18:40:25,639 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.001
2023-06-30 18:40:25,639 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.930
2023-06-30 18:40:25,640 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:25,640 - optimal_runtime.py[116] - INFO: avg ratio: 1.2734174987054638
2023-06-30 18:40:25,640 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032882626337749398
2023-06-30 18:40:25,640 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060301 0.00048531 0.00038317 0.0005719  0.00060672 0.00077484
 0.00099299 0.00143161]
2023-06-30 18:40:25,642 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:25,772 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:25,773 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.2, 0.2, 0.2, 0.2, 0.6, 0.6, 0.8]
2023-06-30 18:40:25,778 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2023-06-30 18:40:25,784 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:25,789 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2023-06-30 18:40:25,794 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.6) from file
2023-06-30 18:40:25,802 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.6) from file
2023-06-30 18:40:25,802 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 672865536.0,
  'blocks_sparsity': [0.4, 0.2, 0.2, 0.2, 0.2, 0.6, 0.6, 0.8],
  'esti_latency': 0.002342384239245872,
  'esti_test_accuracy': 0.7356667319933573,
  'is_relaxed': False,
  'model_size': 17289357.0,
  'update_swap_mem_cost': 22475474.0,
  'update_swap_time_cost': 0.02862262725830078}
2023-06-30 18:40:25,827 - gen_series_legodnn_models.py[28] - INFO: target model size: 16.970MB
2023-06-30 18:40:25,827 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 17794539.141414143B (16.970MB), try to adapt blocks
2023-06-30 18:40:25,829 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:25,843 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010401311874389649
2023-06-30 18:40:25,843 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006807040087878705, 0.0004642559997737408, 0.000389248002320528, 0.0005817280001938343, 0.000561856009066105, 0.0007018559947609901, 0.0006998719945549964, 0.0009688320197165012]
2023-06-30 18:40:25,844 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.573
2023-06-30 18:40:25,844 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.642
2023-06-30 18:40:25,844 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.423
2023-06-30 18:40:25,844 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.292
2023-06-30 18:40:25,844 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.189
2023-06-30 18:40:25,844 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.103
2023-06-30 18:40:25,844 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.938
2023-06-30 18:40:25,844 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.892
2023-06-30 18:40:25,845 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:25,845 - optimal_runtime.py[116] - INFO: avg ratio: 1.2516591760490567
2023-06-30 18:40:25,845 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033454244240879584
2023-06-30 18:40:25,845 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00066881 0.00046994 0.00040467 0.0005995  0.00060971 0.00073203
 0.00105962 0.0014928 ]
2023-06-30 18:40:25,847 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:25,960 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:25,961 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.2, 0.2, 0.0, 0.4, 0.4, 0.6, 0.8]
2023-06-30 18:40:25,966 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:25,970 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2023-06-30 18:40:25,975 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2023-06-30 18:40:25,975 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 709902592.0,
  'blocks_sparsity': [0.4, 0.2, 0.2, 0.0, 0.4, 0.4, 0.6, 0.8],
  'esti_latency': 0.0023250843318910427,
  'esti_test_accuracy': 0.7364000479380289,
  'is_relaxed': False,
  'model_size': 17755085.0,
  'update_swap_mem_cost': 11946218.0,
  'update_swap_time_cost': 0.013776540756225586}
2023-06-30 18:40:26,006 - gen_series_legodnn_models.py[28] - INFO: target model size: 17.404MB
2023-06-30 18:40:26,006 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 18249750.01010101B (17.404MB), try to adapt blocks
2023-06-30 18:40:26,008 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:26,026 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013940799713134765
2023-06-30 18:40:26,026 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0008197119943797587, 0.0006411840096116066, 0.00048639999702572824, 0.000903839997947216, 0.0006298239864408969, 0.0008430719859898089, 0.000879424013197422, 0.0012474240213632584]
2023-06-30 18:40:26,027 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.306
2023-06-30 18:40:26,027 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.189
2023-06-30 18:40:26,027 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.139
2023-06-30 18:40:26,027 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.857
2023-06-30 18:40:26,027 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.963
2023-06-30 18:40:26,027 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.922
2023-06-30 18:40:26,028 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.746
2023-06-30 18:40:26,028 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.692
2023-06-30 18:40:26,028 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:26,028 - optimal_runtime.py[116] - INFO: avg ratio: 0.9699393650044259
2023-06-30 18:40:26,029 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004317106129793193
2023-06-30 18:40:26,029 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00080539 0.00064904 0.00050567 0.00090384 0.00075294 0.00087625
 0.00133146 0.00192206]
2023-06-30 18:40:26,032 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:26,155 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:26,155 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.6, 0.8]
2023-06-30 18:40:26,160 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:26,165 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2023-06-30 18:40:26,165 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 702959616.0,
  'blocks_sparsity': [0.4, 0.2, 0.2, 0.2, 0.2, 0.4, 0.6, 0.8],
  'esti_latency': 0.0030585635291509464,
  'esti_test_accuracy': 0.739233394463857,
  'is_relaxed': False,
  'model_size': 18230157.0,
  'update_swap_mem_cost': 7163880.0,
  'update_swap_time_cost': 0.009802579879760742}
2023-06-30 18:40:26,194 - gen_series_legodnn_models.py[28] - INFO: target model size: 17.838MB
2023-06-30 18:40:26,194 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 18704960.87878788B (17.838MB), try to adapt blocks
2023-06-30 18:40:26,196 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:26,211 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01087286376953125
2023-06-30 18:40:26,211 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006698240004479884, 0.0004637119919061661, 0.0003821760080754757, 0.0005583680048584939, 0.0005842880010604858, 0.0007665919996798038, 0.0006968639828264713, 0.0009595519788563252]
2023-06-30 18:40:26,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.598
2023-06-30 18:40:26,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.643
2023-06-30 18:40:26,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.449
2023-06-30 18:40:26,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.346
2023-06-30 18:40:26,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.143
2023-06-30 18:40:26,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.014
2023-06-30 18:40:26,212 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.942
2023-06-30 18:40:26,212 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.900
2023-06-30 18:40:26,212 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:26,212 - optimal_runtime.py[116] - INFO: avg ratio: 1.2379344320838455
2023-06-30 18:40:26,212 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033825145093829296
2023-06-30 18:40:26,213 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065812 0.00046939 0.00039731 0.00057542 0.00063406 0.00079676
 0.00105506 0.0014785 ]
2023-06-30 18:40:26,215 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:26,341 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:26,342 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.6, 0.8]
2023-06-30 18:40:26,347 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:26,352 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:26,352 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 760837120.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.6, 0.8],
  'esti_latency': 0.002421993572910296,
  'esti_test_accuracy': 0.7395667235056559,
  'is_relaxed': False,
  'model_size': 18516237.0,
  'update_swap_mem_cost': 2741124.0,
  'update_swap_time_cost': 0.010246753692626953}
2023-06-30 18:40:26,378 - gen_series_legodnn_models.py[28] - INFO: target model size: 18.273MB
2023-06-30 18:40:26,378 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 19160171.74747475B (18.273MB), try to adapt blocks
2023-06-30 18:40:26,380 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:26,393 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010269023895263673
2023-06-30 18:40:26,394 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006269120015203952, 0.00046764799579977984, 0.000401184007525444, 0.0005700799934566021, 0.0005533120222389698, 0.0007332160212099551, 0.000699520006775856, 0.000984704028815031]
2023-06-30 18:40:26,394 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.708
2023-06-30 18:40:26,394 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.650
2023-06-30 18:40:26,394 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.381
2023-06-30 18:40:26,394 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.358
2023-06-30 18:40:26,394 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.207
2023-06-30 18:40:26,394 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.060
2023-06-30 18:40:26,394 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.938
2023-06-30 18:40:26,394 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.877
2023-06-30 18:40:26,395 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:26,395 - optimal_runtime.py[116] - INFO: avg ratio: 1.2514562526012296
2023-06-30 18:40:26,395 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033459668841677014
2023-06-30 18:40:26,395 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061596 0.00046765 0.00041707 0.00057008 0.00060044 0.00076207
 0.00105908 0.00151725]
2023-06-30 18:40:26,397 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:26,535 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:26,536 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.4, 0.2, 0.2, 0.2, 0.4, 0.8, 0.6]
2023-06-30 18:40:26,540 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-30 18:40:26,545 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:26,549 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.8) from file
2023-06-30 18:40:26,557 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.6) from file
2023-06-30 18:40:26,557 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 679755776.0,
  'blocks_sparsity': [0.4, 0.4, 0.2, 0.2, 0.2, 0.4, 0.8, 0.6],
  'esti_latency': 0.002402342692534307,
  'esti_test_accuracy': 0.7414333621660868,
  'is_relaxed': False,
  'model_size': 19110029.0,
  'update_swap_mem_cost': 22635564.0,
  'update_swap_time_cost': 0.021132230758666992}
2023-06-30 18:40:26,582 - gen_series_legodnn_models.py[28] - INFO: target model size: 18.707MB
2023-06-30 18:40:26,582 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 19615382.616161615B (18.707MB), try to adapt blocks
2023-06-30 18:40:26,584 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:26,598 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010291199684143066
2023-06-30 18:40:26,598 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006499200053513049, 0.00047033599391579624, 0.00039977599680423735, 0.0005542720183730125, 0.0005641600117087364, 0.0007348799891769887, 0.0005765120014548301, 0.001067104022949934]
2023-06-30 18:40:26,598 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.647
2023-06-30 18:40:26,598 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.646
2023-06-30 18:40:26,598 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.385
2023-06-30 18:40:26,598 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.356
2023-06-30 18:40:26,599 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.184
2023-06-30 18:40:26,599 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.057
2023-06-30 18:40:26,599 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-30 18:40:26,599 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.923
2023-06-30 18:40:26,599 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:26,599 - optimal_runtime.py[116] - INFO: avg ratio: 1.2456019068542363
2023-06-30 18:40:26,600 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033616929736109795
2023-06-30 18:40:26,600 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063857 0.00046871 0.00041561 0.0005712  0.00061221 0.0007638
 0.0010073  0.00144203]
2023-06-30 18:40:26,602 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:26,740 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:26,741 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.8, 0.6]
2023-06-30 18:40:26,750 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:26,759 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:26,759 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 768357376.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.8, 0.6],
  'esti_latency': 0.0024745177673096788,
  'esti_test_accuracy': 0.742133378982544,
  'is_relaxed': False,
  'model_size': 19456269.0,
  'update_swap_mem_cost': 2680964.0,
  'update_swap_time_cost': 0.018150806427001953}
2023-06-30 18:40:26,792 - gen_series_legodnn_models.py[28] - INFO: target model size: 19.141MB
2023-06-30 18:40:26,792 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 20070593.484848484B (19.141MB), try to adapt blocks
2023-06-30 18:40:26,793 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:26,806 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009865216255187988
2023-06-30 18:40:26,807 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005825279988348484, 0.00043756800144910814, 0.0003485120013356209, 0.0005416319929063321, 0.0005375359989702702, 0.0007747200019657612, 0.000644384004175663, 0.0010789120197296142]
2023-06-30 18:40:26,807 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.838
2023-06-30 18:40:26,807 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.763
2023-06-30 18:40:26,807 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.589
2023-06-30 18:40:26,807 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.430
2023-06-30 18:40:26,807 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.242
2023-06-30 18:40:26,807 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.003
2023-06-30 18:40:26,807 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.883
2023-06-30 18:40:26,807 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.913
2023-06-30 18:40:26,808 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:26,808 - optimal_runtime.py[116] - INFO: avg ratio: 1.316115632290205
2023-06-30 18:40:26,808 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031815830428986295
2023-06-30 18:40:26,808 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00057235 0.00043757 0.00036232 0.00054163 0.00058332 0.00080521
 0.00112589 0.00145799]
2023-06-30 18:40:26,810 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:26,944 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:26,944 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.2, 0.0, 0.4, 0.8, 0.6]
2023-06-30 18:40:26,949 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:26,954 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2023-06-30 18:40:26,954 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 761414400.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.2, 0.0, 0.4, 0.8, 0.6],
  'esti_latency': 0.0022708279639294744,
  'esti_test_accuracy': 0.7433000405629476,
  'is_relaxed': False,
  'model_size': 19931341.0,
  'update_swap_mem_cost': 8575464.0,
  'update_swap_time_cost': 0.009958028793334961}
2023-06-30 18:40:26,980 - gen_series_legodnn_models.py[28] - INFO: target model size: 19.575MB
2023-06-30 18:40:26,981 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 20525804.353535354B (19.575MB), try to adapt blocks
2023-06-30 18:40:26,983 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:26,998 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011938272476196289
2023-06-30 18:40:26,999 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006259840093553067, 0.0004747200086712837, 0.00039795200899243356, 0.0005904959924519063, 0.0006163839995861054, 0.0009083839990198612, 0.0007291519939899444, 0.0012914879992604257]
2023-06-30 18:40:26,999 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.710
2023-06-30 18:40:26,999 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.625
2023-06-30 18:40:26,999 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.392
2023-06-30 18:40:26,999 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.273
2023-06-30 18:40:26,999 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.176
2023-06-30 18:40:26,999 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.855
2023-06-30 18:40:26,999 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.780
2023-06-30 18:40:26,999 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.763
2023-06-30 18:40:27,000 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:27,000 - optimal_runtime.py[116] - INFO: avg ratio: 1.1739003598628284
2023-06-30 18:40:27,000 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0035670243585900416
2023-06-30 18:40:27,000 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061505 0.00047472 0.00041371 0.00060853 0.00061638 0.00094413
 0.001274   0.00174525]
2023-06-30 18:40:27,002 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:27,159 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:27,159 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.2, 0.0, 0.0, 0.4, 0.8, 0.6]
2023-06-30 18:40:27,165 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.0) from file
2023-06-30 18:40:27,169 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:27,170 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 850016000.0,
  'blocks_sparsity': [0.0, 0.0, 0.2, 0.0, 0.0, 0.4, 0.8, 0.6],
  'esti_latency': 0.0025168983720713183,
  'esti_test_accuracy': 0.7435333728790283,
  'is_relaxed': False,
  'model_size': 20277581.0,
  'update_swap_mem_cost': 2685926.0,
  'update_swap_time_cost': 0.010192394256591797}
2023-06-30 18:40:27,195 - gen_series_legodnn_models.py[28] - INFO: target model size: 20.009MB
2023-06-30 18:40:27,195 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 20981015.222222224B (20.009MB), try to adapt blocks
2023-06-30 18:40:27,197 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:27,211 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010237183570861817
2023-06-30 18:40:27,211 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006085120067000389, 0.0004601600058376789, 0.00037033600360155105, 0.0005713599994778633, 0.0006144320033490658, 0.0007489920035004616, 0.0005786879882216454, 0.0010724159628152847]
2023-06-30 18:40:27,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.729
2023-06-30 18:40:27,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.676
2023-06-30 18:40:27,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.496
2023-06-30 18:40:27,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.355
2023-06-30 18:40:27,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.179
2023-06-30 18:40:27,212 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.038
2023-06-30 18:40:27,212 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.983
2023-06-30 18:40:27,212 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.918
2023-06-30 18:40:27,212 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:27,212 - optimal_runtime.py[116] - INFO: avg ratio: 1.2669927794744305
2023-06-30 18:40:27,212 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003304936891530904
2023-06-30 18:40:27,213 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060851 0.00046016 0.000385   0.00057136 0.00061443 0.00077847
 0.00101111 0.00144921]
2023-06-30 18:40:27,214 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:27,325 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:27,325 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.4, 0.2, 0.6, 0.6, 0.6]
2023-06-30 18:40:27,330 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.4) from file
2023-06-30 18:40:27,335 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2023-06-30 18:40:27,339 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2023-06-30 18:40:27,344 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.6) from file
2023-06-30 18:40:27,350 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.6) from file
2023-06-30 18:40:27,350 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 700616320.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.4, 0.2, 0.6, 0.6, 0.6],
  'esti_latency': 0.00249813375156288,
  'esti_test_accuracy': 0.744866689046224,
  'is_relaxed': False,
  'model_size': 20866253.0,
  'update_swap_mem_cost': 22180148.0,
  'update_swap_time_cost': 0.02465963363647461}
2023-06-30 18:40:27,378 - gen_series_legodnn_models.py[28] - INFO: target model size: 20.443MB
2023-06-30 18:40:27,379 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 21436226.09090909B (20.443MB), try to adapt blocks
2023-06-30 18:40:27,381 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:27,395 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010850720405578614
2023-06-30 18:40:27,396 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000705791998654604, 0.00046969600394368167, 0.00039110400527715683, 0.000528192013502121, 0.000567711990326643, 0.0006962559819221496, 0.000695839986205101, 0.0010730559900403022]
2023-06-30 18:40:27,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.517
2023-06-30 18:40:27,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.642
2023-06-30 18:40:27,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.416
2023-06-30 18:40:27,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.460
2023-06-30 18:40:27,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.176
2023-06-30 18:40:27,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.112
2023-06-30 18:40:27,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.943
2023-06-30 18:40:27,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.918
2023-06-30 18:40:27,397 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5]),)
2023-06-30 18:40:27,397 - optimal_runtime.py[116] - INFO: avg ratio: 1.3362539291400384
2023-06-30 18:40:27,397 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003133634324191009
2023-06-30 18:40:27,398 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00069346 0.0004697  0.0004066  0.00053058 0.00061607 0.00072619
 0.00105351 0.00145007]
2023-06-30 18:40:27,400 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:27,535 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:27,536 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6]
2023-06-30 18:40:27,541 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:27,545 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2023-06-30 18:40:27,550 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2023-06-30 18:40:27,551 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 738834048.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6],
  'esti_latency': 0.002251821438385591,
  'esti_test_accuracy': 0.746666689713796,
  'is_relaxed': False,
  'model_size': 21341389.0,
  'update_swap_mem_cost': 11475370.0,
  'update_swap_time_cost': 0.014497518539428711}
2023-06-30 18:40:27,577 - gen_series_legodnn_models.py[28] - INFO: target model size: 20.877MB
2023-06-30 18:40:27,577 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 21891436.95959596B (20.877MB), try to adapt blocks
2023-06-30 18:40:27,579 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:27,593 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010491904258728027
2023-06-30 18:40:27,593 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006356479823589326, 0.0004589760042726993, 0.0003934400081634521, 0.000548703994601965, 0.0005017280019819736, 0.000733855988830328, 0.0007000319808721543, 0.0010856319591403007]
2023-06-30 18:40:27,594 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.684
2023-06-30 18:40:27,594 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.681
2023-06-30 18:40:27,594 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.408
2023-06-30 18:40:27,594 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.370
2023-06-30 18:40:27,594 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.208
2023-06-30 18:40:27,594 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.059
2023-06-30 18:40:27,594 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.938
2023-06-30 18:40:27,594 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.907
2023-06-30 18:40:27,594 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:27,595 - optimal_runtime.py[116] - INFO: avg ratio: 1.2611103032210842
2023-06-30 18:40:27,595 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033203528410585405
2023-06-30 18:40:27,595 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062454 0.00045898 0.00040902 0.00056547 0.00059981 0.00076274
 0.00105986 0.00146707]
2023-06-30 18:40:27,597 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:27,734 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:27,734 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.2, 0.2, 0.2, 0.4, 0.6, 0.6]
2023-06-30 18:40:27,739 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2023-06-30 18:40:27,743 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-30 18:40:27,747 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2023-06-30 18:40:27,748 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 671598976.0,
  'blocks_sparsity': [0.6, 0.4, 0.2, 0.2, 0.2, 0.4, 0.6, 0.6],
  'esti_latency': 0.002472009787024271,
  'esti_test_accuracy': 0.7484333515167236,
  'is_relaxed': False,
  'model_size': 21871501.0,
  'update_swap_mem_cost': 5846092.0,
  'update_swap_time_cost': 0.013121843338012695}
2023-06-30 18:40:27,774 - gen_series_legodnn_models.py[28] - INFO: target model size: 21.311MB
2023-06-30 18:40:27,774 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 22346647.82828283B (21.311MB), try to adapt blocks
2023-06-30 18:40:27,776 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:27,789 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010256416320800781
2023-06-30 18:40:27,789 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006177920065820217, 0.00046150400117039685, 0.0003736320063471794, 0.0005470080152153968, 0.0005622079968452454, 0.0007328320182859898, 0.0006935360133647919, 0.0010749759823083878]
2023-06-30 18:40:27,790 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.702
2023-06-30 18:40:27,790 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.677
2023-06-30 18:40:27,790 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.482
2023-06-30 18:40:27,790 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.374
2023-06-30 18:40:27,790 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.188
2023-06-30 18:40:27,790 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.060
2023-06-30 18:40:27,790 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.947
2023-06-30 18:40:27,790 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.916
2023-06-30 18:40:27,790 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:27,791 - optimal_runtime.py[116] - INFO: avg ratio: 1.2761039610320435
2023-06-30 18:40:27,791 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032813401619738243
2023-06-30 18:40:27,791 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061815 0.00045991 0.00038843 0.00056372 0.0006101  0.00076167
 0.00105002 0.00145267]
2023-06-30 18:40:27,793 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:27,925 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:27,925 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.6, 0.6]
2023-06-30 18:40:27,930 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.4) from file
2023-06-30 18:40:27,934 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:27,939 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:27,939 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 790924672.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.6, 0.6],
  'esti_latency': 0.0024666222181788404,
  'esti_test_accuracy': 0.7499667008717855,
  'is_relaxed': False,
  'model_size': 22277901.0,
  'update_swap_mem_cost': 3021544.0,
  'update_swap_time_cost': 0.013626813888549805}
2023-06-30 18:40:27,966 - gen_series_legodnn_models.py[28] - INFO: target model size: 21.746MB
2023-06-30 18:40:27,966 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 22801858.696969695B (21.746MB), try to adapt blocks
2023-06-30 18:40:27,968 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:27,982 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010250911712646485
2023-06-30 18:40:27,982 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006273919865489007, 0.0004791360050439834, 0.00037251200154423715, 0.0005757440105080603, 0.0005624320097267629, 0.0007415680028498172, 0.0006880959868431091, 0.0010742719843983648]
2023-06-30 18:40:27,982 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.707
2023-06-30 18:40:27,982 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.610
2023-06-30 18:40:27,982 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.487
2023-06-30 18:40:27,982 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.345
2023-06-30 18:40:27,982 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.187
2023-06-30 18:40:27,983 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.048
2023-06-30 18:40:27,983 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.954
2023-06-30 18:40:27,983 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.917
2023-06-30 18:40:27,983 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:27,983 - optimal_runtime.py[116] - INFO: avg ratio: 1.2668025039567516
2023-06-30 18:40:27,983 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033054332976999536
2023-06-30 18:40:27,984 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061643 0.00047914 0.00038727 0.00057574 0.00061034 0.00077075
 0.00104179 0.00145172]
2023-06-30 18:40:27,985 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:28,117 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:28,118 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.2, 0.0, 0.4, 0.6, 0.6]
2023-06-30 18:40:28,123 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:28,128 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2023-06-30 18:40:28,128 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 783981696.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.2, 0.0, 0.4, 0.6, 0.6],
  'esti_latency': 0.0025242516342290277,
  'esti_test_accuracy': 0.7511333624521891,
  'is_relaxed': False,
  'model_size': 22752973.0,
  'update_swap_mem_cost': 8575464.0,
  'update_swap_time_cost': 0.009964227676391602}
2023-06-30 18:40:28,155 - gen_series_legodnn_models.py[28] - INFO: target model size: 22.180MB
2023-06-30 18:40:28,155 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 23257069.565656565B (22.180MB), try to adapt blocks
2023-06-30 18:40:28,157 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:28,171 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010350591659545898
2023-06-30 18:40:28,171 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006204479821026325, 0.0004789119958877563, 0.00037619199603796007, 0.000555039994418621, 0.0006106239855289459, 0.0007316479980945586, 0.0006844800040125846, 0.001076832003891468]
2023-06-30 18:40:28,171 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.726
2023-06-30 18:40:28,171 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.611
2023-06-30 18:40:28,171 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.472
2023-06-30 18:40:28,172 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.354
2023-06-30 18:40:28,172 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.187
2023-06-30 18:40:28,172 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.062
2023-06-30 18:40:28,172 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.959
2023-06-30 18:40:28,172 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.915
2023-06-30 18:40:28,172 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:28,172 - optimal_runtime.py[116] - INFO: avg ratio: 1.268784552695168
2023-06-30 18:40:28,172 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033002696709173696
2023-06-30 18:40:28,173 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060961 0.00047891 0.00039109 0.00057199 0.00061062 0.00076044
 0.00103631 0.00145518]
2023-06-30 18:40:28,175 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:28,277 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:28,277 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.6, 0.6]
2023-06-30 18:40:28,283 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:28,283 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 813498496.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.6, 0.6],
  'esti_latency': 0.002537236331094993,
  'esti_test_accuracy': 0.7513666947682699,
  'is_relaxed': False,
  'model_size': 22983693.0,
  'update_swap_mem_cost': 2169666.0,
  'update_swap_time_cost': 0.005400419235229492}
2023-06-30 18:40:28,309 - gen_series_legodnn_models.py[28] - INFO: target model size: 22.614MB
2023-06-30 18:40:28,310 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 23712280.434343435B (22.614MB), try to adapt blocks
2023-06-30 18:40:28,312 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:28,325 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010385536193847656
2023-06-30 18:40:28,325 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006256639994680881, 0.0004715519994497299, 0.0003705919981002808, 0.0005677440017461777, 0.0006034240052103996, 0.000742400024086237, 0.0007114240229129791, 0.0010779200159013271]
2023-06-30 18:40:28,326 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.711
2023-06-30 18:40:28,326 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.636
2023-06-30 18:40:28,326 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.494
2023-06-30 18:40:28,326 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.364
2023-06-30 18:40:28,326 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.201
2023-06-30 18:40:28,326 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.047
2023-06-30 18:40:28,326 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.923
2023-06-30 18:40:28,326 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.914
2023-06-30 18:40:28,326 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:28,327 - optimal_runtime.py[116] - INFO: avg ratio: 1.276575126279975
2023-06-30 18:40:28,327 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00328012906721008
2023-06-30 18:40:28,327 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061473 0.00047155 0.00038527 0.00056774 0.00060342 0.00077162
 0.00107711 0.00145665]
2023-06-30 18:40:28,329 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:28,466 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:28,466 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.2, 0.0, 0.2, 0.6, 0.6]
2023-06-30 18:40:28,471 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:28,478 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.2) from file
2023-06-30 18:40:28,478 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 814075776.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.2, 0.0, 0.2, 0.6, 0.6],
  'esti_latency': 0.0024858290644892158,
  'esti_test_accuracy': 0.7516667048136393,
  'is_relaxed': False,
  'model_size': 23693773.0,
  'update_swap_mem_cost': 8833604.0,
  'update_swap_time_cost': 0.011721611022949219}
2023-06-30 18:40:28,506 - gen_series_legodnn_models.py[28] - INFO: target model size: 23.048MB
2023-06-30 18:40:28,507 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 24167491.303030305B (23.048MB), try to adapt blocks
2023-06-30 18:40:28,509 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:28,522 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010534912109375
2023-06-30 18:40:28,523 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006840960159897805, 0.0004636799953877926, 0.00038444799929857255, 0.0005505599938333034, 0.0006158079914748668, 0.0007944959960877894, 0.0006854399964213371, 0.0010603520348668098]
2023-06-30 18:40:28,523 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.565
2023-06-30 18:40:28,523 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.664
2023-06-30 18:40:28,523 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.441
2023-06-30 18:40:28,523 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.365
2023-06-30 18:40:28,523 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.177
2023-06-30 18:40:28,523 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.978
2023-06-30 18:40:28,523 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.958
2023-06-30 18:40:28,523 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.929
2023-06-30 18:40:28,524 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:28,524 - optimal_runtime.py[116] - INFO: avg ratio: 1.3274732478820424
2023-06-30 18:40:28,524 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003154362006819444
2023-06-30 18:40:28,524 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067215 0.00046368 0.00039968 0.00056738 0.00061581 0.00082587
 0.00103777 0.00143291]
2023-06-30 18:40:28,526 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:28,660 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:28,660 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.2, 0.2, 0.2, 0.4, 0.4, 0.4, 0.6]
2023-06-30 18:40:28,665 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2023-06-30 18:40:28,669 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2023-06-30 18:40:28,674 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2023-06-30 18:40:28,681 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.4) from file
2023-06-30 18:40:28,681 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 733261888.0,
  'blocks_sparsity': [0.4, 0.2, 0.2, 0.2, 0.4, 0.4, 0.4, 0.6],
  'esti_latency': 0.002405781958797467,
  'esti_test_accuracy': 0.7532000343004862,
  'is_relaxed': False,
  'model_size': 24135565.0,
  'update_swap_mem_cost': 27152784.0,
  'update_swap_time_cost': 0.020467519760131836}
2023-06-30 18:40:28,708 - gen_series_legodnn_models.py[28] - INFO: target model size: 23.482MB
2023-06-30 18:40:28,709 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 24622702.17171717B (23.482MB), try to adapt blocks
2023-06-30 18:40:28,711 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:28,724 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010428352355957031
2023-06-30 18:40:28,725 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006496639996767042, 0.00046943999826908116, 0.0003919679895043373, 0.0005583039857447147, 0.0005222719982266426, 0.0007589120082557202, 0.0007983360141515731, 0.0010759999714791775]
2023-06-30 18:40:28,725 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.648
2023-06-30 18:40:28,725 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.623
2023-06-30 18:40:28,725 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.413
2023-06-30 18:40:28,725 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.346
2023-06-30 18:40:28,725 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.161
2023-06-30 18:40:28,725 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.024
2023-06-30 18:40:28,725 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.983
2023-06-30 18:40:28,725 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.915
2023-06-30 18:40:28,726 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:28,726 - optimal_runtime.py[116] - INFO: avg ratio: 1.2359222380647983
2023-06-30 18:40:28,726 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033880215512141197
2023-06-30 18:40:28,726 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063831 0.00047519 0.00040749 0.00057536 0.00062437 0.00078878
 0.00101107 0.00145405]
2023-06-30 18:40:28,728 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:28,831 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:28,831 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.2, 0.2, 0.4, 0.2, 0.4, 0.4, 0.6]
2023-06-30 18:40:28,836 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2023-06-30 18:40:28,840 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2023-06-30 18:40:28,841 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 725138240.0,
  'blocks_sparsity': [0.4, 0.2, 0.2, 0.4, 0.2, 0.4, 0.4, 0.6],
  'esti_latency': 0.0027058432504984136,
  'esti_test_accuracy': 0.7549666961034139,
  'is_relaxed': False,
  'model_size': 24601229.0,
  'update_swap_mem_cost': 6693032.0,
  'update_swap_time_cost': 0.00914621353149414}
2023-06-30 18:40:28,870 - gen_series_legodnn_models.py[28] - INFO: target model size: 23.916MB
2023-06-30 18:40:28,870 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 25077913.04040404B (23.916MB), try to adapt blocks
2023-06-30 18:40:28,872 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:28,887 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011013440132141113
2023-06-30 18:40:28,887 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006438720040023327, 0.00046134399622678755, 0.0003784000054001808, 0.0005459839999675751, 0.0005834560133516789, 0.0008409280180931093, 0.0008090239986777307, 0.001088479969650507]
2023-06-30 18:40:28,887 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.663
2023-06-30 18:40:28,887 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.652
2023-06-30 18:40:28,887 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.464
2023-06-30 18:40:28,887 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.412
2023-06-30 18:40:28,888 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.145
2023-06-30 18:40:28,888 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.924
2023-06-30 18:40:28,888 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.970
2023-06-30 18:40:28,888 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.905
2023-06-30 18:40:28,888 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 6]),)
2023-06-30 18:40:28,888 - optimal_runtime.py[116] - INFO: avg ratio: 1.2475913015076354
2023-06-30 18:40:28,888 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003356332456893695
2023-06-30 18:40:28,889 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00063262 0.00046699 0.00039339 0.00054845 0.00063315 0.00087402
 0.00102461 0.00147092]
2023-06-30 18:40:28,891 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:29,021 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:29,023 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.2, 0.2, 0.0, 0.2, 0.4, 0.4, 0.6]
2023-06-30 18:40:29,033 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:29,034 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 785352512.0,
  'blocks_sparsity': [0.4, 0.2, 0.2, 0.0, 0.2, 0.4, 0.4, 0.6],
  'esti_latency': 0.002666125276885902,
  'esti_test_accuracy': 0.7565000454584757,
  'is_relaxed': False,
  'model_size': 25072077.0,
  'update_swap_mem_cost': 1929538.0,
  'update_swap_time_cost': 0.010687589645385742}
2023-06-30 18:40:29,071 - gen_series_legodnn_models.py[28] - INFO: target model size: 24.350MB
2023-06-30 18:40:29,071 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 25533123.90909091B (24.350MB), try to adapt blocks
2023-06-30 18:40:29,073 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:29,086 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009935359954833984
2023-06-30 18:40:29,086 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005812799856066705, 0.0004094080030918121, 0.0003505919948220253, 0.0005473919995129109, 0.000541663996875286, 0.0007093759886920452, 0.0008238399773836135, 0.0010519360154867172]
2023-06-30 18:40:29,086 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.842
2023-06-30 18:40:29,086 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.861
2023-06-30 18:40:29,086 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.580
2023-06-30 18:40:29,086 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.415
2023-06-30 18:40:29,086 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.233
2023-06-30 18:40:29,086 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.095
2023-06-30 18:40:29,086 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.953
2023-06-30 18:40:29,086 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.936
2023-06-30 18:40:29,087 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:29,087 - optimal_runtime.py[116] - INFO: avg ratio: 1.3307297004759835
2023-06-30 18:40:29,087 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031466429107959147
2023-06-30 18:40:29,087 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00057113 0.00041442 0.00036448 0.00054739 0.0005878  0.00073729
 0.00104337 0.00142153]
2023-06-30 18:40:29,089 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:29,220 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:29,221 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.4, 0.2, 0.2, 0.0, 0.4, 0.4, 0.6]
2023-06-30 18:40:29,226 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-30 18:40:29,230 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:29,234 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2023-06-30 18:40:29,235 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 747685440.0,
  'blocks_sparsity': [0.4, 0.4, 0.2, 0.2, 0.0, 0.4, 0.4, 0.6],
  'esti_latency': 0.0025110717748560445,
  'esti_test_accuracy': 0.7573000192642212,
  'is_relaxed': False,
  'model_size': 25486989.0,
  'update_swap_mem_cost': 9031402.0,
  'update_swap_time_cost': 0.013280153274536133}
2023-06-30 18:40:29,263 - gen_series_legodnn_models.py[28] - INFO: target model size: 24.784MB
2023-06-30 18:40:29,263 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 25988334.77777778B (24.784MB), try to adapt blocks
2023-06-30 18:40:29,265 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:29,279 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010658207893371583
2023-06-30 18:40:29,279 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006332160048186779, 0.00046940799802541733, 0.0003691840097308159, 0.000549919992685318, 0.0006155519969761372, 0.0008003199882805347, 0.0008094079829752445, 0.001084192007780075]
2023-06-30 18:40:29,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.691
2023-06-30 18:40:29,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.649
2023-06-30 18:40:29,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.500
2023-06-30 18:40:29,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.367
2023-06-30 18:40:29,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.177
2023-06-30 18:40:29,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.971
2023-06-30 18:40:29,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.970
2023-06-30 18:40:29,280 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.908
2023-06-30 18:40:29,280 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:29,281 - optimal_runtime.py[116] - INFO: avg ratio: 1.348020075561519
2023-06-30 18:40:29,281 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003106282505803252
2023-06-30 18:40:29,281 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062215 0.00046779 0.00038381 0.00056672 0.00061555 0.00083182
 0.0010251  0.00146512]
2023-06-30 18:40:29,283 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:29,412 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:29,413 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.4, 0.6]
2023-06-30 18:40:29,418 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:29,422 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:29,423 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 836287040.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.4, 0.6],
  'esti_latency': 0.002474605522319833,
  'esti_test_accuracy': 0.7580000360806783,
  'is_relaxed': False,
  'model_size': 25833229.0,
  'update_swap_mem_cost': 2680964.0,
  'update_swap_time_cost': 0.009246349334716797}
2023-06-30 18:40:29,451 - gen_series_legodnn_models.py[28] - INFO: target model size: 25.219MB
2023-06-30 18:40:29,451 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 26443545.646464646B (25.219MB), try to adapt blocks
2023-06-30 18:40:29,453 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:29,467 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010426400184631347
2023-06-30 18:40:29,467 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000627519991248846, 0.0004765760041773319, 0.0003778880052268505, 0.0005713919959962369, 0.0006204480044543744, 0.0007300159856677055, 0.0007944320067763328, 0.0010828480161726474]
2023-06-30 18:40:29,467 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.706
2023-06-30 18:40:29,468 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.619
2023-06-30 18:40:29,468 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.466
2023-06-30 18:40:29,468 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.355
2023-06-30 18:40:29,468 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.168
2023-06-30 18:40:29,468 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.065
2023-06-30 18:40:29,468 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.988
2023-06-30 18:40:29,468 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.910
2023-06-30 18:40:29,468 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:29,468 - optimal_runtime.py[116] - INFO: avg ratio: 1.2633851781894758
2023-06-30 18:40:29,469 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033143741516653527
2023-06-30 18:40:29,469 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061656 0.00047658 0.00039286 0.00057139 0.00062045 0.00075875
 0.00100613 0.00146331]
2023-06-30 18:40:29,471 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:29,609 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:29,609 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.4, 0.6]
2023-06-30 18:40:29,610 - gen_series_legodnn_models.py[28] - INFO: target model size: 25.653MB
2023-06-30 18:40:29,610 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 26898756.515151516B (25.653MB), try to adapt blocks
2023-06-30 18:40:29,611 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:29,626 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010878911972045898
2023-06-30 18:40:29,626 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006287679933011533, 0.00046735998988151555, 0.0003664319962263107, 0.0005530879832804204, 0.0006102719940245152, 0.0007520640082657338, 0.0007844799980521202, 0.0010467520132660865]
2023-06-30 18:40:29,626 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.703
2023-06-30 18:40:29,626 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.651
2023-06-30 18:40:29,626 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.511
2023-06-30 18:40:29,626 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.400
2023-06-30 18:40:29,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.188
2023-06-30 18:40:29,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.033
2023-06-30 18:40:29,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.000
2023-06-30 18:40:29,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.941
2023-06-30 18:40:29,627 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:29,627 - optimal_runtime.py[116] - INFO: avg ratio: 1.2831212529440128
2023-06-30 18:40:29,627 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032633947638080565
2023-06-30 18:40:29,628 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061778 0.00046736 0.00038095 0.00055309 0.00061027 0.00078166
 0.00099353 0.00141453]
2023-06-30 18:40:29,629 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:29,729 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:29,729 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.4, 0.6]
2023-06-30 18:40:29,735 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.2) from file
2023-06-30 18:40:29,736 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 866381120.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.4, 0.6],
  'esti_latency': 0.00265334834557813,
  'esti_test_accuracy': 0.7585333784421285,
  'is_relaxed': False,
  'model_size': 26774029.0,
  'update_swap_mem_cost': 6663938.0,
  'update_swap_time_cost': 0.006469011306762695}
2023-06-30 18:40:29,764 - gen_series_legodnn_models.py[28] - INFO: target model size: 26.087MB
2023-06-30 18:40:29,764 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 27353967.383838385B (26.087MB), try to adapt blocks
2023-06-30 18:40:29,766 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:29,780 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010514431953430176
2023-06-30 18:40:29,780 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006093759946525097, 0.0004546560049057007, 0.0003783360011875629, 0.0005943360030651091, 0.0006108160056173802, 0.000797664001584053, 0.0007990400046110153, 0.0010750079602003097]
2023-06-30 18:40:29,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.757
2023-06-30 18:40:29,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.697
2023-06-30 18:40:29,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.464
2023-06-30 18:40:29,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.303
2023-06-30 18:40:29,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.186
2023-06-30 18:40:29,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.974
2023-06-30 18:40:29,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.982
2023-06-30 18:40:29,780 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.916
2023-06-30 18:40:29,781 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 6]),)
2023-06-30 18:40:29,781 - optimal_runtime.py[116] - INFO: avg ratio: 1.2338936660187882
2023-06-30 18:40:29,781 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033935915982930124
2023-06-30 18:40:29,781 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059873 0.00045466 0.00039332 0.00059434 0.00061082 0.00082916
 0.00101197 0.00145271]
2023-06-30 18:40:29,783 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:29,909 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:29,909 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.4, 0.6]
2023-06-30 18:40:29,910 - gen_series_legodnn_models.py[28] - INFO: target model size: 26.521MB
2023-06-30 18:40:29,910 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 27809178.25252525B (26.521MB), try to adapt blocks
2023-06-30 18:40:29,912 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:29,928 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01172480010986328
2023-06-30 18:40:29,928 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007871039882302285, 0.0005056960023939609, 0.00035824000462889667, 0.0005938240066170693, 0.000610111977905035, 0.0007800000160932541, 0.0007850879989564418, 0.0010685120224952695]
2023-06-30 18:40:29,928 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.360
2023-06-30 18:40:29,928 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.525
2023-06-30 18:40:29,928 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.546
2023-06-30 18:40:29,928 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.304
2023-06-30 18:40:29,928 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.188
2023-06-30 18:40:29,928 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.996
2023-06-30 18:40:29,928 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.000
2023-06-30 18:40:29,928 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.922
2023-06-30 18:40:29,929 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4]),)
2023-06-30 18:40:29,929 - optimal_runtime.py[116] - INFO: avg ratio: 1.2840870966446272
2023-06-30 18:40:29,929 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032609401567307967
2023-06-30 18:40:29,929 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00077335 0.0005057  0.00037243 0.00059382 0.00061011 0.0008108
 0.0009943  0.00144393]
2023-06-30 18:40:29,931 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:30,038 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:30,038 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.4, 0.6]
2023-06-30 18:40:30,046 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.0) from file
2023-06-30 18:40:30,046 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 896475200.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.4, 0.6],
  'esti_latency': 0.002675872548044294,
  'esti_test_accuracy': 0.7586000561714172,
  'is_relaxed': False,
  'model_size': 27714957.0,
  'update_swap_mem_cost': 8545666.0,
  'update_swap_time_cost': 0.007546424865722656}
2023-06-30 18:40:30,076 - gen_series_legodnn_models.py[28] - INFO: target model size: 26.955MB
2023-06-30 18:40:30,076 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 28264389.12121212B (26.955MB), try to adapt blocks
2023-06-30 18:40:30,078 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:30,092 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010628191947937012
2023-06-30 18:40:30,092 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006223360039293765, 0.0004697279930114746, 0.00038112000748515126, 0.0005961920022964477, 0.0006015679910779, 0.0008452479913830758, 0.0007937919944524766, 0.0010843199640512466]
2023-06-30 18:40:30,092 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.720
2023-06-30 18:40:30,092 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.642
2023-06-30 18:40:30,092 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.453
2023-06-30 18:40:30,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.299
2023-06-30 18:40:30,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.205
2023-06-30 18:40:30,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.956
2023-06-30 18:40:30,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.989
2023-06-30 18:40:30,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.908
2023-06-30 18:40:30,093 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 6]),)
2023-06-30 18:40:30,093 - optimal_runtime.py[116] - INFO: avg ratio: 1.236389570999791
2023-06-30 18:40:30,093 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003386740940238028
2023-06-30 18:40:30,094 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061146 0.00046973 0.00039622 0.00059619 0.00060157 0.00084525
 0.00100532 0.0014653 ]
2023-06-30 18:40:30,096 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:30,223 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:30,224 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.4, 0.6]
2023-06-30 18:40:30,225 - gen_series_legodnn_models.py[28] - INFO: target model size: 27.389MB
2023-06-30 18:40:30,225 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 28719599.98989899B (27.389MB), try to adapt blocks
2023-06-30 18:40:30,226 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:30,242 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01152393627166748
2023-06-30 18:40:30,242 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007374719977378846, 0.0004848319999873638, 0.0003664640039205551, 0.0005432959981262684, 0.0006024640016257764, 0.0008340799920260907, 0.0007852799929678441, 0.001054496020078659]
2023-06-30 18:40:30,242 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.452
2023-06-30 18:40:30,242 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.591
2023-06-30 18:40:30,242 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.511
2023-06-30 18:40:30,243 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.425
2023-06-30 18:40:30,243 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.203
2023-06-30 18:40:30,243 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.968
2023-06-30 18:40:30,243 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.999
2023-06-30 18:40:30,243 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.934
2023-06-30 18:40:30,243 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4]),)
2023-06-30 18:40:30,243 - optimal_runtime.py[116] - INFO: avg ratio: 1.3600585890694734
2023-06-30 18:40:30,243 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030787873491929622
2023-06-30 18:40:30,244 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00072459 0.00048483 0.00038098 0.0005433  0.00060246 0.00083408
 0.00099454 0.00142499]
2023-06-30 18:40:30,246 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:30,349 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:30,350 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.2, 0.6]
2023-06-30 18:40:30,356 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2023-06-30 18:40:30,363 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.2) from file
2023-06-30 18:40:30,364 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 858854336.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.2, 0.6],
  'esti_latency': 0.002565609674708366,
  'esti_test_accuracy': 0.7594000498453776,
  'is_relaxed': False,
  'model_size': 28654861.0,
  'update_swap_mem_cost': 27493416.0,
  'update_swap_time_cost': 0.014025211334228516}
2023-06-30 18:40:30,393 - gen_series_legodnn_models.py[28] - INFO: target model size: 27.823MB
2023-06-30 18:40:30,393 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 29174810.85858586B (27.823MB), try to adapt blocks
2023-06-30 18:40:30,395 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:30,409 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01080339241027832
2023-06-30 18:40:30,409 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006125440001487732, 0.0004751680009067059, 0.00037715200707316395, 0.0005902079977095127, 0.0006090239882469177, 0.0007280960008502007, 0.0009090240225195884, 0.0010691839940845968]
2023-06-30 18:40:30,410 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.748
2023-06-30 18:40:30,410 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.623
2023-06-30 18:40:30,410 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.468
2023-06-30 18:40:30,410 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.312
2023-06-30 18:40:30,410 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.190
2023-06-30 18:40:30,410 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.067
2023-06-30 18:40:30,410 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.973
2023-06-30 18:40:30,410 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.921
2023-06-30 18:40:30,410 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:30,411 - optimal_runtime.py[116] - INFO: avg ratio: 1.2594773301551494
2023-06-30 18:40:30,411 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003324657838559512
2023-06-30 18:40:30,411 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060184 0.00047517 0.00039209 0.00059021 0.00060902 0.00075675
 0.00102145 0.00144484]
2023-06-30 18:40:30,413 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:30,548 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:30,549 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.2, 0.6]
2023-06-30 18:40:30,550 - gen_series_legodnn_models.py[28] - INFO: target model size: 28.257MB
2023-06-30 18:40:30,550 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 29630021.727272727B (28.257MB), try to adapt blocks
2023-06-30 18:40:30,552 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:30,566 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010657792091369628
2023-06-30 18:40:30,566 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006071040108799935, 0.00047452799975872034, 0.00036566400155425073, 0.0005615039989352226, 0.000601439993828535, 0.0007279679886996746, 0.0009027199968695641, 0.0010643839687108992]
2023-06-30 18:40:30,566 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.764
2023-06-30 18:40:30,566 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.626
2023-06-30 18:40:30,566 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.515
2023-06-30 18:40:30,566 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.379
2023-06-30 18:40:30,566 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.205
2023-06-30 18:40:30,566 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.067
2023-06-30 18:40:30,566 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.980
2023-06-30 18:40:30,566 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.925
2023-06-30 18:40:30,567 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:30,567 - optimal_runtime.py[116] - INFO: avg ratio: 1.2915784708955471
2023-06-30 18:40:30,567 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00324202615059458
2023-06-30 18:40:30,567 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005965  0.00047453 0.00038015 0.0005615  0.00060144 0.00075662
 0.00101437 0.00143835]
2023-06-30 18:40:30,569 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:30,674 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:30,675 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.2, 0.6]
2023-06-30 18:40:30,681 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.2) from file
2023-06-30 18:40:30,682 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 888948416.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.2, 0.6],
  'esti_latency': 0.002723785072306616,
  'esti_test_accuracy': 0.7599333922068278,
  'is_relaxed': False,
  'model_size': 29595661.0,
  'update_swap_mem_cost': 6663938.0,
  'update_swap_time_cost': 0.006853580474853516}
2023-06-30 18:40:30,712 - gen_series_legodnn_models.py[28] - INFO: target model size: 28.692MB
2023-06-30 18:40:30,712 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 30085232.595959596B (28.692MB), try to adapt blocks
2023-06-30 18:40:30,714 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:30,728 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010610431671142577
2023-06-30 18:40:30,728 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006257920004427433, 0.00045900800451636315, 0.0003753600008785724, 0.0005874879956245423, 0.0006160960011184215, 0.0008036159873008728, 0.00091158402338624, 0.0010725120306015014]
2023-06-30 18:40:30,728 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.711
2023-06-30 18:40:30,728 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.681
2023-06-30 18:40:30,728 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.475
2023-06-30 18:40:30,728 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.318
2023-06-30 18:40:30,728 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.176
2023-06-30 18:40:30,728 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.967
2023-06-30 18:40:30,728 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.970
2023-06-30 18:40:30,729 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.918
2023-06-30 18:40:30,729 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:30,729 - optimal_runtime.py[116] - INFO: avg ratio: 1.3233419433591957
2023-06-30 18:40:30,729 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003164209522112724
2023-06-30 18:40:30,729 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061486 0.00045901 0.00039023 0.00058749 0.0006161  0.00083535
 0.00102433 0.00144934]
2023-06-30 18:40:30,731 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:30,867 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:30,868 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.2, 0.6]
2023-06-30 18:40:30,869 - gen_series_legodnn_models.py[28] - INFO: target model size: 29.126MB
2023-06-30 18:40:30,870 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 30540443.464646466B (29.126MB), try to adapt blocks
2023-06-30 18:40:30,874 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:30,902 - optimal_runtime.py[77] - INFO: infer time of current model: 0.019119359970092772
2023-06-30 18:40:30,902 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.001212511993944645, 0.0008660160005092621, 0.0006119040027260781, 0.0009199999943375588, 0.0007771200165152549, 0.0010127679854631424, 0.0010669120177626609, 0.0012276799902319906]
2023-06-30 18:40:30,902 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.883
2023-06-30 18:40:30,902 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.891
2023-06-30 18:40:30,902 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.905
2023-06-30 18:40:30,902 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.842
2023-06-30 18:40:30,902 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.933
2023-06-30 18:40:30,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.767
2023-06-30 18:40:30,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.829
2023-06-30 18:40:30,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.802
2023-06-30 18:40:30,903 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 3, 6]),)
2023-06-30 18:40:30,903 - optimal_runtime.py[116] - INFO: avg ratio: 0.8699444610869602
2023-06-30 18:40:30,904 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0048133316153957965
2023-06-30 18:40:30,904 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00119133 0.00086602 0.00063614 0.00092    0.00077712 0.00105276
 0.00119887 0.00165902]
2023-06-30 18:40:30,906 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:31,008 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:31,009 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.2, 0.2, 0.4, 0.0, 0.6]
2023-06-30 18:40:31,014 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:31,019 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2023-06-30 18:40:31,024 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2023-06-30 18:40:31,036 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.0) from file
2023-06-30 18:40:31,036 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 829331008.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.2, 0.2, 0.4, 0.0, 0.6],
  'esti_latency': 0.004250799730606434,
  'esti_test_accuracy': 0.7605667114257812,
  'is_relaxed': False,
  'model_size': 30539981.0,
  'update_swap_mem_cost': 40771216.0,
  'update_swap_time_cost': 0.026978731155395508}
2023-06-30 18:40:31,066 - gen_series_legodnn_models.py[28] - INFO: target model size: 29.560MB
2023-06-30 18:40:31,066 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 30995654.333333332B (29.560MB), try to adapt blocks
2023-06-30 18:40:31,068 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:31,082 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01087558364868164
2023-06-30 18:40:31,083 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006336320042610169, 0.0004800640009343624, 0.000377408005297184, 0.000556096013635397, 0.0005655680038034916, 0.0007413440085947514, 0.0010303999967873098, 0.0010969919934868814]
2023-06-30 18:40:31,083 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.690
2023-06-30 18:40:31,083 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.607
2023-06-30 18:40:31,083 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.467
2023-06-30 18:40:31,083 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.351
2023-06-30 18:40:31,083 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.181
2023-06-30 18:40:31,083 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.048
2023-06-30 18:40:31,083 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.965
2023-06-30 18:40:31,083 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.898
2023-06-30 18:40:31,084 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:31,084 - optimal_runtime.py[116] - INFO: avg ratio: 1.2619752800687425
2023-06-30 18:40:31,084 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033180770212553065
2023-06-30 18:40:31,084 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062256 0.00048006 0.00039236 0.00057308 0.00061374 0.00077052
 0.0010304  0.00148242]
2023-06-30 18:40:31,086 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:31,225 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:31,226 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.0, 0.6]
2023-06-30 18:40:31,231 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:31,232 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 858847808.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.2, 0.4, 0.0, 0.6],
  'esti_latency': 0.0028514189568998836,
  'esti_test_accuracy': 0.7608000437418619,
  'is_relaxed': False,
  'model_size': 30770701.0,
  'update_swap_mem_cost': 2169666.0,
  'update_swap_time_cost': 0.005515098571777344}
2023-06-30 18:40:31,263 - gen_series_legodnn_models.py[28] - INFO: target model size: 29.994MB
2023-06-30 18:40:31,263 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 31450865.2020202B (29.994MB), try to adapt blocks
2023-06-30 18:40:31,265 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:31,279 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010645503997802735
2023-06-30 18:40:31,279 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006322560161352158, 0.00046576000750064844, 0.0003789120055735111, 0.0005803839899599552, 0.0005698240175843239, 0.0007315839938819408, 0.0010093439891934396, 0.0010639039874076844]
2023-06-30 18:40:31,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.693
2023-06-30 18:40:31,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.656
2023-06-30 18:40:31,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.462
2023-06-30 18:40:31,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.334
2023-06-30 18:40:31,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.172
2023-06-30 18:40:31,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.062
2023-06-30 18:40:31,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.985
2023-06-30 18:40:31,279 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.926
2023-06-30 18:40:31,280 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:31,280 - optimal_runtime.py[116] - INFO: avg ratio: 1.257560373595397
2023-06-30 18:40:31,280 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003329725765942066
2023-06-30 18:40:31,280 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062121 0.00046576 0.00039392 0.00058038 0.00061836 0.00076038
 0.00100934 0.00143771]
2023-06-30 18:40:31,282 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:31,418 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:31,418 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.2, 0.2, 0.0, 0.0, 0.4, 0.0, 0.6]
2023-06-30 18:40:31,423 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2023-06-30 18:40:31,428 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2023-06-30 18:40:31,428 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 853060928.0,
  'blocks_sparsity': [0.4, 0.2, 0.2, 0.0, 0.0, 0.4, 0.0, 0.6],
  'esti_latency': 0.0029175327633764853,
  'esti_test_accuracy': 0.7621000409126282,
  'is_relaxed': False,
  'model_size': 31421133.0,
  'update_swap_mem_cost': 6977256.0,
  'update_swap_time_cost': 0.009712696075439453}
2023-06-30 18:40:31,460 - gen_series_legodnn_models.py[28] - INFO: target model size: 30.428MB
2023-06-30 18:40:31,460 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 31906076.07070707B (30.428MB), try to adapt blocks
2023-06-30 18:40:31,462 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:31,476 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010754048347473144
2023-06-30 18:40:31,476 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006231360025703908, 0.0004513600058853626, 0.00037686400488018987, 0.0005962559953331947, 0.0006122560054063797, 0.0007589439824223519, 0.0010156479924917222, 0.0010803200379014015]
2023-06-30 18:40:31,477 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.718
2023-06-30 18:40:31,477 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.688
2023-06-30 18:40:31,477 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.470
2023-06-30 18:40:31,477 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.299
2023-06-30 18:40:31,477 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.184
2023-06-30 18:40:31,477 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.024
2023-06-30 18:40:31,477 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.979
2023-06-30 18:40:31,477 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.912
2023-06-30 18:40:31,477 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:31,478 - optimal_runtime.py[116] - INFO: avg ratio: 1.244014648908129
2023-06-30 18:40:31,478 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003365982210791121
2023-06-30 18:40:31,478 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061225 0.00045689 0.00039179 0.00059626 0.00061226 0.00078881
 0.00101565 0.00145989]
2023-06-30 18:40:31,480 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:31,602 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:31,603 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.0, 0.6]
2023-06-30 18:40:31,609 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:31,609 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 881421632.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.0, 0.6],
  'esti_latency': 0.002952502023882966,
  'esti_test_accuracy': 0.7622000376383463,
  'is_relaxed': False,
  'model_size': 31476493.0,
  'update_swap_mem_cost': 571458.0,
  'update_swap_time_cost': 0.00628972053527832}
2023-06-30 18:40:31,642 - gen_series_legodnn_models.py[28] - INFO: target model size: 30.862MB
2023-06-30 18:40:31,642 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 32361286.93939394B (30.862MB), try to adapt blocks
2023-06-30 18:40:31,644 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:31,658 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010878879547119141
2023-06-30 18:40:31,658 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006224320009350777, 0.0004720640107989311, 0.00038166400045156477, 0.0005835839919745922, 0.0006287360042333603, 0.0007724159918725491, 0.0010398720167577266, 0.0010827199853956698]
2023-06-30 18:40:31,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.720
2023-06-30 18:40:31,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.634
2023-06-30 18:40:31,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.451
2023-06-30 18:40:31,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.327
2023-06-30 18:40:31,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.153
2023-06-30 18:40:31,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.006
2023-06-30 18:40:31,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.956
2023-06-30 18:40:31,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.910
2023-06-30 18:40:31,660 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:31,660 - optimal_runtime.py[116] - INFO: avg ratio: 1.2342235655352805
2023-06-30 18:40:31,660 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003392684514472292
2023-06-30 18:40:31,660 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061156 0.00047206 0.00039678 0.00058358 0.00062874 0.00080282
 0.00103987 0.00146313]
2023-06-30 18:40:31,662 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:31,766 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:31,767 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.2, 0.2, 0.0, 0.2, 0.0, 0.6]
2023-06-30 18:40:31,773 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.0) from file
2023-06-30 18:40:31,777 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:31,783 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.2) from file
2023-06-30 18:40:31,783 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 941083712.0,
  'blocks_sparsity': [0.0, 0.0, 0.2, 0.2, 0.0, 0.2, 0.0, 0.6],
  'esti_latency': 0.002949356877250476,
  'esti_test_accuracy': 0.7625000476837158,
  'is_relaxed': False,
  'model_size': 32302093.0,
  'update_swap_mem_cost': 9349864.0,
  'update_swap_time_cost': 0.015729188919067383}
2023-06-30 18:40:31,815 - gen_series_legodnn_models.py[28] - INFO: target model size: 31.296MB
2023-06-30 18:40:31,816 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 32816497.808080807B (31.296MB), try to adapt blocks
2023-06-30 18:40:31,818 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:31,833 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011798527717590332
2023-06-30 18:40:31,834 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006674880012869835, 0.0005065919980406762, 0.00038531200215220453, 0.000567872017621994, 0.0006130239851772785, 0.000891008000820875, 0.001064063996076584, 0.001124000009149313]
2023-06-30 18:40:31,834 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.576
2023-06-30 18:40:31,834 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.523
2023-06-30 18:40:31,834 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.437
2023-06-30 18:40:31,834 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.323
2023-06-30 18:40:31,834 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.182
2023-06-30 18:40:31,834 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.872
2023-06-30 18:40:31,834 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.934
2023-06-30 18:40:31,835 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.876
2023-06-30 18:40:31,835 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:31,835 - optimal_runtime.py[116] - INFO: avg ratio: 1.3143075802174922
2023-06-30 18:40:31,835 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003185959847766687
2023-06-30 18:40:31,836 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00066749 0.00050659 0.00040057 0.00058522 0.00061302 0.00092619
 0.00106406 0.00151892]
2023-06-30 18:40:31,838 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:31,965 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:31,966 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.6]
2023-06-30 18:40:31,971 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:31,971 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 970600512.0,
  'blocks_sparsity': [0.0, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.6],
  'esti_latency': 0.002740594953617775,
  'esti_test_accuracy': 0.7627333799997965,
  'is_relaxed': False,
  'model_size': 32532813.0,
  'update_swap_mem_cost': 2169666.0,
  'update_swap_time_cost': 0.005354166030883789}
2023-06-30 18:40:32,005 - gen_series_legodnn_models.py[28] - INFO: target model size: 31.730MB
2023-06-30 18:40:32,005 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 33271708.676767677B (31.730MB), try to adapt blocks
2023-06-30 18:40:32,007 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:32,022 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011238271713256837
2023-06-30 18:40:32,022 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006623999923467637, 0.0004814400002360344, 0.0003864319995045662, 0.0005952319987118244, 0.0006174079924821853, 0.0008178559802472592, 0.0010325439646840095, 0.0010836479812860488]
2023-06-30 18:40:32,022 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.588
2023-06-30 18:40:32,022 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.602
2023-06-30 18:40:32,022 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.433
2023-06-30 18:40:32,022 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.301
2023-06-30 18:40:32,022 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.174
2023-06-30 18:40:32,022 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.950
2023-06-30 18:40:32,022 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.963
2023-06-30 18:40:32,022 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.909
2023-06-30 18:40:32,023 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:32,023 - optimal_runtime.py[116] - INFO: avg ratio: 1.302700136015202
2023-06-30 18:40:32,023 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032143476940110337
2023-06-30 18:40:32,023 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006624  0.00048144 0.00040174 0.00059523 0.00061741 0.00085015
 0.00103254 0.00146439]
2023-06-30 18:40:32,025 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:32,160 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:32,160 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.6]
2023-06-30 18:40:32,161 - gen_series_legodnn_models.py[28] - INFO: target model size: 32.164MB
2023-06-30 18:40:32,161 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 33726919.54545455B (32.164MB), try to adapt blocks
2023-06-30 18:40:32,162 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:32,176 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01036691188812256
2023-06-30 18:40:32,176 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005828160084784031, 0.00044140800088644035, 0.00035222399607300753, 0.0005422719940543176, 0.0005947519950568675, 0.0007736639939248562, 0.000996639970690012, 0.0010544639825820924]
2023-06-30 18:40:32,176 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.805
2023-06-30 18:40:32,176 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.748
2023-06-30 18:40:32,176 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.572
2023-06-30 18:40:32,176 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.428
2023-06-30 18:40:32,176 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.219
2023-06-30 18:40:32,177 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.004
2023-06-30 18:40:32,177 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.997
2023-06-30 18:40:32,177 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.934
2023-06-30 18:40:32,177 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:32,177 - optimal_runtime.py[116] - INFO: avg ratio: 1.4063584506542428
2023-06-30 18:40:32,177 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029774281060709405
2023-06-30 18:40:32,178 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058282 0.00044141 0.00036618 0.00054227 0.00059475 0.00080422
 0.00099664 0.00142495]
2023-06-30 18:40:32,179 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:32,293 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:32,294 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.6]
2023-06-30 18:40:32,300 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.4) from file
2023-06-30 18:40:32,311 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.0) from file
2023-06-30 18:40:32,312 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 941609792.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.6],
  'esti_latency': 0.0026033543072579417,
  'esti_test_accuracy': 0.7628000577290853,
  'is_relaxed': False,
  'model_size': 33358221.0,
  'update_swap_mem_cost': 9061926.0,
  'update_swap_time_cost': 0.01756453514099121}
2023-06-30 18:40:32,352 - gen_series_legodnn_models.py[28] - INFO: target model size: 32.599MB
2023-06-30 18:40:32,352 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 34182130.41414142B (32.599MB), try to adapt blocks
2023-06-30 18:40:32,354 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:32,368 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010995712280273438
2023-06-30 18:40:32,369 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006293759979307652, 0.00047596799954771987, 0.0003808320090174675, 0.0005956479981541633, 0.0006149119958281516, 0.0008526400029659272, 0.0010186240002512932, 0.001081152006983757]
2023-06-30 18:40:32,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.701
2023-06-30 18:40:32,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.621
2023-06-30 18:40:32,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.454
2023-06-30 18:40:32,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.300
2023-06-30 18:40:32,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.179
2023-06-30 18:40:32,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.947
2023-06-30 18:40:32,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.976
2023-06-30 18:40:32,369 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.911
2023-06-30 18:40:32,370 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 6]),)
2023-06-30 18:40:32,370 - optimal_runtime.py[116] - INFO: avg ratio: 1.2271966343601337
2023-06-30 18:40:32,370 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0034121110349782037
2023-06-30 18:40:32,370 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061838 0.00047597 0.00039592 0.00059565 0.00061491 0.00085264
 0.00101862 0.00146101]
2023-06-30 18:40:32,372 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:32,476 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:32,476 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.6]
2023-06-30 18:40:32,476 - gen_series_legodnn_models.py[28] - INFO: target model size: 33.033MB
2023-06-30 18:40:32,476 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 34637341.28282829B (33.033MB), try to adapt blocks
2023-06-30 18:40:32,478 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:32,492 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010594304084777833
2023-06-30 18:40:32,492 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005794240050017833, 0.0004591039940714836, 0.0003593920022249222, 0.0005537919960916043, 0.0006017279960215092, 0.0008514879941940308, 0.0010115200132131577, 0.0010526399947702887]
2023-06-30 18:40:32,492 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.848
2023-06-30 18:40:32,492 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.680
2023-06-30 18:40:32,492 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.541
2023-06-30 18:40:32,492 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.398
2023-06-30 18:40:32,492 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.204
2023-06-30 18:40:32,492 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.949
2023-06-30 18:40:32,493 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.983
2023-06-30 18:40:32,493 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.936
2023-06-30 18:40:32,493 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:32,493 - optimal_runtime.py[116] - INFO: avg ratio: 1.3812930109088883
2023-06-30 18:40:32,493 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030314575872884986
2023-06-30 18:40:32,493 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005693  0.0004591  0.00037363 0.00055379 0.00060173 0.00085149
 0.00101152 0.00142248]
2023-06-30 18:40:32,495 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:32,626 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:32,627 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.6]
2023-06-30 18:40:32,627 - gen_series_legodnn_models.py[28] - INFO: target model size: 33.467MB
2023-06-30 18:40:32,627 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 35092552.15151515B (33.467MB), try to adapt blocks
2023-06-30 18:40:32,629 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:32,643 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010954239845275878
2023-06-30 18:40:32,643 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006270080022513865, 0.0004623680002987385, 0.00037980800867080684, 0.0005612800084054471, 0.0006020480021834373, 0.0008498240076005458, 0.0010137600041925906, 0.001063424028456211]
2023-06-30 18:40:32,643 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.708
2023-06-30 18:40:32,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.668
2023-06-30 18:40:32,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.458
2023-06-30 18:40:32,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.380
2023-06-30 18:40:32,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.204
2023-06-30 18:40:32,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.950
2023-06-30 18:40:32,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.980
2023-06-30 18:40:32,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.926
2023-06-30 18:40:32,644 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:32,644 - optimal_runtime.py[116] - INFO: avg ratio: 1.3472485429800394
2023-06-30 18:40:32,644 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031080613892713357
2023-06-30 18:40:32,645 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061605 0.00046237 0.00039485 0.00056128 0.00060205 0.00084982
 0.00101376 0.00143706]
2023-06-30 18:40:32,647 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:32,761 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:32,761 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.6]
2023-06-30 18:40:32,762 - gen_series_legodnn_models.py[28] - INFO: target model size: 33.901MB
2023-06-30 18:40:32,762 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 35547763.02020202B (33.901MB), try to adapt blocks
2023-06-30 18:40:32,764 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:32,781 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01293388843536377
2023-06-30 18:40:32,781 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007290879972279072, 0.00047296000272035603, 0.00038137599080801017, 0.0007310719937086105, 0.000626240000128746, 0.0008611199893057347, 0.0010244159735739232, 0.0011397120058536533]
2023-06-30 18:40:32,781 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.468
2023-06-30 18:40:32,782 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.631
2023-06-30 18:40:32,782 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.452
2023-06-30 18:40:32,782 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.059
2023-06-30 18:40:32,782 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.157
2023-06-30 18:40:32,782 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.938
2023-06-30 18:40:32,782 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.970
2023-06-30 18:40:32,782 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.864
2023-06-30 18:40:32,783 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5, 6]),)
2023-06-30 18:40:32,783 - optimal_runtime.py[116] - INFO: avg ratio: 1.1153969720869603
2023-06-30 18:40:32,783 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0037541173976415143
2023-06-30 18:40:32,784 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00071635 0.00047296 0.00039648 0.00073107 0.00062624 0.00086112
 0.00102442 0.00154015]
2023-06-30 18:40:32,786 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:32,897 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:32,898 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.6]
2023-06-30 18:40:32,898 - gen_series_legodnn_models.py[28] - INFO: target model size: 34.335MB
2023-06-30 18:40:32,898 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 36002973.88888889B (34.335MB), try to adapt blocks
2023-06-30 18:40:32,900 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:32,914 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01087830352783203
2023-06-30 18:40:32,914 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006143679991364479, 0.0004752320013940335, 0.0003669120036065578, 0.0005599359981715679, 0.0006049279868602753, 0.0008484479896724225, 0.0010121600106358527, 0.0010618560090661048]
2023-06-30 18:40:32,914 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.743
2023-06-30 18:40:32,915 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.623
2023-06-30 18:40:32,915 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.509
2023-06-30 18:40:32,915 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.383
2023-06-30 18:40:32,915 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.198
2023-06-30 18:40:32,915 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.952
2023-06-30 18:40:32,915 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.982
2023-06-30 18:40:32,915 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.928
2023-06-30 18:40:32,915 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:32,915 - optimal_runtime.py[116] - INFO: avg ratio: 1.3635263264619952
2023-06-30 18:40:32,916 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030709573382813856
2023-06-30 18:40:32,916 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060364 0.00047523 0.00038144 0.00055994 0.00060493 0.00084845
 0.00101216 0.00143494]
2023-06-30 18:40:32,918 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:33,030 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:33,030 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.6]
2023-06-30 18:40:33,031 - gen_series_legodnn_models.py[28] - INFO: target model size: 34.769MB
2023-06-30 18:40:33,031 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 36458184.75757576B (34.769MB), try to adapt blocks
2023-06-30 18:40:33,033 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:33,050 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013205280303955078
2023-06-30 18:40:33,050 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007206400036811829, 0.0005062719956040383, 0.00046540799364447593, 0.0005927679911255836, 0.000654752004891634, 0.0009334719777107238, 0.001073440007865429, 0.0011496319845318795]
2023-06-30 18:40:33,050 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.486
2023-06-30 18:40:33,051 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.524
2023-06-30 18:40:33,051 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.190
2023-06-30 18:40:33,051 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.306
2023-06-30 18:40:33,051 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.107
2023-06-30 18:40:33,051 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.865
2023-06-30 18:40:33,051 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.926
2023-06-30 18:40:33,051 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.857
2023-06-30 18:40:33,052 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 6]),)
2023-06-30 18:40:33,052 - optimal_runtime.py[116] - INFO: avg ratio: 1.1323204106116616
2023-06-30 18:40:33,052 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003698009096141254
2023-06-30 18:40:33,053 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00070805 0.00050627 0.00048384 0.00059277 0.00065475 0.00093347
 0.00107344 0.00155355]
2023-06-30 18:40:33,055 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:33,176 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:33,177 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.4]
2023-06-30 18:40:33,192 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.2) from file
2023-06-30 18:40:33,210 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.4) from file
2023-06-30 18:40:33,211 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 941898240.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.4],
  'esti_latency': 0.0033939135904239998,
  'esti_test_accuracy': 0.7629000743230184,
  'is_relaxed': False,
  'model_size': 36216141.0,
  'update_swap_mem_cost': 27514564.0,
  'update_swap_time_cost': 0.03327631950378418}
2023-06-30 18:40:33,246 - gen_series_legodnn_models.py[28] - INFO: target model size: 35.203MB
2023-06-30 18:40:33,246 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 36913395.62626263B (35.203MB), try to adapt blocks
2023-06-30 18:40:33,248 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:33,264 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011700927734375
2023-06-30 18:40:33,264 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006097600050270558, 0.0004763839989900589, 0.00036905600130558014, 0.0005954879932105541, 0.0006555199846625328, 0.0008081280030310154, 0.0010113600119948387, 0.001180800009518862]
2023-06-30 18:40:33,265 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.756
2023-06-30 18:40:33,265 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.619
2023-06-30 18:40:33,265 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.501
2023-06-30 18:40:33,265 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.301
2023-06-30 18:40:33,265 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.106
2023-06-30 18:40:33,265 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.961
2023-06-30 18:40:33,265 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.983
2023-06-30 18:40:33,265 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.936
2023-06-30 18:40:33,266 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 6]),)
2023-06-30 18:40:33,266 - optimal_runtime.py[116] - INFO: avg ratio: 1.22238452536544
2023-06-30 18:40:33,266 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0034255433468748254
2023-06-30 18:40:33,267 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059911 0.00047638 0.00038367 0.00059549 0.00065552 0.00084004
 0.00101136 0.0014212 ]
2023-06-30 18:40:33,269 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:33,395 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:33,395 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.4]
2023-06-30 18:40:33,395 - gen_series_legodnn_models.py[28] - INFO: target model size: 35.637MB
2023-06-30 18:40:33,395 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 37368606.4949495B (35.637MB), try to adapt blocks
2023-06-30 18:40:33,397 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:33,412 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010702848434448242
2023-06-30 18:40:33,412 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006085120029747487, 0.00045353599637746814, 0.0003588800057768822, 0.0005560319907963276, 0.0005976000092923642, 0.0007981440164148807, 0.0010078079849481583, 0.0011622080281376839]
2023-06-30 18:40:33,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.759
2023-06-30 18:40:33,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.701
2023-06-30 18:40:33,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.543
2023-06-30 18:40:33,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.393
2023-06-30 18:40:33,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.213
2023-06-30 18:40:33,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.974
2023-06-30 18:40:33,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.986
2023-06-30 18:40:33,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.951
2023-06-30 18:40:33,413 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:33,413 - optimal_runtime.py[116] - INFO: avg ratio: 1.3829211670473793
2023-06-30 18:40:33,413 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030278885579056764
2023-06-30 18:40:33,413 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059788 0.00045354 0.00037309 0.00055603 0.0005976  0.00082966
 0.00100781 0.00139882]
2023-06-30 18:40:33,415 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:33,527 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:33,528 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.4]
2023-06-30 18:40:33,538 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.0) from file
2023-06-30 18:40:33,539 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 971992320.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.4],
  'esti_latency': 0.002787689935532153,
  'esti_test_accuracy': 0.7629667520523071,
  'is_relaxed': False,
  'model_size': 37157069.0,
  'update_swap_mem_cost': 8545666.0,
  'update_swap_time_cost': 0.010950565338134766}
2023-06-30 18:40:33,584 - gen_series_legodnn_models.py[28] - INFO: target model size: 36.072MB
2023-06-30 18:40:33,584 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 37823817.36363637B (36.072MB), try to adapt blocks
2023-06-30 18:40:33,586 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:33,601 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011201215744018554
2023-06-30 18:40:33,601 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006109440065920353, 0.00046044800058007236, 0.0003805759996175766, 0.000600160002708435, 0.0006121600046753884, 0.0008646400123834611, 0.001027712032198906, 0.001179135985672474]
2023-06-30 18:40:33,601 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.752
2023-06-30 18:40:33,602 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.675
2023-06-30 18:40:33,602 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.455
2023-06-30 18:40:33,602 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.290
2023-06-30 18:40:33,602 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.184
2023-06-30 18:40:33,602 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.934
2023-06-30 18:40:33,602 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.967
2023-06-30 18:40:33,602 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.938
2023-06-30 18:40:33,602 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:33,602 - optimal_runtime.py[116] - INFO: avg ratio: 1.309844454541218
2023-06-30 18:40:33,603 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031968155941500443
2023-06-30 18:40:33,603 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060027 0.00046045 0.00039565 0.00060016 0.00061216 0.00086464
 0.00102771 0.0014192 ]
2023-06-30 18:40:33,605 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:33,712 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:33,713 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.4]
2023-06-30 18:40:33,714 - gen_series_legodnn_models.py[28] - INFO: target model size: 36.506MB
2023-06-30 18:40:33,714 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 38279028.23232323B (36.506MB), try to adapt blocks
2023-06-30 18:40:33,718 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:33,745 - optimal_runtime.py[77] - INFO: infer time of current model: 0.018978879928588866
2023-06-30 18:40:33,745 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0011320320144295693, 0.0008943999856710434, 0.0005780800133943559, 0.0009144960045814513, 0.0008049279898405075, 0.0011551679968833924, 0.001196927987039089, 0.0013786559849977493]
2023-06-30 18:40:33,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.946
2023-06-30 18:40:33,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.862
2023-06-30 18:40:33,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.958
2023-06-30 18:40:33,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.847
2023-06-30 18:40:33,746 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.900
2023-06-30 18:40:33,746 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.699
2023-06-30 18:40:33,746 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.830
2023-06-30 18:40:33,746 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.802
2023-06-30 18:40:33,747 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4, 6, 7]),)
2023-06-30 18:40:33,747 - optimal_runtime.py[116] - INFO: avg ratio: 0.8484358551625695
2023-06-30 18:40:33,747 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004935353866422802
2023-06-30 18:40:33,747 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00111226 0.0008944  0.00060098 0.0009145  0.00080493 0.00115517
 0.00119693 0.00165934]
2023-06-30 18:40:33,750 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:33,880 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:33,881 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.4]
2023-06-30 18:40:33,881 - gen_series_legodnn_models.py[28] - INFO: target model size: 36.940MB
2023-06-30 18:40:33,881 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 38734239.1010101B (36.940MB), try to adapt blocks
2023-06-30 18:40:33,883 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:33,898 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010865440368652344
2023-06-30 18:40:33,898 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006113919951021671, 0.00046403199061751364, 0.0003613759987056255, 0.0005515839867293834, 0.0006012799963355064, 0.0008364799953997135, 0.001012127999216318, 0.0011756799854338168]
2023-06-30 18:40:33,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.751
2023-06-30 18:40:33,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.662
2023-06-30 18:40:33,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.533
2023-06-30 18:40:33,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.404
2023-06-30 18:40:33,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.205
2023-06-30 18:40:33,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.966
2023-06-30 18:40:33,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.982
2023-06-30 18:40:33,899 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.941
2023-06-30 18:40:33,899 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:33,899 - optimal_runtime.py[116] - INFO: avg ratio: 1.3806379329941807
2023-06-30 18:40:33,899 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030328959375375743
2023-06-30 18:40:33,900 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060071 0.00046403 0.00037569 0.00055158 0.00060128 0.00083648
 0.00101213 0.00141504]
2023-06-30 18:40:33,901 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:34,013 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:34,014 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.4, 0.2, 0.2, 0.0, 0.4, 0.0, 0.2]
2023-06-30 18:40:34,025 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2023-06-30 18:40:34,037 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2023-06-30 18:40:34,048 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2023-06-30 18:40:34,065 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.2) from file
2023-06-30 18:40:34,066 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 853290112.0,
  'blocks_sparsity': [0.4, 0.4, 0.2, 0.2, 0.0, 0.4, 0.0, 0.2],
  'esti_latency': 0.0028644767916816216,
  'esti_test_accuracy': 0.7634000380833944,
  'is_relaxed': False,
  'model_size': 38690765.0,
  'update_swap_mem_cost': 36815240.0,
  'update_swap_time_cost': 0.05098915100097656}
2023-06-30 18:40:34,099 - gen_series_legodnn_models.py[28] - INFO: target model size: 37.374MB
2023-06-30 18:40:34,099 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 39189449.96969697B (37.374MB), try to adapt blocks
2023-06-30 18:40:34,101 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:34,115 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010903200149536134
2023-06-30 18:40:34,115 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006135680042207241, 0.0004501760043203831, 0.00037811199948191643, 0.0005483519993722439, 0.0006083840057253837, 0.0007519360072910785, 0.0010239680111408232, 0.0012930880226194857]
2023-06-30 18:40:34,115 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.745
2023-06-30 18:40:34,115 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.720
2023-06-30 18:40:34,115 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.465
2023-06-30 18:40:34,115 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.370
2023-06-30 18:40:34,116 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.191
2023-06-30 18:40:34,116 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.033
2023-06-30 18:40:34,116 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.971
2023-06-30 18:40:34,116 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.943
2023-06-30 18:40:34,116 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:34,116 - optimal_runtime.py[116] - INFO: avg ratio: 1.2649720255607435
2023-06-30 18:40:34,116 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033102164265902574
2023-06-30 18:40:34,117 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060285 0.00044862 0.00039309 0.0005651  0.00060838 0.00078153
 0.00102397 0.00141113]
2023-06-30 18:40:34,118 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:34,225 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:34,225 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.0, 0.2]
2023-06-30 18:40:34,231 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2023-06-30 18:40:34,236 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2023-06-30 18:40:34,237 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 941891712.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.0, 0.2],
  'esti_latency': 0.0031583221191215493,
  'esti_test_accuracy': 0.7641000548998514,
  'is_relaxed': False,
  'model_size': 39037005.0,
  'update_swap_mem_cost': 2680964.0,
  'update_swap_time_cost': 0.011112451553344727}
2023-06-30 18:40:34,280 - gen_series_legodnn_models.py[28] - INFO: target model size: 37.808MB
2023-06-30 18:40:34,280 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 39644660.83838384B (37.808MB), try to adapt blocks
2023-06-30 18:40:34,282 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:34,299 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012294079780578613
2023-06-30 18:40:34,300 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000662432000041008, 0.0005239039994776248, 0.00039603199809789657, 0.0006187520064413548, 0.0006143679991364479, 0.0007487040124833584, 0.0010194559767842293, 0.0013413119725883007]
2023-06-30 18:40:34,300 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.616
2023-06-30 18:40:34,300 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.472
2023-06-30 18:40:34,300 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.398
2023-06-30 18:40:34,300 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.252
2023-06-30 18:40:34,300 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.180
2023-06-30 18:40:34,300 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.038
2023-06-30 18:40:34,300 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.975
2023-06-30 18:40:34,300 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.909
2023-06-30 18:40:34,301 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:34,301 - optimal_runtime.py[116] - INFO: avg ratio: 1.2169106965672545
2023-06-30 18:40:34,301 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0034409519038662707
2023-06-30 18:40:34,302 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065086 0.0005239  0.00041172 0.00061875 0.00061437 0.00077817
 0.00101946 0.00146376]
2023-06-30 18:40:34,304 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:34,415 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:34,416 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.0, 0.2]
2023-06-30 18:40:34,416 - gen_series_legodnn_models.py[28] - INFO: target model size: 38.242MB
2023-06-30 18:40:34,416 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 40099871.70707071B (38.242MB), try to adapt blocks
2023-06-30 18:40:34,418 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:34,432 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010606592178344726
2023-06-30 18:40:34,432 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005780800022184849, 0.00045295999944210054, 0.00035049599781632423, 0.0005529280006885529, 0.0005995520129799843, 0.0007207999899983406, 0.0010062399841845036, 0.0012875199876725672]
2023-06-30 18:40:34,432 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.852
2023-06-30 18:40:34,432 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.703
2023-06-30 18:40:34,432 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.580
2023-06-30 18:40:34,432 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.401
2023-06-30 18:40:34,433 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.209
2023-06-30 18:40:34,433 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.078
2023-06-30 18:40:34,433 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.988
2023-06-30 18:40:34,433 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.947
2023-06-30 18:40:34,433 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:34,433 - optimal_runtime.py[116] - INFO: avg ratio: 1.3169155882609143
2023-06-30 18:40:34,433 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031796504009175023
2023-06-30 18:40:34,434 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00056798 0.00045296 0.00036438 0.00055293 0.00059955 0.00074917
 0.00100624 0.00140505]
2023-06-30 18:40:34,436 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:34,568 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:34,568 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2]
2023-06-30 18:40:34,575 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.2) from file
2023-06-30 18:40:34,575 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 971985792.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2],
  'esti_latency': 0.0030298705478134925,
  'esti_test_accuracy': 0.7646333972613016,
  'is_relaxed': False,
  'model_size': 39977805.0,
  'update_swap_mem_cost': 6663938.0,
  'update_swap_time_cost': 0.0067272186279296875}
2023-06-30 18:40:34,610 - gen_series_legodnn_models.py[28] - INFO: target model size: 38.676MB
2023-06-30 18:40:34,610 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 40555082.57575758B (38.676MB), try to adapt blocks
2023-06-30 18:40:34,612 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:34,626 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01105510425567627
2023-06-30 18:40:34,626 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006147839985787869, 0.0004624639973044396, 0.0003778240084648132, 0.0005722879990935325, 0.0006124479919672012, 0.0008301120102405548, 0.0010214719995856286, 0.0013006720133125781]
2023-06-30 18:40:34,626 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.742
2023-06-30 18:40:34,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.668
2023-06-30 18:40:34,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.466
2023-06-30 18:40:34,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.353
2023-06-30 18:40:34,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.183
2023-06-30 18:40:34,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.936
2023-06-30 18:40:34,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.973
2023-06-30 18:40:34,627 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.938
2023-06-30 18:40:34,627 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:34,627 - optimal_runtime.py[116] - INFO: avg ratio: 1.3341406174468409
2023-06-30 18:40:34,628 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003138598078365731
2023-06-30 18:40:34,628 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060404 0.00046246 0.00039279 0.00057229 0.00061245 0.00086289
 0.00102147 0.00141941]
2023-06-30 18:40:34,630 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:34,758 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:34,759 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.2]
2023-06-30 18:40:34,759 - gen_series_legodnn_models.py[28] - INFO: target model size: 39.110MB
2023-06-30 18:40:34,759 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 41010293.44444445B (39.110MB), try to adapt blocks
2023-06-30 18:40:34,761 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:34,776 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011423775672912598
2023-06-30 18:40:34,776 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006635839901864528, 0.000482015997171402, 0.00035868799686431885, 0.0005539520047605038, 0.0005997440107166767, 0.0007960640154778957, 0.001006944015622139, 0.0012803520187735559]
2023-06-30 18:40:34,776 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.613
2023-06-30 18:40:34,776 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.600
2023-06-30 18:40:34,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.544
2023-06-30 18:40:34,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.398
2023-06-30 18:40:34,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.208
2023-06-30 18:40:34,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.976
2023-06-30 18:40:34,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.987
2023-06-30 18:40:34,777 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.953
2023-06-30 18:40:34,777 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:34,777 - optimal_runtime.py[116] - INFO: avg ratio: 1.3834946604544947
2023-06-30 18:40:34,777 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030266334217818633
2023-06-30 18:40:34,778 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00065199 0.00048202 0.0003729  0.00055395 0.00059974 0.0008275
 0.00100694 0.00139723]
2023-06-30 18:40:34,779 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:34,882 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:34,882 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2]
2023-06-30 18:40:34,890 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.0) from file
2023-06-30 18:40:34,891 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 1002079872.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2],
  'esti_latency': 0.0029071383324764857,
  'esti_test_accuracy': 0.7647000749905905,
  'is_relaxed': False,
  'model_size': 40918733.0,
  'update_swap_mem_cost': 8545666.0,
  'update_swap_time_cost': 0.007911443710327148}
2023-06-30 18:40:34,925 - gen_series_legodnn_models.py[28] - INFO: target model size: 39.545MB
2023-06-30 18:40:34,926 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 41465504.31313131B (39.545MB), try to adapt blocks
2023-06-30 18:40:34,928 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:34,942 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011085439682006835
2023-06-30 18:40:34,942 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006195200085639954, 0.00047935999557375907, 0.00037535999715328217, 0.0005777280069887639, 0.0006086399964988231, 0.0008659199848771096, 0.0010230400115251541, 0.0012916159927845003]
2023-06-30 18:40:34,942 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.728
2023-06-30 18:40:34,942 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.609
2023-06-30 18:40:34,943 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.475
2023-06-30 18:40:34,943 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.340
2023-06-30 18:40:34,943 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.191
2023-06-30 18:40:34,943 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.933
2023-06-30 18:40:34,943 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.972
2023-06-30 18:40:34,943 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.944
2023-06-30 18:40:34,943 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:34,943 - optimal_runtime.py[116] - INFO: avg ratio: 1.3355685466350675
2023-06-30 18:40:34,943 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031352424319502008
2023-06-30 18:40:34,944 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006087  0.00047936 0.00039023 0.00057773 0.00060864 0.00086592
 0.00102304 0.00140952]
2023-06-30 18:40:34,946 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:35,071 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:35,072 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2]
2023-06-30 18:40:35,072 - gen_series_legodnn_models.py[28] - INFO: target model size: 39.979MB
2023-06-30 18:40:35,072 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 41920715.18181818B (39.979MB), try to adapt blocks
2023-06-30 18:40:35,074 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:35,090 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012586624145507812
2023-06-30 18:40:35,091 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007441919930279256, 0.0005790400020778179, 0.0003792000077664852, 0.0005856959968805313, 0.0006240640133619308, 0.0008721920028328897, 0.0010229119695723057, 0.0012916800044476986]
2023-06-30 18:40:35,091 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.439
2023-06-30 18:40:35,091 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.332
2023-06-30 18:40:35,091 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.461
2023-06-30 18:40:35,091 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.322
2023-06-30 18:40:35,091 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.161
2023-06-30 18:40:35,091 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.926
2023-06-30 18:40:35,091 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.972
2023-06-30 18:40:35,091 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.944
2023-06-30 18:40:35,092 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4]),)
2023-06-30 18:40:35,092 - optimal_runtime.py[116] - INFO: avg ratio: 1.2719253868335216
2023-06-30 18:40:35,092 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032921201365535687
2023-06-30 18:40:35,092 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00073119 0.00057904 0.00039422 0.0005857  0.00062406 0.00087219
 0.00102291 0.00140959]
2023-06-30 18:40:35,094 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:35,194 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:35,194 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2]
2023-06-30 18:40:35,194 - gen_series_legodnn_models.py[28] - INFO: target model size: 40.413MB
2023-06-30 18:40:35,194 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 42375926.05050505B (40.413MB), try to adapt blocks
2023-06-30 18:40:35,196 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:35,210 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010667424201965332
2023-06-30 18:40:35,210 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005841600075364112, 0.0004647360034286976, 0.00034988800063729287, 0.0005444479994475841, 0.0005886080078780651, 0.000849183987826109, 0.0010008640214800835, 0.0012598720304667949]
2023-06-30 18:40:35,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.833
2023-06-30 18:40:35,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.660
2023-06-30 18:40:35,210 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.583
2023-06-30 18:40:35,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.422
2023-06-30 18:40:35,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.231
2023-06-30 18:40:35,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.951
2023-06-30 18:40:35,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.993
2023-06-30 18:40:35,211 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.968
2023-06-30 18:40:35,211 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:35,211 - optimal_runtime.py[116] - INFO: avg ratio: 1.4121949245725498
2023-06-30 18:40:35,211 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029651226649577193
2023-06-30 18:40:35,212 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00057395 0.00046474 0.00036375 0.00054445 0.00058861 0.00084918
 0.00100086 0.00137488]
2023-06-30 18:40:35,213 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:35,324 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:35,325 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2]
2023-06-30 18:40:35,325 - gen_series_legodnn_models.py[28] - INFO: target model size: 40.847MB
2023-06-30 18:40:35,325 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 42831136.91919192B (40.847MB), try to adapt blocks
2023-06-30 18:40:35,327 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:35,344 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012769280433654785
2023-06-30 18:40:35,344 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007110400125384331, 0.0004859840013086795, 0.0003873279951512814, 0.0006060800068080426, 0.0006082879826426506, 0.0009296960011124611, 0.0010201280154287814, 0.00134262403100729]
2023-06-30 18:40:35,344 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.506
2023-06-30 18:40:35,344 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.587
2023-06-30 18:40:35,344 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.430
2023-06-30 18:40:35,344 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.278
2023-06-30 18:40:35,344 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.191
2023-06-30 18:40:35,344 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.869
2023-06-30 18:40:35,345 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.974
2023-06-30 18:40:35,345 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.908
2023-06-30 18:40:35,345 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 6]),)
2023-06-30 18:40:35,345 - optimal_runtime.py[116] - INFO: avg ratio: 1.218353288166597
2023-06-30 18:40:35,345 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0034368776436673027
2023-06-30 18:40:35,346 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00069862 0.00048598 0.00040267 0.00060608 0.00060829 0.0009297
 0.00102013 0.00146519]
2023-06-30 18:40:35,348 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:35,463 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:35,464 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.0, 0.0]
2023-06-30 18:40:35,470 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2023-06-30 18:40:35,486 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.0) from file
2023-06-30 18:40:35,486 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 971979264.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.0, 0.0],
  'esti_latency': 0.00339875368802134,
  'esti_test_accuracy': 0.7658333977063497,
  'is_relaxed': False,
  'model_size': 42798733.0,
  'update_swap_mem_cost': 41657668.0,
  'update_swap_time_cost': 0.02221822738647461}
2023-06-30 18:40:35,524 - gen_series_legodnn_models.py[28] - INFO: target model size: 41.281MB
2023-06-30 18:40:35,524 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 43286347.78787879B (41.281MB), try to adapt blocks
2023-06-30 18:40:35,526 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:35,541 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011579903602600097
2023-06-30 18:40:35,541 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006225280091166497, 0.000465888001024723, 0.00038358401134610176, 0.0005880000032484531, 0.0006200639829039574, 0.000748959980905056, 0.0010252799764275552, 0.001488320052623749]
2023-06-30 18:40:35,541 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.720
2023-06-30 18:40:35,541 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.656
2023-06-30 18:40:35,541 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.444
2023-06-30 18:40:35,541 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.317
2023-06-30 18:40:35,541 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.169
2023-06-30 18:40:35,542 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.038
2023-06-30 18:40:35,542 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.969
2023-06-30 18:40:35,542 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.894
2023-06-30 18:40:35,542 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:35,542 - optimal_runtime.py[116] - INFO: avg ratio: 1.2418233513181574
2023-06-30 18:40:35,542 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033719217582304285
2023-06-30 18:40:35,543 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061165 0.00046589 0.00039878 0.000588   0.00062006 0.00077844
 0.00102528 0.00148832]
2023-06-30 18:40:35,545 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:35,678 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:35,679 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.4, 0.0, 0.0]
2023-06-30 18:40:35,679 - gen_series_legodnn_models.py[28] - INFO: target model size: 41.715MB
2023-06-30 18:40:35,679 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 43741558.65656566B (41.715MB), try to adapt blocks
2023-06-30 18:40:35,681 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:35,695 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011034624099731445
2023-06-30 18:40:35,696 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006166719943284989, 0.000473471999168396, 0.0003659200072288513, 0.0005566400028765202, 0.0006079999804496764, 0.0007390080057084559, 0.0010022080093622207, 0.0013826560080051422]
2023-06-30 18:40:35,696 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.736
2023-06-30 18:40:35,696 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.629
2023-06-30 18:40:35,696 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.514
2023-06-30 18:40:35,696 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.391
2023-06-30 18:40:35,696 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.192
2023-06-30 18:40:35,696 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.052
2023-06-30 18:40:35,696 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.992
2023-06-30 18:40:35,696 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.963
2023-06-30 18:40:35,697 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5]),)
2023-06-30 18:40:35,697 - optimal_runtime.py[116] - INFO: avg ratio: 1.2870894149054322
2023-06-30 18:40:35,697 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0032533335521961267
2023-06-30 18:40:35,697 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006059  0.00047347 0.00038041 0.00055664 0.000608   0.00076809
 0.00100221 0.00138266]
2023-06-30 18:40:35,699 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:35,820 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:35,820 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.0]
2023-06-30 18:40:35,829 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.2) from file
2023-06-30 18:40:35,829 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 1002073344.0,
  'blocks_sparsity': [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.0],
  'esti_latency': 0.0032204327852243726,
  'esti_test_accuracy': 0.7663667400677999,
  'is_relaxed': False,
  'model_size': 43739533.0,
  'update_swap_mem_cost': 6663938.0,
  'update_swap_time_cost': 0.008585691452026367}
2023-06-30 18:40:35,869 - gen_series_legodnn_models.py[28] - INFO: target model size: 42.149MB
2023-06-30 18:40:35,869 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 44196769.52525253B (42.149MB), try to adapt blocks
2023-06-30 18:40:35,871 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:35,886 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011385215759277343
2023-06-30 18:40:35,886 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006207999922335149, 0.00047731200233101843, 0.00038300801068544385, 0.0005919039957225322, 0.0006129919961094856, 0.0008080000057816506, 0.0010238399617373943, 0.0014077760130167007]
2023-06-30 18:40:35,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.725
2023-06-30 18:40:35,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.616
2023-06-30 18:40:35,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.446
2023-06-30 18:40:35,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.308
2023-06-30 18:40:35,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.182
2023-06-30 18:40:35,887 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.962
2023-06-30 18:40:35,887 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.971
2023-06-30 18:40:35,887 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.945
2023-06-30 18:40:35,887 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:35,887 - optimal_runtime.py[116] - INFO: avg ratio: 1.3122281538560718
2023-06-30 18:40:35,887 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003191008488793329
2023-06-30 18:40:35,888 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060995 0.00047731 0.00039818 0.0005919  0.00061299 0.00083991
 0.00102384 0.00140778]
2023-06-30 18:40:35,890 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:35,988 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:35,988 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.0]
2023-06-30 18:40:35,988 - gen_series_legodnn_models.py[28] - INFO: target model size: 42.583MB
2023-06-30 18:40:35,988 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 44651980.39393939B (42.583MB), try to adapt blocks
2023-06-30 18:40:35,990 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:36,004 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01088764762878418
2023-06-30 18:40:36,005 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006032320000231267, 0.0004565120115876198, 0.0003632320016622543, 0.0005518720000982284, 0.0005971839912235738, 0.0008032000102102758, 0.0010085119977593423, 0.001381311982870102]
2023-06-30 18:40:36,005 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.775
2023-06-30 18:40:36,005 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.690
2023-06-30 18:40:36,005 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.525
2023-06-30 18:40:36,005 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.403
2023-06-30 18:40:36,005 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.214
2023-06-30 18:40:36,005 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.967
2023-06-30 18:40:36,005 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.986
2023-06-30 18:40:36,005 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.964
2023-06-30 18:40:36,005 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:36,006 - optimal_runtime.py[116] - INFO: avg ratio: 1.380538994106091
2023-06-30 18:40:36,006 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003033113295651349
2023-06-30 18:40:36,006 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00059269 0.00045651 0.00037762 0.00055187 0.00059718 0.00083492
 0.00100851 0.00138131]
2023-06-30 18:40:36,008 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:36,133 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:36,134 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.4, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.0]
2023-06-30 18:40:36,134 - gen_series_legodnn_models.py[28] - INFO: target model size: 43.018MB
2023-06-30 18:40:36,134 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 45107191.26262626B (43.018MB), try to adapt blocks
2023-06-30 18:40:36,136 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:36,152 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01177190399169922
2023-06-30 18:40:36,152 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007240320034325123, 0.0004397439993917942, 0.0003490560054779053, 0.0005527359992265701, 0.0006178559847176075, 0.0007964160107076167, 0.0010181119963526726, 0.0014804479889571668]
2023-06-30 18:40:36,152 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.479
2023-06-30 18:40:36,152 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.754
2023-06-30 18:40:36,152 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.587
2023-06-30 18:40:36,152 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.401
2023-06-30 18:40:36,152 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.173
2023-06-30 18:40:36,152 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.976
2023-06-30 18:40:36,153 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.976
2023-06-30 18:40:36,153 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.899
2023-06-30 18:40:36,153 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4]),)
2023-06-30 18:40:36,153 - optimal_runtime.py[116] - INFO: avg ratio: 1.350937725521636
2023-06-30 18:40:36,153 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003099573799059816
2023-06-30 18:40:36,154 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00071138 0.00043974 0.00036288 0.00055274 0.00061786 0.00082787
 0.00101811 0.00148045]
2023-06-30 18:40:36,155 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:36,252 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:36,252 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]
2023-06-30 18:40:36,257 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.0) from file
2023-06-30 18:40:36,264 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.0) from file
2023-06-30 18:40:36,264 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 1091252224.0,
  'blocks_sparsity': [0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0],
  'esti_latency': 0.003085748084731149,
  'esti_test_accuracy': 0.7664334177970886,
  'is_relaxed': False,
  'model_size': 44795981.0,
  'update_swap_mem_cost': 9061926.0,
  'update_swap_time_cost': 0.011631965637207031}
2023-06-30 18:40:36,300 - gen_series_legodnn_models.py[28] - INFO: target model size: 43.452MB
2023-06-30 18:40:36,300 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 45562402.13131313B (43.452MB), try to adapt blocks
2023-06-30 18:40:36,302 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:36,316 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011130880355834961
2023-06-30 18:40:36,317 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006237439997494221, 0.0004603840000927448, 0.0003796480037271977, 0.0005828160047531127, 0.0006100160032510757, 0.0008484480082988739, 0.0010199360102415085, 0.0014153920374810694]
2023-06-30 18:40:36,317 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.687
2023-06-30 18:40:36,317 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.676
2023-06-30 18:40:36,317 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.459
2023-06-30 18:40:36,317 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.329
2023-06-30 18:40:36,317 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.188
2023-06-30 18:40:36,317 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.952
2023-06-30 18:40:36,317 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.975
2023-06-30 18:40:36,317 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.940
2023-06-30 18:40:36,318 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4]),)
2023-06-30 18:40:36,318 - optimal_runtime.py[116] - INFO: avg ratio: 1.3252173328093708
2023-06-30 18:40:36,318 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031597316715677617
2023-06-30 18:40:36,318 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00062374 0.00046038 0.00039469 0.00058282 0.00061002 0.00084845
 0.00101994 0.00141539]
2023-06-30 18:40:36,320 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:36,435 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:36,435 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]
2023-06-30 18:40:36,435 - gen_series_legodnn_models.py[28] - INFO: target model size: 43.886MB
2023-06-30 18:40:36,436 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 46017613.0B (43.886MB), try to adapt blocks
2023-06-30 18:40:36,437 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2023-06-30 18:40:36,454 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012183072090148926
2023-06-30 18:40:36,454 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007270080111920834, 0.0004917440041899682, 0.0003938880115747452, 0.0005621759928762913, 0.0006590400077402592, 0.0008637120015919208, 0.0010291519798338413, 0.00141040001437068]
2023-06-30 18:40:36,454 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.447
2023-06-30 18:40:36,454 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.569
2023-06-30 18:40:36,454 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.406
2023-06-30 18:40:36,454 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.378
2023-06-30 18:40:36,454 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.100
2023-06-30 18:40:36,454 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.935
2023-06-30 18:40:36,455 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.966
2023-06-30 18:40:36,455 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.944
2023-06-30 18:40:36,455 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4]),)
2023-06-30 18:40:36,455 - optimal_runtime.py[116] - INFO: avg ratio: 1.3325736399541483
2023-06-30 18:40:36,455 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031422887656192893
2023-06-30 18:40:36,456 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00072701 0.00049174 0.00040949 0.00056218 0.00065904 0.00086371
 0.00102915 0.0014104 ]
2023-06-30 18:40:36,458 - optimal_runtime.py[226] - INFO: solving...
2023-06-30 18:40:36,561 - optimal_runtime.py[228] - INFO: solving finished
2023-06-30 18:40:36,562 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0]
